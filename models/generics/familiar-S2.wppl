// time ~/webppl-fork/webppl familiar-S2.wppl --require utils 0

var chain = last(process.argv) // load index as last command line index

// var targetUtterance = "some";
// var targetUtterance = "most";
// var targetUtterance = "all";
var targetUtterance = "generic";

var responseDictionary = { "agree-key": 1, "disagree-key": 0 };

var dataPath = "../../data/familiar_generics/"
var truthJudgmentDataFile = dataPath + "naturalGenerics-trials-formatted.csv"
var priorDataFile = dataPath + "naturalGenerics-prior-trials-n57.csv"

var d0 = dataFrame(utils.readCSV(priorDataFile).data, ["prevalence"]);
var d1 = dataFrame(utils.readCSV(truthJudgmentDataFile).data);

var data = {
	speaker: map(function(d){
			extend(d, {binaryResponse: responseDictionary[d.response]})
		}, d1.slice(0, d1.length - 1)),
	prior: map(function(d){
		extend(d, {
			roundedPrevalence: avoidEnds(d.prevalence/100),
			counts: Math.round(d.prevalence)
		})
	}, d0.slice(0, d0.length - 1))
};


// displayObj(_.filter(data.prior, {Property: "are white"}))
var properties = levels(data.speaker, "Property")

var utterancePrior = Infer({model: function(){return uniformDraw([targetUtterance,"silence"])}});

var meaning = function(utt,state, theta) {
  return utt=="generic"? state > theta :
         utt=="generic is false"? state<=theta :
         utt=='silence'? true :
         utt=='some'? state>0:
         utt=='most'? state>= 0.5:
         utt=='all'? state >= 0.99:
         true
}

var noiseLink = function(dist, noise){
	return Infer({model: function() { flip(noise) ? uniformDraw([0,1]) : sample(dist) }});
}

var customUniformDrift = function(params) {
  return sample(Uniform(_.omit(params, 'width')), {
    driftKernel: function(prevVal) {
		      var width = _.has(params, 'width') ? params.width : 0.1;
		      var a = Math.max(params.a, prevVal - width);
		      var b = Math.min(params.b, prevVal + width);
					return Uniform({a: a, b: b})
					// var range = params.b - params.a;
					// var midPt = params.b - (range / 2);
		      // return Infer({model: function(){
					// 	return flip(0.5) ? Uniform({a: a, b: b}) :
					// 	prevVal > midPt ?
					// 		Uniform({a: params.a,b: midPt  }) :
					// 		Uniform({a: midPt,b: params.b})
					// }})
		}
  });
};

var properties = ["have wings"];

var model = function(){

	var speakerOptimality = {
		s1: uniformDrift({a:0,b:20,r:10}),
		s2: uniformDrift({a:0,b:5, r:2.5})
	};

	// var speakerOptimality = {
	// 	s1: customUniformDrift({a:0, b:20, width: 5}),
	// 	s2: customUniformDrift({a:0, b:5, width: 1})
	// };

	// var nullParams = {
	// 	a: 1,
	// 	b: customUniformDrift({a:0, b:100, width: 20})
	// };

	var nullParams = {
		a: 1,
		b: 100
	};

	// var noise = uniformDrift({a:0,b:1,r:0.1});

	foreach(properties, function(p){

		var propertyData = {
			speaker: _.filter(data.speaker, {Property: p}),
			prior: _.filter(data.prior, {Property: p})
		}

		// prior parameters
		var theta = uniformDrift({a: 0, b: 1, width:0.2})
		// var theta = customUniformDrift({a:0, b:1, width: 0.2})

		var betaParams = {
			g: uniformDrift({a: 0, b: 1, width: 0.2}),
			d: uniformDrift({a: 0, b: 100, width: 20})
		}

		// var betaParams = {
		// 	g: customUniformDrift({a:0, b:1, width: 0.2}),
		// 	d: customUniformDrift({a:0, b:100, width: 20})
		// };

		// var nullParams = {
		// 	a:1,
		// 	b:uniformDrift({a:1,b:100,r:3})
		// };


		var priorParams = betaShape(betaParams);

		// display(_.map(propertyData.prior, "roundedPrevalence"))
		// observe structured prior data
		mapData({data: propertyData.prior}, function(d){
			 factor(
				 util.logsumexp([
						Math.log(theta) + Beta(priorParams).score(d.roundedPrevalence),
						Math.log(1-theta) + Beta(nullParams).score(d.roundedPrevalence)
					]))
		// 	factor(
		// 	Math.log(
		// 	(1-theta)*probability(Beta(nullParams), di) +
		// 	theta * probability(Beta(priorParams), di)
		// 	)
		// )
		})


		// observe structured prior data
		// mapData({data: propertyData.prior}, function(d){
		// 	var di = d.counts;
		// 	factor(Math.log(
		// 		(di==0 ? 1 : 0)*(1-theta)+
		// 		(di> 0 ? 1 : 0) * theta * probability(Binomial({n:100, p:g}), di)))
		// })

		query.add(["prior","isPresent", p, "na"], theta)
		query.add(["prior","prevalenceGivenPresent", p, "mean"], betaParams.g)
		query.add(["prior","prevalenceGivenPresent", p, "sampleSize"], betaParams.d)
		// query.add(["prior","nullParamsB", p, "na"], nullParams.b)
		query.add(["prior","prevalencePrior", p, "na"],
			beta ( flip(theta) ? priorParams : nullParams) )

			var statePrior = Infer({model: function(){
				sample(flip(theta) ? DiscretizedBeta(priorParams) : DiscretizedBeta(nullParams))
			}});

		// var statePrior = Infer({model: function(){
		// 	var component = flip(theta);
		// 	return component ?
		// 		categorical({
		// 			vs: bins,
		// 			ps:map(function(b) {
		// 				return probability(Binomial({n:100,
		// 					p: g}), Math.round(b*100)) +
    //       Number.EPSILON
		// 				}, bins )
		// 		}) : 0
		// }});

		/// RSA model
		var listener0 = cache(function(utterance, theta) {
		  Infer({model: function(){
		    var state = sample(statePrior)
		    var m = meaning(utterance, state, theta)
		    condition(m)
		    return state
		 }})}, 10000)

		var speaker1 = cache(function(state, theta) {
			Infer({model: function(){
		    var utterance = sample(utterancePrior);
		    var L0 = listener0(utterance, theta);
		    factor(speakerOptimality.s1 * L0.score(state))
		    return utterance
			}})}, 10000)

		var listener1 = cache(function(utterance) {
			Infer({model: function(){
		    var state = sample(statePrior);
		    var theta = targetUtterance === "generic" ? sample(thetaPrior) : -99;
		    var S1 = speaker1(state, theta)
		    observe(S1, utterance)
		    return state
			}})}, 10000)

		var speaker2 = function(speakerBeliefs){
			Infer({model: function(){
				var utterance = sample(utterancePrior);
		    var L1 = listener1(utterance)
		    // factor(speakerOptimality.s2 * L1.score(speakerBeliefs))
				var _kl = KL(speakerBeliefs, L1, L1.support());
				factor(speakerOptimality.s2  * -1 * _kl)
		    return utterance === targetUtterance ? 1 : 0
		 }})}

		var categories = levels(propertyData.speaker, "Category");

		foreach(categories, function(k){

			var categoryData = {
				speaker: _.filter(propertyData.speaker, {Category: k}),
				prior: _.filter(propertyData.prior, {Category: k})
			};

			var withinParams = {
				g: uniformDrift({a: 0, b: 1, width: 0.2}),
				d: uniformDrift({a: 0, b: 100, width: 20})
			}
			// var withinParams = {
			// 	g: customUniformDrift({a:0, b:1, width: 0.2}),
			// 	d: customUniformDrift({a:0, b:100, width: 20})
			// };

			var withinShape = betaShape(withinParams);

			mapData({data: categoryData.prior}, function(d){
				observe(Beta(withinShape), d.roundedPrevalence)
			})

			// mapData({data: categoryData.prior}, function(d){
			// 	var di = d.counts;
			// 	observe(Binomial({n:100, p: withinKind_prev}), di)
			// })


			query.add(["withinKind","prevalence", p, k],
			 				beta(withinShape))
			// query.add(["withinKind","prevalence", p, k], withinKind_prev)
			// displayObj(withinShape);
			var speakerBeliefs = DiscretizedBeta(withinShape)

			// var speakerBeliefs = Infer({model: function(){
			// 	return categorical({
			// 			vs:bins,
			// 			ps:map(function(b) {
			// 				return probability(Binomial({n:100,
			// 					p: withinKind_prev}), Math.round(b*100)) +
      //     Number.EPSILON
			// 				}, bins )
			// 		})
			// }});


			var s2prediction = speaker2(speakerBeliefs);
			// var s2prediction = noiseLink(speaker2(speakerBeliefs), noise);
			// display(s2prediction.support())
			var responseData = _.map(categoryData.speaker, "binaryResponse")

			mapData({data:responseData}, function(d){
				// display(s2prediction.score(d))
				observe(s2prediction, d)
			})

			query.add(["predictive",targetUtterance, p, k], expectation(s2prediction) )

		})

	})

	query.add(["param","speakerOptimality","s1","na"], speakerOptimality.s1)
	query.add(["param","speakerOptimality","s2","na"], speakerOptimality.s2)

	// query.add(["param","nullParams","b","na"], nullParams.b);

	// query.add(["param","noise","na","na"], noise)
	return query
}

var mhiter = 10000;

var burn = mhiter / 2;

var outfile = 'results-fullModel-s2-allowUPriors-refinedPriors-fixedNull-prevPriorFactorBugFixed-'+'smtncs'+targetUtterance+"-"+ mhiter+'_burn'+burn+'_chain'+chain+'.csv'

var posterior = Infer({
  model: model,
  method: "incrementalMH",
  samples: mhiter, burn: burn,
  verbose: T,
  verboseLag: mhiter / 20,
	stream: {
		path: "results/" + outfile,
		header: ["type", "param", "property", "category", "val"]
	}
})


//
// utils.writeQueryERP(posterior, "results/" + outfile,
// 	["type", "param", "property", "category", "val"])

display("written to " + outfile)
