// time ~/webppl-fork/webppl regression.wppl --require  ../node_modules/utils 0

var chain = last(process.argv) // load index as last command line index

var betaShape = function(p){
  return {a: p.g * p.d, b: (1-p.g) * p.d}
};

var responseDictionary = { "agree-key": true,
"disagree-key": false };

var dataPath = "../../../data/familiar_generics/"
var truthJudgmentDataFile = dataPath + "naturalGenerics-trials-formatted.csv"
var priorDataFile = dataPath + "naturalGenerics-prior-trials-n57.csv"
var cueValidityDataFile = dataPath + "cueValidity.csv"

var d0 = dataFrame(utils.readCSV(priorDataFile).data, ["prevalence"]);
var d1 = dataFrame(utils.readCSV(truthJudgmentDataFile).data);
var d2 = dataFrame(utils.readCSV(cueValidityDataFile).data, ["response"])

var data = {
	speaker: map(function(d){
			extend(d, {binaryResponse: responseDictionary[d.response]})
		}, d1.slice(0, d1.length - 1)),
	prevalence: map(function(d){
		extend(d, {
			roundedPrevalence: avoidEnds(d.prevalence/100),
			counts: Math.round(d.prevalence)
		})
	}, d0.slice(0, d0.length - 1)),
  cue: map(function(d){
    extend(d, {
      roundedCue: avoidEnds(d.response)
    })
  }, d2.slice(0, d2.length - 1))
};

var properties = levels(data.speaker, "Property");

var logisticFunction = function(y) {
   return 1 / (1 + exp(-y));
};

var regression = function(){

  var bs = {
    intercept: uniform({a: -10, b: 10}),
    prevalence: uniform({a: -10, b: 10}),
    cue: uniform({a: -10, b: 10})
  }

  var linearFunction = function(xs){
     return bs.intercept +
     bs.prevalence * xs.prevalence +
     bs.cue * xs.cue;
  };

  var sigma = uniform({a: 0, b: 10});

  foreach(properties, function(p){

    var categories = levels(_.filter(data.speaker, {Property: p}), "Category");

    foreach(categories, function(k){

      var itemData = {
				speaker: _.filter(data.speaker, {Category: k, Property: p}),
				prevalence: _.filter(data.prevalence, {Category: k, Property: p}),
        cue: _.filter(data.cue, {Category: k, Property: p})
			};

      // analyze prevalence data
      // var prevalenceParams = {
      //   g: uniformDrift({a: 0, b: 1, width: 0.2}),
      //   d: uniformDrift({a: 0, b: 100, width: 5})
      // };
      //
			// var prevalenceShapes = betaShape(prevalenceParams);
      var prevalenceShapes = {
        a: uniform({a: 1, b: 40}),
        b: uniform({a: 1, b: 40})
      };


      mapData({data: itemData.prevalence}, function(d){
        // display(Beta(prevalenceShapes).score(d.roundedPrevalence))
				observe(Beta(prevalenceShapes), d.roundedPrevalence)
			});

      // analyze cue validity data
      // var cueParams = {
      //   g: uniformDrift({a: 0, b: 1, width: 0.2}),
      //   d: uniformDrift({a: 0, b: 100, width: 5})
      // };
      //
      // var cueShapes = betaShape(cueParams);

      var cueShapes = {
        a: uniform({a: 1, b: 40}),
        b: uniform({a: 1, b: 40})
      };



      mapData({data: itemData.cue}, function(d){
        // display(Beta(cueShapes).score(d.roundedCue))
				observe(Beta(cueShapes), d.roundedCue)
			});

      var predictors = {
        prevalence: beta(prevalenceShapes),
        cue: beta(cueShapes)
      };

      query.add(["predictive", "prevalence", p, k], predictors.prevalence)
      query.add(["predictive", "cue", p, k], predictors.cue)

      var prediction = linearFunction(predictors);
      var prediction_withNoise = gaussian({mu: prediction, sigma: sigma});
      var logisticPrediction = Bernoulli({p:
        logisticFunction(prediction_withNoise)
      })

      var genericsData = _.map(itemData.speaker, "binaryResponse");

      mapData({data: genericsData}, function(d){
        // display(logisticPrediction.score(d))
        observe(logisticPrediction, d)
      })

      query.add(["predictive","generic", p, k], expectation(logisticPrediction) )
    })

  })

  query.add(["param", "beta", "intercept", "NA"], bs.intercept)
  query.add(["param", "beta", "prevalence", "NA"], bs.prevalence)
  query.add(["param", "beta", "cue", "NA"], bs.cue)
  query.add(["param", "sigma", "NA", "NA"], sigma)

  return query
}

var mhiter = 2000;

var burn = mhiter / 2;

var outfile = 'results-regression-'+ mhiter+'_burn'+burn+'_chain'+chain+'.csv'

var posterior = Infer({
  model: regression,
  method: "MCMC",
	kernel: {
		HMC: {
			steps: 5, stepSize: 0.004
		}
	},
	// method: "incrementalMH",
  samples: mhiter, burn: burn,
  verbose: T,
  // verboseLag: mhiter / 20,
	// stream: {
	// 	path: "results/" + outfile,
	// 	header: ["type", "param", "property", "category", "val"]
	// }
})

utils.writeQueryERP(posterior, "results/" + outfile,
	["type", "param", "property", "category", "val"])


display("written to " + outfile)
