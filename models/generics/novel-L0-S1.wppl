// time ~/webppl-fork/webppl novel-L0-S1.wppl --require utils 0

var chain = last(process.argv) // load index as last command line index

// var targetUtterance = "some";
// var targetUtterance = "most";
// var targetUtterance = "all";
var targetUtterance = "generic";
var responseDictionary = { "Agree": 1, "Disagree": 0 };

var utterancePrior = Infer({model: function(){return uniformDraw([targetUtterance,"silence"])}});

var meaning = function(utt,state, theta) {
  return utt=="generic"? state > theta :
         utt=="generic is false"? state<=theta :
         utt=='silence'? true :
         utt=='some'? state>0:
         utt=='most'? state>= 0.5:
         utt=='all'? state >= 0.99:
         true
}

var dataPath = "../../data/unfamiliar_generics/"

var interpretationsDataFile = dataPath + "interpretations-trials.csv"
var truthJudgmentDataFile = dataPath + "truth-conditions-2-trials.csv"
var priorDataFile = dataPath + "unfamiliar-priors.csv"


var d0 = dataFrame(utils.readCSV(priorDataFile).data,
			["prevAcross", "prevWithin"]);
var d1 = dataFrame(utils.readCSV(interpretationsDataFile).data,
 			["response"]);
var d2 = dataFrame(utils.readCSV(truthJudgmentDataFile).data,
 			["stim_prevalence"]);

var data = {
	prior: map(function(d){
		extend(d, {
			roundedAcross: avoidEnds(d.prevAcross),
			roundedWithin: avoidEnds(d.prevWithin),
		})
	}, d0.slice(0, d0.length - 1)),
	listener: filter(function(d){
		d.roundedPrevalence != midBins[0] // 1 response was exactly 0 (which is literally impossible)
	}, map(function(d){
		extend(d, {
			roundedPrevalence: utils.closest(midBins,d.response)
		})
	}, d1.slice(0, d1.length - 1))),
	speaker: map(function(d){
		extend(d, {
			roundedPrevalence: utils.closest(midBins, d.stim_prevalence/100),
			binaryResponse: responseDictionary[d.response]
		})
	}, d2.slice(0, d2.length - 1))
};

var items = levels(data.prior, "stim_property");

var model = function(){

	var speakerOptimality = {
		s1: uniformDrift({a:0,b:20,r:2})
	};

	foreach(items, function(item){

		var propertyData = {
			prior: _.filter(data.prior, {stim_property: item}),
			listener: _.filter(data.listener, {stim_property: item}),
			speaker: _.filter(data.speaker, {stim_property: item})
		}

		var priorParams = {
			across: {
				g: uniform({a: 0, b: 1, width: 0.2}),
				d: uniform({a: 0, b: 100, width: 5})
			},
			within: {
			g: uniform({a: 0, b: 1, width: 0.2}),
			d: uniform({a: 0, b: 100, width: 5})
		}};

		var shapeParams = {
			across: betaShape(priorParams.across),
			within: betaShape(priorParams.within)
		};

		var nullParams = {a:1,b:100}
		// var shapeParams = {
		// 	across: {
		// 		a: uniformDrift({a: 1, b: 100, width: 2}),
		// 		b: uniformDrift({a: 1, b: 100, width: 2})
		// 	},
		// 	within: {
		// 		a: uniformDrift({a: 1, b: 100, width: 2}),
		// 		b: uniformDrift({a: 1, b: 100, width: 2})
		// 	}
		// };

		mapData({data: propertyData.prior}, function(d){
			observe(Beta(shapeParams.across), d.roundedAcross);
			observe(Beta(shapeParams.within), d.roundedWithin);
		});

		// var theta = beta(priorParams.across);
		query.add(["prior","isPresent", item, "na"], beta(shapeParams.across))
		query.add(["prior","prevalenceGivenPresent", item, "na"],
		 beta(shapeParams.within))

		var statePrior = Infer({model: function(){
			var theta = sample(DiscretizedBeta(shapeParams.across));
			sample(flip(theta) ? DiscretizedBeta(shapeParams.within) : DiscretizedBeta(nullParams))
 		}});

		/// RSA model
		var listener0 = cache(function(utterance) {
			Infer({model: function(){
				var state = sample(statePrior)
				var theta = targetUtterance === "generic" ? sample(thetaPrior) : -99;
				var m = meaning(utterance, state, theta)
				condition(m)
				// factor(Math.log(state))
				return state
		 }})}, 10000)

		var speaker1 = cache(function(state) {
			Infer({model: function(){
				var utterance = sample(utterancePrior);
				var L0 = listener0(utterance);
				factor(speakerOptimality.s1 * L0.score(state))
				return utterance == targetUtterance ? 1 : 0
		}})}, 10000)

		var l0prediction = listener0(targetUtterance);

		mapData({data: propertyData.listener}, function(d){
			// display(d.roundedPrevalence + " " + l0prediction.score(d.roundedPrevalence))
			observe(l0prediction, d.roundedPrevalence)
		})

		query.add(["predictive","listener",targetUtterance, item], expectation(l0prediction) )

		var frequencies = levels(propertyData.speaker, "roundedPrevalence");

		foreach(frequencies, function(freq){

			var frequencyData = _.filter(propertyData.speaker, {roundedPrevalence: freq});
			var s1prediction = speaker1(freq);

			mapData({data: frequencyData}, function(d){
				observe(s1prediction, d.binaryResponse)
			})

			query.add(["predictive","speaker", freq, item], expectation(s1prediction) )

		})

	})

	query.add(["param","speakerOptimality","s1","na"], speakerOptimality.s1)
	return query
}

var mhiter = 100;
var burn = mhiter / 2;

var outfile = 'results-novelL0-S1-allowUPriors-'+'smtncs'+targetUtterance+"-"+ mhiter+'_burn'+burn+'_chain'+chain+'.csv'

var posterior = Infer({
  model: model,
  method: "incrementalMH",
  samples: mhiter, burn: burn,
  verbose: T,
  verboseLag: mhiter / 20,
	stream: {
		path: outfile,
		header: ["type", "param", "property", "category", "val"]
	}
})

// utils.writeQueryERP(posterior, "results/" + outfile,
// 	["type", "param", "property", "category", "val"])

display("written to " + outfile)
