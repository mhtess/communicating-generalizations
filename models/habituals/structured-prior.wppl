// time ~/webppl-fork/webppl structured-prior.wppl --require utils 1

var chain = last(process.argv) // load index as last command line index

var intervals = {
	"week": 52,
	"month": 12,
	"year": 1,
	"5 years": 1/5
};

var dataPath = "data/"
var priorFile = dataPath + "friends-and-family-1-trials.csv";

var d0 = dataFrame(utils.readCSV(priorFile).data, ["n_times"]);

var data = {
		prior: map(function(d){
			var annualRate = intervals[d.interval] * d.n_times;
			return extend(d, {
					annualRate: annualRate,
					logAnnualRate: annualRate == 0 ? -99 : Math.log(annualRate),
					roundedRate: utils.closest(midBins, annualRate)
				})
			}, d0.slice(0, d0.length -1))
};

var items = levels(data.prior, "action");
// display(items)
var model = function(){

	var nullDist = Delta({v: -99})
	var alpha = sample(Gamma({shape: 2, scale: 1}), {
		driftKernel: function(prevVal){
			  return Gamma({shape: prevVal, scale: 1});
	}});

	foreach(items, function(i){

		var itemData = _.filter(data.prior, {action: i})

		var theta = uniformDrift({a: 0, b: 1, width: 0.1});

		var priorParams = {
			mu: uniformDrift({a: -2, b: 8, width: 0.5}),
			sigma: uniformDrift({a: 0, b: 10, width: 0.5})
		}

		var statePrior = Infer({model: function(){
			sample(
				flip(theta) ?
					DiscretizedLognormal(priorParams) :
					Delta({v: _.min(midBins)})
				)
			}
		})

		var scaledPrior = Categorical({
			vs: statePrior.support(),
			ps: normalize(map(function(s){
				return Math.pow(exp(statePrior.score(s)), alpha)
			}, statePrior.support()))
		})

		mapData({data: itemData}, function(d){
			// display(scaledPrior.score(d.roundedRate))
			observe(scaledPrior, d.roundedRate)
		})

		query.add(["prior", i, "theta"], theta)
		query.add(["prior", i, "mu"], priorParams.mu)
		query.add(["prior", i, "sigma"], priorParams.sigma)

	})

	query.add(["prior", "global", "alpha"], alpha)

	return query
}

var totalIterations = 50000, lag = 5;
var mhiter = totalIterations/lag, burn = totalIterations / 2;
var outfile = 'results-habituals-prior-ffPriorStructuredDelta-SoftmaxDiscretized-'+ totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv'

var posterior = Infer({
  model: model,
  method: "incrementalMH",
  samples: mhiter, burn: burn, lag: lag, verbose: T, verboseLag: totalIterations/20,
	stream: {
		path: "results/" + outfile,
		header: [
			"type", "item", "param", "val"
		]
	}
})

display("written to " + outfile)
