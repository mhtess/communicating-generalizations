// time ~/webppl-fork/webppl habituals-S1.wppl --require utils 1

var chain = last(process.argv) // load index as last command line index

var responseDictionary = { "agree-key": 1, "disagree-key": 0 };


var dataPath = "data/"
var targetUtterance = "habitual"

var prior_existenceFile = dataPath + "prior2-existence.csv";
var prior_waitFile = dataPath + "prior2-timesper5yr.csv";
var truthJudgmentDataFile = dataPath+"tj-2-logtimes.csv";
// var priorDataFile = dataPath + "prior2.csv";

var d0 = dataFrame(utils.readCSV(prior_existenceFile).data, ["val"]);
var d1 = dataFrame(utils.readCSV(prior_waitFile).data, ["val", "logval"]);
var d2 = dataFrame(utils.readCSV(truthJudgmentDataFile).data,
				["n_times", "log_times"]);
// var d3 = dataFrame(utils.readCSV(priorDataFile).data,
// ["mixture_male", "mixture_female",
// "dayRate_male","dayRate_female",
// "annualRate_male","annualRate_female"]);



var data = {
	speaker: map(function(d){
			extend(d, {
				// rate: d.n_times / 5,
				// roundedRate: utils.closest(midBins, d.n_times / 5),
				rate: Math.log(d.n_times / 5),
				roundedRate: utils.closest(midBins,
					Math.log(d.n_times / 5)),
				alignedResponse : responseDictionary[d.response]
			})
		}, d2.slice(0, d2.length - 1)),
		prior: {
			mixture: map(function(d){
					extend(d, {
						avoided_endval: avoidEnds(d.val)
					})
			}, d0.slice(0, d0.length - 1)),
			frequency: map(function(d){
				return extend(d, {
					logAnnualRate: d.val == 0 ?
					Math.log(1 / 5) :
					Math.log(d.val/5)
				})
			}, d1.slice(0, d1.length - 1))
		}
};

// console.log()
//
var items = levels(data.speaker, "habitual");
// var genders = levels(data.prior.existence, "gender");
// var priorQuestions = ["Q1","Q2"];
//
var utterancePrior = Infer({model: function(){
	return uniformDraw([targetUtterance,"silence"])
}});


// var thetaPrior = Infer({model: function(){
// 	return uniformDraw(bins.threshold)}
// });

var meaning = function(utt,state, theta) {
  return utt=="habitual"? state > theta :
         utt=="habitual is false"? state<=theta :
         utt=='silence'? true :
         utt=='some'? state > 0 :
         true
}

// _.uniqBy(map(function(x){
// 	_.pick(x, ["time_period", "roundedRate"])
// }, data.speaker), "time_period")
//
var model = function(){

	var speakerOptimality = {
		s1: uniformDrift({a: 0, b: 20, width:2})
	}

	var nullDist = Delta({v: _.min(midBins)})

	// var nullParams = {
	// 	mu: uniformDrift({a: -4, b:  0, width: 1}),
	// 	sigma: uniformDrift({a: 0, b: 2, width: 0.2})
	// }

	// var c = uniformDrift({a: 0 , b: 1, width: 0.1});
	//
	// var utterancePrior = Infer({model: function(){
	// 	return flip(c) ? "habitual" : "silence"//"habitual is false"
	// }});


	foreach(items, function(i){

		var itemData = {
			speaker: _.filter(data.speaker, {habitual: i}),
			prior: {
				mixture: _.filter(data.prior.mixture, {item: i}),
				frequency: _.filter(data.prior.frequency, {item: i})
			}
		};

		// prior parameters
		/// mixture component

		var mixtureParams = {
			male: {
        g: uniformDrift({a: 0, b: 1, width: 0.2}),
        d: uniformDrift({a: 0, b: 100, width: 5})
      },
			female: {
        g: uniformDrift({a: 0, b: 1, width: 0.2}),
        d: uniformDrift({a: 0, b: 100, width: 5})
      }
		};

		var mixtureShapes = {
			male: betaShape(mixtureParams.male),
			female: betaShape(mixtureParams.female)
		};

		mapData({data: itemData.prior.mixture}, function(d){
			observe(Beta(mixtureShapes[d.gender]), d.avoided_endval)
		})
		query.add(["prior", i, "mixture", "male", "mean"], mixtureParams.male.g);
		query.add(["prior", i, "mixture", "male", "samplesize"], mixtureParams.male.d);
		query.add(["prior", i, "mixture", "female", "mean"], mixtureParams.female.g);
		query.add(["prior", i, "mixture", "female", "samplesize"], mixtureParams.female.d);

		var frequencyWhenPresent = {
			male: {
				mu: uniformDrift({a: 0, b:10, width: 2}),
				sigma: uniformDrift({a:0, b:5, width: 1})
			},
			female: {
				mu: uniformDrift({a:0, b:10, width: 2}),
				sigma: uniformDrift({a:0, b:5, width: 1})
			}
		}

		mapData({data: itemData.prior.frequency}, function(d){
			observe(Gaussian(frequencyWhenPresent[d.gender]), d.logAnnualRate)
		})

		query.add(["prior", i, "stableFreq", "male", "mean"], frequencyWhenPresent.male.mu);
		query.add(["prior", i, "stableFreq", "male", "samplesize"], frequencyWhenPresent.male.sigma);
		query.add(["prior", i, "stableFreq", "female", "mean"], frequencyWhenPresent.female.mu);
		query.add(["prior", i, "stableFreq", "female", "samplesize"], frequencyWhenPresent.female.sigma);


		var existenceProb = {
			male: beta(mixtureShapes.male),
			female: beta(mixtureShapes.female)
		};

		var marginalFrequency = sample(
			flip(0.5) ?
				flip(existenceProb.female) ?
					Gaussian(frequencyWhenPresent.female) :
					nullDist :
				flip(existenceProb.male) ?
					Gaussian(frequencyWhenPresent.male) :
					nullDist
				)

		query.add(["prior", i, "marginalFreq", "NA", "NA"], marginalFrequency);


		// query.add(["prior", i, mixtureShapes.male.a], [
		// 	mixtureShapes.male.b,
		// 	mixtureShapes.female.a, mixtureShapes.female.b,
		// 	frequencyWhenPresent.male.mu, frequencyWhenPresent.male.sigma,
		// 	frequencyWhenPresent.female.mu, frequencyWhenPresent.female.sigma
		// ])
		//
		// query.add(["prior","mixture_a", i, "male"], mixtureShapes.male.a)
		// query.add(["prior","mixture_b", i, "male"], mixtureShapes.male.b)
		// query.add(["prior","mixture_a", i, "female"], mixtureShapes.female.a)
		// query.add(["prior","mixture_b", i, "female"], mixtureShapes.female.b)
		// query.add(["prior","freq_mu", i, "male"], frequencyWhenPresent.male.mu)
		// query.add(["prior","freq_sigma", i, "male"], frequencyWhenPresent.male.sigma)
		// query.add(["prior","freq_mu", i, "female"], frequencyWhenPresent.female.mu)
		// query.add(["prior","freq_sigma", i, "female"], frequencyWhenPresent.female.sigma)

		// query.add(["prior", i, "predictive", "mixture", "male"], existenceProb.male);
		// query.add(["prior", i, "predictive", "mixture", "female"], existenceProb.female);
		// query.add(["prior", i, "predictive", "frequency", "male"], freqWhenPresent.male);
		// query.add(["prior", i, "predictive", "frequency", "female"], freqWhenPresent.female);

		// var statePrior = Infer({model: function(){
		// 	sample(
		// 		flip(0.5) ?
		// 			flip(existenceProb.female) ?
		// 				DiscretizedLognormal(frequencyWhenPresent.female) :
		// 				DiscretizedLognormal(nullParams) :
		// 			flip(existenceProb.male) ?
		// 				DiscretizedLognormal(frequencyWhenPresent.male) :
		// 				DiscretizedLognormal(nullParams)
		// 			)
		// 		}
		// 	})

	var statePrior = Infer({model: function(){
		sample(
			flip(0.5) ?
				flip(existenceProb.female) ?
					DiscretizedGaussian(frequencyWhenPresent.female) :
					nullDist :
				flip(existenceProb.male) ?
					DiscretizedGaussian(frequencyWhenPresent.male) :
					nullDist
				)
			}
		})

		/// RSA model
		var listener0 = cache(function(utterance) {
		  Infer({model: function(){
		    var state = sample(statePrior)
				var theta = sample(thetaPrior);
		    var m = meaning(utterance, state, theta)
		    condition(m)
		    return state
		 }})}, 10000)

		var speaker1 = cache(function(freq) {
			Infer({model: function(){
		    var utterance = sample(utterancePrior);
		    var L0 = listener0(utterance);
		    factor(speakerOptimality.s1 * L0.score(freq))
		    return utterance === targetUtterance ? 1 : 0
			}})}, 10000)

		var observedFrequencies = levels(itemData.speaker, "roundedRate");

		foreach(observedFrequencies, function(freq){

			var freqData = _.filter(itemData.speaker, {roundedRate: freq});
			// var responseData = _.map(freqData, "alignedResponse");
			var s1prediction = speaker1(freq);
			// display(map(function(s){return [s, s1prediction.score(s)]},
			//  s1prediction.support()))

			mapData({data:freqData}, function(d){
				// display(d)
				// display("speaker score = " + s1prediction.score(d.alignedResponse))
				observe(s1prediction, d.alignedResponse)
			})

			// query.add(["predictive", i, freqData[0]["time_period"]], [
			// 	freq, "s2", expectation(s2prediction),
			// 	"NA",  "NA",  "NA",  "NA" ])

			query.add(["predictive", i, "s1", freqData[0]["time_period"], freq], expectation(s1prediction));

				// query.add(["predictive", i, freqData[0]["time_period"],freq], expectation(s1prediction))


		})

	})

	// query.add(["param","speakerOptimality","s1","na"], speakerOptimality.s1)
		query.add(["param","speakerOptimality","s1","NA", "NA"], speakerOptimality.s1)

		// query.add(["param","habUttPrior","NA","NA", "NA"], c)

		// var nullPred = gaussian(nullParams);

		// query.add(["param","nullDistribution","predictive","NA", "NA"], nullPred)

	// query.add(["param", "speakerOptimality", "s1"], [
	// 	 speakerOptimality.s1, "NA", "NA",
	// 	"nullParams_mu",  nullParams.mu,
	// 	"nullParams_sigma",  nullParams.sigma])

	return query
}

var totalIterations = 100000, lag = 50;
var mhiter = totalIterations/lag, burn = totalIterations;
var outfile = 'results-habituals-S1-decomposedPrior-normalPrior-'+ totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv'

var posterior = Infer({
  model: model,
  method: "incrementalMH",
  samples: mhiter, burn: burn, lag: lag,
  verbose: T, verboseLag: totalIterations / 100,
	stream: {
		path: "results/" + outfile,
		header: [
			"type", "B", "C", "D", "E", "val"
		]
	}
})

display("written to " + outfile)
//
// _.filter(
// 	data.prior.frequency, {val:0 })
