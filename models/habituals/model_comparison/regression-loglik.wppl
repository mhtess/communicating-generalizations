// time ~/webppl-fork/webppl regression-loglik.wppl --require ../node_modules/utils 1

var chain = last(process.argv) // load index as last command line index

var responseDictionary = { "agree-key": 1, "disagree-key": 0 };
var intervals = {
	"week": 52,
	"2 weeks": 26,
	"month": 12,
	"2 months": 6,
	"6 months": 2,
	"year": 1,
	"2 years": 1/2,
	"5 years": 1/5
};


var dataPath = "../data/"
var targetUtterance = "habitual"

var priorFile = dataPath + "friends-and-family-2-trials.csv";
var truthJudgmentDataFile = dataPath+"tj-2-logtimes.csv";

var d0 = dataFrame(utils.readCSV(priorFile).data, ["n_times"]);
var d2 = dataFrame(utils.readCSV(truthJudgmentDataFile).data, ["n_times", "log_times"]);

var data = {
	speaker: map(function(d){
			extend(d, {
				// rate: d.n_times / 5,
				// roundedRate: utils.closest(midBins, d.n_times / 5),
				rate: Math.log(d.n_times / 5),
				roundedRate: utils.closest(midBins, Math.log(d.n_times / 5)),
				alignedResponse : responseDictionary[d.response]
			})
		}, d2.slice(0, d2.length - 1)),
		prior: map(function(d){
			var annualRate = intervals[d.interval] * d.n_times
				return extend(d, {
					annualRate: annualRate,
					logAnnualRate: annualRate == 0 ? -99 : Math.log(annualRate),
					roundedRate: utils.closest(midBins, annualRate)
				})
			}, d0.slice(0, d0.length -1))
};

var items = levels(data.prior, "action");

var logisticFunction = function(y) {
   return 1 / (1 + exp(-y));
};

var globalParamPriors = {
	intercept: Uniform({a: -5, b: 0}),
	freq: Uniform({a: -5, b: 5}),
	priorMean: Uniform({a: -5, b: 5})
}

var model = function(){

	var bs = {
    intercept: sample(globalParamPriors.intercept),
    freq: sample(globalParamPriors.freq),
    priorMean: sample(globalParamPriors.priorMean)
  }

	var globalLatentLike = globalParamPriors.intercept.score(bs.intercept) +
													globalParamPriors.freq.score(bs.freq) +
													globalParamPriors.priorMean.score(bs.priorMean)

	// display(globalLatentLike)

	query.add(["logLikelihood", "globalLatents", "NA", "NA", "NA"], globalLatentLike)

	var linearFunction = function(xs){
     bs.intercept +
     bs.freq * xs.freq +
     bs.priorMean * xs.priorMean;
  };

	// var alpha = gamma({shape: 2, scale: 1})

	foreach(items, function(i){
		// display(i)
		var itemPriorData = _.filter(data.prior, {action: i})
		// display(itemPriorData)
    var itemData = _.filter(data.speaker, {habitual: i});
		// display(itemData)
		var theta = uniformDrift({a: 0, b: 1, width: 0.1});

		var priorParams = {
			mu: uniformDrift({a: -2, b: 8, width: 0.5}),
			sigma: uniformDrift({a: 0, b: 10, width: 0.5})
		}

		var itemPriorLike = Uniform({a:0, b:1}).score(theta) +
												Uniform({a:-2, b:8}).score(priorParams.mu) +
												Uniform({a:0, b:10}).score(priorParams.sigma)

		var statePrior = Infer({model: function(){
			sample(
				flip(theta) ?
					DiscretizedGaussian(priorParams) :
					Delta({v: _.min(midBins)})
				)
			}
		})

		// var scaledPrior = Categorical({
		// 	vs: statePrior.support(),
		// 	ps: normalize(map(function(s){
		// 		return Math.pow(exp(statePrior.score(s)), alpha)
		// 	}, statePrior.support()))
		// })

    // displayObj(statePrior)
		mapData({data: itemPriorData}, function(d){
			// display(scaledPrior.score(d.roundedRate))
			// observe(scaledPrior, d.roundedRate)
			observe(statePrior, d.roundedRate)
		})


		// query.add(["prior", i, "theta","NA", "NA"], theta)
		// query.add(["prior", i, "mu","NA", "NA"], priorParams.mu)
		// query.add(["prior", i, "sigma","NA", "NA"], priorParams.sigma)

		// var logMeanPriorFreq = Math.log(expectation(statePrior));
		var logMeanPriorFreq = expectation(statePrior);
		// displayObj(bs)
		// display(logMeanPriorFreq)
		// display(freq)
		var regressionSpeaker = cache(function(freq){
			return Infer({model: function(){
		  var habitual = flip(Math.exp(bs.intercept));
		  factor( habitual ?
				(bs.priorMean*logMeanPriorFreq + bs.freq*freq) :
				0
			)
		  return habitual ? 1 : 0
		}})})

		var observedFrequencies = levels(itemData, "roundedRate");

		var itemLogLike = sum(map(function(freq){

			var freqData = _.filter(itemData, {roundedRate: freq});
      // display(freqData)
			var regressionPrediction = regressionSpeaker(freq);
      // displayObj(s1prediction)

      var logLike = sum(map(function(d){
				// display(regressionPrediction.score(d.alignedResponse))
        return regressionPrediction.score(d.alignedResponse)
      }, freqData))

      return logLike

		}, observedFrequencies))

		var itemMarginalLike = itemLogLike + itemPriorLike

    // display(i + " --> " + itemLogLike)

    query.add(["logLikelihood", i, "regression","NA", "NA"], itemMarginalLike)

	})

	// query.add(["param", "beta", "intercept","NA", "NA"], bs.intercept)
	// query.add(["param", "beta", "freq","NA", "NA"], bs.freq)
	// query.add(["param", "beta", "priorMean","NA", "NA"], bs.priorMean)
	// query.add(["param","alpha","NA","NA", "NA"], alpha)


	return query
}

// items

var totalIterations = 200000, lag = 20;
var mhiter = totalIterations/lag, burn = totalIterations / 2;
var outfile = 'logLikelihood-withPrior-habituals-regression-softmaxPrior-intercept-freq-priorMean-ffPrior2Structured-'+ totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv'

var posterior = Infer({
  model: model,
  method: "incrementalMH",
  samples: mhiter, burn: burn, lag: lag, verbose: T,
	verboseLag: totalIterations/50,
	stream: {
		path: "results/" + outfile,
		header: [
			"type", "item", "cat", "param", "gender", "val"
		]
	}
})

display("written to " + outfile)
