// time ~/webppl-fork/webppl S1-structuredPriorData-loglik.wppl --require ../node_modules/utils 1

var chain = last(process.argv) // load index as last command line index

var responseDictionary = { "agree-key": 1, "disagree-key": 0 };
var intervals = {
	"week": 52,
	"2 weeks": 26,
	"month": 12,
	"2 months": 6,
	"6 months": 2,
	"year": 1,
	"2 years": 1/2,
	"5 years": 1/5
};


var dataPath = "../data/"
var targetUtterance = "habitual"

var prior_existenceFile = dataPath + "prior2-existence.csv";
var prior_waitFile = dataPath + "prior2-timesper5yr.csv";var truthJudgmentDataFile = dataPath+"tj-2-logtimes.csv";

var d0 = dataFrame(utils.readCSV(prior_existenceFile).data, ["val"]);
var d1 = dataFrame(utils.readCSV(prior_waitFile).data,
					["val", "logval"]);
var d2 = dataFrame(utils.readCSV(truthJudgmentDataFile).data,
				["n_times", "log_times"]);

var data = {
	speaker: map(function(d){
			extend(d, {
				// rate: d.n_times / 5,
				// roundedRate: utils.closest(midBins, d.n_times / 5),
				rate: Math.log(d.n_times / 5),
				roundedRate: utils.closest(midBins, Math.log(d.n_times / 5)),
				alignedResponse : responseDictionary[d.response]
			})
		}, d2.slice(0, d2.length - 1)),
		prior: {
			mixture: map(function(d){
					extend(d, {
						avoided_endval: avoidEnds(d.val)
					})
			}, d0.slice(0, d0.length - 1)),
			frequency: filter(function(d){
				d.val != 0
			}, map(function(d){
				var annualRate = d.val / 5;
				extend(d, {
					annualRate: annualRate,
					logAnnualRate: Math.log(annualRate)
				})
			}, d1.slice(0, d1.length - 1)))
		}
};

var items = levels(data.prior.mixture, "item");

var utterancePrior = Infer({model: function(){
	return uniformDraw([targetUtterance,"silence"])
}});

var meaning = function(utt,state, theta) {
 return utt=="habitual"? state > theta :
        utt=="habitual is false"? state <= theta :
				 utt=="opposite habitual"? state < theta :
         utt=='silence'? true :
         utt=='some'? state > 0 :
         true
}


var model = function(){

	var speakerOptimality = {
		s1: uniform({a: 0, b: 5})
	}
	var contamination = uniform({a: 0, b: 1});

	var globalLatentLike = Uniform({a: 0, b: 5}).score(speakerOptimality.s1)+
	Uniform({a: 0, b: 1}).score(contamination)

	// query.add(["logLikelihood", "globalLatents", "NA", "NA", "NA"], globalLatentLike)

	var nullDist = Delta({v: -99})


	foreach(items, function(i){

		var itemData = {
			speaker: _.filter(data.speaker, {habitual: i}),
			prior: {
				mixture: _.filter(data.prior.mixture, {item: i}),
				frequency: _.filter(data.prior.frequency, {item: i})
			}
		};
		// displayObj(itemData)

		var mixtureParams = {
			male: {
        g: uniformDrift({a: 0, b: 1, width: 0.2}),
        d: uniformDrift({a: 0, b: 100, width: 5})
      },
			female: {
        g: uniformDrift({a: 0, b: 1, width: 0.2}),
        d: uniformDrift({a: 0, b: 100, width: 5})
      }
		};

		var mixtureShapes = {
			male: betaShape(mixtureParams.male),
			female: betaShape(mixtureParams.female)
		};

		mapData({data: itemData.prior.mixture}, function(d){
			// Beta(mixtureShapes[d.gender]).score(d.avoided_endval) == -Infinity ? display(JSON.stringify(d) + Beta(mixtureShapes[d.gender]).score(d.avoided_endval)) : null
			observe(Beta(mixtureShapes[d.gender]), d.avoided_endval)
		})

		var frequencyWhenPresent = {
			male: {
				mu: uniformDrift({a: -2, b: 8, width: 0.5}),
				sigma: uniformDrift({a:0, b:5, width: 0.5})
			},
			female: {
				mu: uniformDrift({a: -2, b: 8, width: 0.5}),
				sigma: uniformDrift({a:0, b:5, width: 0.5})
			}
		}

		mapData({data: itemData.prior.frequency}, function(d){
			// Gaussian(frequencyWhenPresent[d.gender]).score( d.logAnnualRate) == -Infinity ? display(JSON.stringify(d) + Gaussian(frequencyWhenPresent[d.gender]).score( d.logAnnualRate)) : null
			observe(Gaussian(frequencyWhenPresent[d.gender]), d.logAnnualRate)
		})

		var existenceProb = {
			male: beta(mixtureShapes.male),
			female: beta(mixtureShapes.female)
		};

		var statePrior = Infer({model: function(){
			sample(
				flip(0.5) ?
					flip(existenceProb.female) ?
						DiscretizedGaussian(frequencyWhenPresent.female) :
						Delta({v: _.min(midBins)}) :
					flip(existenceProb.male) ?
						DiscretizedGaussian(frequencyWhenPresent.male) :
						Delta({v: _.min(midBins)})
					)
				}
			})

			var freqWhenPresent = {
				male: gaussian(frequencyWhenPresent.male),
				female: gaussian(frequencyWhenPresent.female)
			};

			// query.add(["prior", i, "predictive", "mixture", "male"], existenceProb.male);
			// query.add(["prior", i, "predictive", "mixture", "female"], existenceProb.female);
			// query.add(["prior", i, "predictive", "frequency", "male"], freqWhenPresent.male);
			// query.add(["prior", i, "predictive", "frequency", "female"], freqWhenPresent.female);
/// RSA model
		var listener0 = cache(function(utterance) {
		  Infer({model: function(){
		    var state = sample(statePrior)
				var theta =  sample(thetaPrior)
		    var m = meaning(utterance, state, theta)
		    condition(m)
		    return state
		 }})}, 10000)

		var speaker1 = cache(function(freq) {
			Infer({model: function(){
		    var utterance = sample(utterancePrior);
		    var L0 = listener0(utterance);
		    factor(speakerOptimality.s1 * L0.score(freq))
		    return utterance === targetUtterance ? 1 : 0
			}})}, 10000)

		var observedFrequencies = levels(itemData.speaker, "roundedRate");
    // display(observedFrequencies)

		var itemLogLike = sum(map(function(freq){

			var freqData = _.filter(itemData.speaker, {roundedRate: freq});
      // display(freqData)
			var s1prediction = speaker1(freq);
      // displayObj(s1prediction)
			var s1predictionWithNoise = addNoise(s1prediction, contamination);

      var logLike = sum(map(function(d){
        // display(s1prediction.score(d.alignedResponse))
        return s1predictionWithNoise.score(d.alignedResponse)
      }, freqData))

      return logLike

		}, observedFrequencies))
    // display(i + " --> " + itemLogLike)

    query.add(["logLikelihood", i, "NA","NA", "NA"], itemLogLike)

	})

	// query.add(["param","speakerOptimality","s1","NA", "NA"], speakerOptimality.s1)

	// var nullPred = gaussian(nullParams);
	//
	// query.add(["param","nullDistribution","predictive","NA", "NA"], nullPred)

	return query
}
// 1000 total Iter in 1.5 minutes
var totalIterations = 1000, lag = 20;
var mhiter = totalIterations/lag, burn = totalIterations / 2;
var outfile = 'logLikelihood-habituals-S1-structuredPriorData-logSpace-silenceAlt-wContamination-'+ totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv';

var posterior = Infer({
  model: model,
  method: "incrementalMH",
  samples: mhiter, burn: burn, lag: lag, verbose: T,
	verboseLag: totalIterations/50,
	stream: {
		path: "results/" + outfile,
		header: [
			"type", "item", "cat", "param", "gender", "val"
		]
	}
})

display("written to " + outfile)

// midBins
