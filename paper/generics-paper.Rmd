---
title             : "Communicating generalizations about categories, events, and causes"
shorttitle        : "Communicating generalizations"

author: 
  - name          : "Michael Henry Tessler"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Serra Mall, Bldg. 420, Rm. 316, Stanford, CA 94305"
    email         : "mtessler@stanford.edu"
  - name          : "Noah D. Goodman"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
    
header-includes:
  - \usepackage{tabularx}
  - \usepackage{multicol}
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{booktabs}

author_note: >
  Enter author note here.

abstract: > 
    Generalizations are central to human understanding yet can be difficult to acquire through direct experience (e.g., learning that a plant is poisonous).
    Language provides simple ways to convey generalizations (e.g., *Birds fly.*), and the language of generalizations is ubiquitous in everyday discourse and child-directed speech.
    Yet the meaning of these expressions is philosophically puzzling (e.g., not all birds fly) and has resisted precise formalization.
    One major issue in formalizing *genericity* is that such language is extremely flexible in its usage. 
    Using a state-of-the-art probabilistic model of pragmatic reasoning, we explore the hypothesis that the meaning of such linguistic expressions is *simple but underspecified*, and that general communicative principles can be used to establish a more precise meaning in context. 
    To test this theory, we examine endorsements of generalizations about three different domains: generalizations about events (i.e., *habitual language*, e.g., *John runs*), causes (i.e., *causal language*, e.g., *The block makes the machine play music.*), and categories (i.e., *generic language*, e.g., *Birds fly*), and find that the model, and not simpler models, explains full spectra of endorsements of generalizations in language.
    The model suggests that central phenomena of genericity emerge from the interaction of diverse prior beliefs about properties with general communicative principles. 
  
keywords          : "genericity, generalizations, generics, pragmatics, semantics, bayesian modeling"
wordcount         : "X"

bibliography      : ["generics.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}
<!-- \newcommand{\ndg}[1]{\textcolor{Green}{$[ndg: #1 ]$}} -->
<!-- \newcommand{\mht}[1]{\textcolor{Blue}{$[mht: #1 ]$}} -->
<!-- \newcommand{\red}[1]{\textcolor{Red}{$#1$}} -->

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=6, fig.height=5, fig.crop = F, fig.path='figs/',
                      echo=FALSE, warning=FALSE, cache=F, message=FALSE, sanitize = T)

```


```{r include = FALSE}
library("papaja")
```


```{r helpers}
library(rwebppl)
library(xtable)
library(tidyverse)
library(forcats)
library(langcog)
library(tidyr)
library(dplyr)
library(data.table)
library(coda)
library(knitr)
library(ggthemes)
library(ggrepel)
library(rwebppl)
theme_set(theme_few())
estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
project.path <- "~/Documents/research/communicating-generalizations/"
options("scipen"=10) 
```

# Introduction 

Figuring out that an object tends to have a property, an entity tends to exhibit a behavior, or a cause tends to produce an effect is crucial knowledge for a cognitive agent.
We learn such *generalizations* early in life by observing instances and drawing inductive inferences [@Dewar2010].
Social learning---relying upon the human capacity to infer others' intentions---faciliates this process [@Csibra2009; @Tomasello1999; @Butler2012].
At around a child's first birthday, her mind gains access to a new, human-unique source of data: language.

<!-- give rise to the productivity of human thought and form of foundations of cultural knowledge. -->
<!-- They allow us to understand the complex world around us and dream up how possible future situations might unfold. -->
<!-- It's been suggested that were psychology to have *general laws* akin to Newtonian laws in physics, the first general law in psychology would be of generalizations [Shepard1987]. -->
<!-- Generalizations are central to human understanding.  -->
<!-- Even before birth, human and non-human animals alike gather statistical information and form generalizations to predict what will come next. -->
<!-- The human learner, perhaps uniquely in the animal kingdom, displays striking sensitivity to the intentional and pedagogical actions of others, leading to distinct and often stronger inferences from data than would otherwise be warranted from random observations. -->

Minimally, language helps foster generalization by bringing attention to non-obvious shared relations through the use of labeling [@Gelman1986; @Graham2004; @Markman1989].
But language also has the ability to refer to *generalization itself*.
At around the age of two and a half, children begin to understand that *generic language* (e.g., "Dogs bark") refers to kinds and conveys generalizations that extend beyond the here and now [@Cimpian2008].
Generic language is ubiquitous in everyday conversation as well as in child-directed speech [@Gelman2008].
It is believed that every language can express generic meaning [@Behrens2005; @Carlson1995], and that generics are central to the growth of conceptual knowledge [#Gelman2004] 
Additionally, generics are the primary way by which speakers discuss social categories, making them key to propagating stereotypes [@Gelman2004; @Rhodes2012; @Leslie2015] and impacting motivation [@Cimpian2010].
It's plausible that cultural knowledge accumulates across generations through language's ability to talk about generalizations [@Henrich2015].

Computational models of learning formalize the inferences derived from observations, focusing on the question of how children and adults generalize from sparse data [@Tenenbaum2011]. 
They showcase the role of flexibly structured representations [@Kemp2007; @Kemp2008] and assumptions learners can make about the data-generating process [e.g., learning from pedagogical actions; @Shafto2012].
Learning from language, however, is more challenging to formalize because of the inherent context-sensitivity of language [@Grice1975; @Clark1996; @Levinson2000].
Probabilistic models have recently made progress in describing pragmatic language understanding in precise terms [@Frank2012; @Goodman2013; @Goodman2016], formalizing complex linguistic phenomena ranging from politeness [@Yoon2016] and hyperbole [@Kao2014] to metaphor [@Kao2014] and vagueness [@Lassiter2013].
These models of rational communication describe inferences one can draw from language about *particular* situations: utterances that convey information about a specific entity or event.
The language of generalizations --- statements that extend beyond the here-and-now --- has heretofore eluded precise formalization.

The major issue in formalizing generic language is determining what makes a generic statement true or false. 
When we hear *Dogs bark*, we may feel it's a universal statment as in *All* dogs bark.
We may then realize that, among others, exquisitely well-trained dogs do not bark, which means the generic should signal something weaker like *Most* dogs bark.
Indeed, many generic statements seem to have the quantificational force of *most*. 
But most mosquitos do not carry malaria, while the statement *Mosquitos carry malaria* is intuitively true.
So the generic must in some way be compatible with *some* (e.g., *some mosquitos carry malaria*).
But equating the generic with *some* is too lenient: Some robins are female, but saying *Robins are female* seems odd.
Perhaps properties that only apply to one gender are an exception, but *Robins lay eggs* is intuitively true, despite the property being very similarly distributed among the population of robins as being female.

Generic statements convey generalizations about categories, but there are other linguistic devices that look different but seem to similary convey generalization.
*Genericity* can be observed when talking about categories (e.g., *Dogs bark*), people in general (e.g., *You never know what will happen on a blind date*), specific people (e.g., *Martha swims after work*), or causal events (e.g., *Drinking moonshines makes you go blind*).
Though this diverse array of utterances all seem to convey something beyond the here and now, what exactly is common to each of them is not obvious. 
Without a formal way of describing generalizations in language, we do not yet know in what ways these large swaths of language are similar. 

In this paper, we combine a probabilistic model of pragmatic reasoning with ideas from formal semantics to define the truth conditions of generalizations in language. 
By formalizing such a hypothesis in a probabilistic language understanding model, we derive predictions for endorsements of such statements by specifying relevant prior knowledge.
Across three distinct case studies, we both measure and manipulate prior knowledge, showing that it is causally related to the endorsement of generalizations in the ways predicted by our model.
<!-- We relate known measurements on factors regarding generic language to each other via our model. -->
<!-- We then go on to manipulate the relevant factors, showing they are causally related via our model to generic endorsement and interpretation.  -->
We do this in three domains: generalizations about categories, events, and causes. 
In each domain, we define a scale that corresponds to the relevant metric by which a learner should generalize. 
We show that in each domain, our general theoretical framework applies and predicts endorsements about generalizations conveyed in language, when simpler models would fail. 

The rest of this paper is organized as follows. 
In Section 1, we describe the Bayesian framework for generalization and define the scales along which generalization is measured in different domains. 
In Section 2, we formalize the hypothesis that the core of meaning of a generalization is *simple but underspecified* and incorporate this uncertain semantics into a general framework for pragmatic language understanding -- the Rational Speech Act framework.

To test our model, we examine endorsements of generalizations in three domains: categories, events, and causes.
Our model makes predictions about how endorsements should vary according to (i) the listener's world knowledge prior and (ii) the speaker's intended message (or, belief distribution) that she seeks to communicate. 
In Section 3, we describe experiments the measure both (i) and (ii) and relate it to the endorsements of generalizations about categories, or *generic language*. 
In Section 4, we describe experiments that measure (i) and manipulate (ii) to predict endorsements of generalizations about events, or *habitual language*.
In Section 5, we describe experiments that manipulate both (i) and (ii) to predict endorsements of generalizations about causes, or *causal language*. 
Across all of our experimental settings, we find a very strong agreement of our model's predictions to human elicited endorsement (cumulative $r^2(N) = 0.XX$), where simpler models fall short.
In the final section of the paper, we discuss how our model begins the process of unifying the extant psychological, linguistic, and philosophical literature on *genericity*.
Our theory also opens up a number of new directions for understanding generic language and building models that learn and think like people.

<!-- ALTERNATIVE INTRO -->


<!-- Yet, generalizations can be hard to acquire. -->
<!-- Consider what it would take to learn that under certain conditions (e.g., when eaten raw) a plant is poisonous, while under other conditions (e.g., when processed appropriately) the plant is nutritious.  -->
<!-- This is a common ecological problem and historical examples suggest that humans are not particularly good at learning such generalizations [e.g., the Australian explorers case; @Henrich2015]. -->
<!-- In this domain, the relationship to be learned (i.e., between different ways of food processing and the poisonousness of the plant) is non-obvious and trial-and-error learning is costly (negative examples entail death). -->

<!-- Crucially, once acquired, such hard-won generalizations can be communicated among humans, something which other animals struggle to accomplish [cite tomasello apes something]. -->
<!-- Generalizable knowledge can be inferred through demonstration, or in pedagogical contexts when ostensive cues are present [@Csibra].  -->
<!-- By and large, however, language provides the most flexible and generative way to communicate generalizations.  -->

<!-- A generalization provides a relation between a category and a property: It tells us to predict that property of future instances of the category [@HumeTHN]. -->
<!-- Generalization can be described as a probability and inductive inference as a probabilistic model [@Tenenbaum2011]. -->
<!-- From a very young age, children make strong inductive inferences from their experience in a way consistent with the Bayesian probability calculus [@Dewar2010; @Gelman1986; @Markman1989]. -->

<!-- If generalizations can be described by predictive probabilities, it would stand to reason that the most direct way to communicate a generalization would be to convey probability.  -->
<!-- Ironically, humans are very bad at describing and interpreting probabilities explicitly [@Tversky1974]. -->
<!-- Rather than be a deficiency, however, the difficulty we have in understanding numerical descriptions of probability might reflect the flexible adaptivity of natural language to make vague or ambiguous that which shared context can be relied upon to guide interpretation [@Piantadosi2012]. -->
<!-- If language has evolved in a way to make efficient the kinds of inductive inferences that are central to human cognition, we would expect the language of generalizations to be simple [c.f., @Leslie2008]. -->

<!-- Indeed, generalizations in language (e.g., *Dogs are friendly*, *Mary smokes cigarettes*, *Yeast makes bread rise*) are among the simplest forms of compositional expressions.  -->
<!-- Generalizations do not come in just one syntactic form: "*Dogs* are friendly", "*A library book* should be treated with respect", "*The contemporary foodie* seeks culinary experinces in menu-less restaurants and grandmothers' kitchens" [@Carlson1995; @NickelBlackwell; @sepGenerics]. -->
<!-- Each of these statements has in common the fact that they predicate a property of a category and the properties themselves apply to instances of the category (unlike, e.g., *Dinosaurs are extinct* because being extinct is not a property that can be true of a particular dinosaur).  -->
<!-- In this way, these statements exhibit *genericity*, or put another way, they convey generalizations. -->

<!-- In this paper, we formalize the language of generalizations with the interest is deciding what makes a generalization in language *true or false*. -->
<!-- How speakers convey generalizations and how listeners interpret them. -->

<!-- We examine three case studies of generalizations in language: Generalizations about agents, objects, and events.  -->
<!-- In Section 1, we introduce an information-theoric communicative theory of how generalizations are conveyed in language and flesh out the model's predictions alongside alternative models. -->
<!-- In order to do so, we provide a unified mathematical framework for dealing with agents, objects, and events, casting each as a category over which generalization can occur. -->
<!-- Our model predicts the endorsements of generalizations should vary with the (A) the probability of an instances having the property and (B) the prior distribution over the property probability (e.g., how likely instances of other categories are to have the property). -->
<!-- In Section 2, we introduce our empirical paradigm which we use to measure endorsement and interpretation of linguisitic generalizations, examining generalizations about *agents* in what is known as *habitual language* (e.g., "Mary smokes cigarettes.").  -->
<!-- In Section 3, we extend our paradigm to generalizations about *events* (i.e., *causal language* e.g., "Yeast makes bread rise.") and experimentally manipulate participants' background knowledge, showing that prior beliefs about probabilities are causally related to endorsement and interpretation of generalizations. -->
<!-- In Section 4, we use our paradigm to address long-standing theoretical and empirical puzzles regarding generalizations about *objects*, so-called *generic language*.  -->
<!-- We show our how model explains three known psychological puzzles surrounding generic language.  -->
<!-- In all case studies, we provide formal comparison to simpler models and in all cases, find that only our communicative theory explains the patterns of empirical data. -->
<!-- We conclude with a general discussion about the relationship of our theory to extant theories in the psychology, linguistics, and philosophy of genericity, and highlight the implications for modeling language acquisition, conceptual development, and other avenues of research that this framework opens. -->


<!-- the truth conditions of generalizations of events (so called *habitual language*) by manipulating the target propensity (A) while surveying a wide variety of events (which should induce variability in B). -->
<!-- In Section 3, we manipulate both (A) and (B) while testing the model on generalizations about causes (*causal language*). -->
<!-- If our theory is truly a theory about communicating generalizations, it should be able to explain the known psychological puzzles surrounding *generic language* (generalizations about categories).  -->



<!-- In stark constrast, a computational understanding of communicating generalizations is not well understood at all.  -->

<!-- Gathering data and observing evidence, however, is costly.  -->
<!-- The human problem of induction even displays a complex sensitivity to not only the type of data, but how the data was generated [@Gweon2010; @Shafto2012]. -->
<!-- A learner cannot form all of her abstract knowledge through direct experience, however. -->
<!-- Life is only so long, and you can only be in one place at a time. -->






<!-- In this paper, we introduce a formal model for understanding the language of generalizations. -->
<!-- <!-- The fact that generalizations in language seem to convey something about the propensity but that there seem to be as many interpretations of generalized statements as there are generalizations have confounded formal models aimed to capture their meaning. --> -->
<!-- We take as a starting point the idea that the core meaning of a linguistic generalization is simple (i.e., it conveys something about the propensity), but underspecified (i.e., there is uncertainty in the meaning). -->
<!-- We extend a rational model of communication --- the Rational Speech Act theory --- to be able to understand general statements that extend beyond the here-and-now. -->
<!-- We provide a number of stringest tests of this theory to explain generalizations about categories, events, and causal forces.  -->



<!-- How can generalizations in language have such flexible truth conditions while simultaneously carrying intuitive and, at times, very strong implications? -->
<!-- This question has been investigated by psychologists, linguists, and philosophers since @Carlson1977. -->
<!-- Here, we provide a unified formal theory of generalizations conveyed in language. -->
<!-- We test theory on the preeminent case study of linguistic generalizations: generic language, or generalizations about categories. -->
<!--  -->
<!-- To be precise, we develop a computational model that describes pragmatic reasoning about the propensity required to assert the generaization.   -->
<!-- We find that this formalism resolves known philosophical and empirical puzzles. -->
<!--We also provide the first set of experimental results about linguistic generalizations about events and causal forces, so called *habitual* and *causal statements*.-->

<!-- and find extreme flexibility in usage, which our model predicts.  -->

<!-- In Section 2, we conduct a set of experiments to test the *truth conditions* of familiar generalizations about categories (generic statements), and find our model predicts key patterns in human judgments -->
<!-- In Section 3, we conduct a set of experiments to test *interpretations* of novel generic sentences, again finding our model predicts human judgments with high quantitative accuracy. -->
<!-- In Section 4, we begin to test the generality of the theory, examining the *truth conditions* of generalizations about events. -->
<!-- In Section 5, we further probe our theory's generality, investing the *truth conditions* and *interpretations* of novel generalizations about causal forces.  -->
<!-- In all cases, we provide formal comparison to simpler models and in all cases, find that only our communicative theory with an underspecified meaning function explains the pattern of human data. -->
<!-- We also find that the prior beliefs used in our model reflect conceptual structure, and this provides an understanding of the conceptual implications of generics. -->
<!-- Finally, we investigate the underlying semantic scale in more detail, and find that the core meaning of generalizations in language depends in a crucial way on subjective beliefs, not mere frequency. -->

<!--
Most would agree that \emph{Swans are white}, but certainly not every swan is.
This type of utterance conveys a generalization about a category (i.e. \textsc{swans}) and is known as a generic utterance [@Carlson1977; @Leslie2008].
Communicating generically about categories is useful because categories themselves are unobservable [@Markman1989].
Knowledge about categories, while central to human reasoning, is tricky to acquire because categories themselves are unobservable [Markman1989}.
It is believed that every language can express generic meaning [@Behrens2005; @Carlson1995], and that generics are essential to the growth of conceptual knowledge [@Gelman2004] and how kinds are represented in the mind [@Leslie2008].
Generic language is ubiquitous in everyday conversation as well as in child-directed speech [@Gelman2008], and children as young as two or three understand that generics refer to categories and support generalization [@Cimpian2008].
and though English and many other languages do not possess an unambiguous form devoted to generic meaning [@Behrens2000, @AlMalki2014].
Additionally, generics are the primary way by which speakers discuss social categories, making them key to propagating stereotypes [@GelmanEtAl2004; @Rhodes2012; @Leslie2015] and impacting motivation [@Cimpian2010motivation].
Despite their psychological centrality, apparent simplicity, and ubiquity, a formal account of generic meaning remains elusive.


How can generics have such flexible truth conditions while simultaneously carrying strong implications?
In this paper, we explore the idea that the core meaning of a generic statement is simple, but underspecified, and that general principles of communication may be used to resolve precise meaning in context. 
In particular, we develop a mathematical model that describes pragmatic reasoning about the degree of prevalence required to assert the generic.  
We find that this formalism resolves the philosophical and empirical puzzles.
-->



# The Bayesian Framework for Generalizations 

Generalizations are used to make predictions about instances that an agent has yet to experience [@HumeTHN].
From a very young age, children draw strong inferences about nonobvious object properties from just a few examples [@Baldwin1993].
To form a generalization about a category or kind $k$, an observer must be able to individuate an exemplar or instance $x$ as belonging to the category.
The linguistic expression of such an individuation would manifest in utterances such as "$x$ is a $k$" or "this $k$ ..."
To generalize a feature $f$ to that category, it is also necessary to be able to determine if the particular instance has the feature.
That is, a speaker must be able to say "This $k$ (i.e., $x$) has $f$".
We call this kind of statement a *particular*.

```{r table-generalization, results="asis"}
df.tab <- data.frame(
  Generalization = c("Dogs are friendly", "John smokes", "Drinking moonshine makes you go blind"),
  #x = c("an instance of K in space", "an instance of K in time", "an instance of a "),
  "Generalization over" = c("Category", "Event", "Cause"),
  "Linguistic construct" = c("Generic", "Habitual", "Causal"),
  x = c("a dog", "an instance of John", "an instance of a person drinking moonshine"),
  k = c("DOGS", "JOHN", "DRINKING MOONSHINE"),
  f = c("is friendly", "is smoking / smoked at time t", "caused person to go blind")
) #%>% xtable(., 
 #        caption = c("Decomposition of generalizations into concrete particulars and corresponding properties."),
  #       label = c("tab:genpart"))


apa_table(df.tab, 
          caption = "Decomposition of generalizations into concrete particulars and corresponding properties.", 
          escape = TRUE, small = TRUE
)

#print(df.tab,  type = "latex", tabular.environment = "tabularx", width = "\\textwidth",  include.rownames = FALSE, comment = F)
```

We can make particular statements about objects, events, and causes.
We can say "My dog is friendly.", "John ran this afternoon.", or "My grandfather drank moonshine and it made him go blind."
To consider the corresponding generalizations (i.e., "Dogs are friendly", "John runs", "Drinking moonshines makes you go blind"), we must say exactly how the particular relates to the generalization.
We consider the generalization to be about a *category* and the particular to correspond to *instances* of that category.
Thus, *dog* is an instance of the category \textsc{dogs}, *John at a particular time* is an instance of the category of \textsc{john}, and *drinking moonshine at a particular time* is an instance of the category of \textsc{drinking moonshine} (see Table \ref{tabgenPart}).


Suppose we observe instances $\{x_1, x_2, ..., x_n\}$ of category $k$ and some number of them have feature $f$: What do we learn about possible future instances of $x_{n+1}$, particularly with respect to $f$?
For properties among instances of a category, we can describe an inductive inference by a probability $h$ $h = P(x \in f \mid x \in k)$^[
With a frequentist interpretation, this can be thought of as the *prevalence* of $f$ among $k$.
].
In the study of categories and properties, $x$ is an object.
For a behavior exhibited by an agent, the inference concerns a rate --- how frequently (in time) does $x \in f$ occur --- which can be described as a probability integral: $h = \int_{t} P(x \in f_t \mid x \in k_t) \diff t$
In this case, $x$ is a instance of an agent.
Causal learning can be described with the same formalism as for categories, a probability referring to the probability of an effect $e$ given a cause $c$: $h = P(x \in e \mid x \in c)$.
We refer to this probability as $h$ because it represents a hypothesis about the underlying causal power or frequency that generated the observed data.
<!-- A Bayesian agent will have prior beliefs about the probability (potentially an uninformed prior) and uses Bayesian inference to learn about the probability from her observations. -->

<!-- Suppose *a priori* we have no informative beliefs about the propensity (i.e., $P(x \in f \mid x \in k) \sim \text{Uniform}(0, 1)$). -->
Observing some number of positive instances of $k$ with $f$ will update a prior belief distribution into a posterior belief distribution.
As a concrete example, consider the feature *is friendly* ($f$) for the category *dog* ($k$): $h = P(x \in \{\text{is friendly}\} \mid x \in \{\text{is a dog}\})$.
If an agent were to encounter some number of individual dogs, note how many of them were friendly ($d$), she could form a posterior belief distribution about the friendliness of dogs.

$$
P(h \mid d) = \frac{P(d \mid h) \cdot P(h)}{\int_{h'}P(d \mid h') \cdot P(h')}
$$

Our ability to use this updated belief $P(h \mid d)$ in order to make predictions about unobserved instances is a computational description of generalization [e.g., @Tenenbaum2006; @Tenenbaum2011].

The human capacity to generalize from observations has been studied extensively in cognitive and developmental psychology [@Nisbett1983; @Baldwin1993; @Heit2000].
Inductive inferences show complex sensitivites to the kind of observations, and even how those observations came to be observed in the first place.
For instance, observing that an indigenous person living on a remote island *is obese* provides considerably less information about the weights of other islanders in comparison to inferences about skin color upon learning that one islander's skin color *is brown* [@Nisbett1983].
Confounded causal evidence can be suddenly become unconfounded when you know the evidence was generated by an intentional agent [@Goodman2009].
Quantitative modeling has been crucial in explaining how the subtleties of experience relate to subtleties in generalization [@Tenenbaum2006; @Kemp2008].

Studying generalizations from observational evidence can only take us so far in understanding how the mind understands the world or culture accumulates across generations.
Relying upon observations would be particularly problematic to learn, for example, about properties that are difficult to observe (e.g., *cows have four stomachs*) or events that are statistically unlikely (e.g., *lightning strikes tall objects*).
For abstract, generalizable knowledge to remain in a culture, it must be able to be faithfully transmitted between individuals and across generations [@Tomasello1999], and language provides simple ways to communicate generalizations.


# Communicating Generalizations with a Formal Model

We will discuss communicating generalizations in the context of generalizations about categories (i.e., *generic language*), though the arguments will extend to events and causes as well, following the formalization described in the previous section. 
Generics express a relation between a kind K (e.g., \textsc{dogs}) and a property F (e.g., \textsc{is friendly}), such that the property can also be said to be applicable of an individual (i.e., "My dog is friendly"). 
Bare plural statements (e.g., *Dogs are friendly*) strongly tend to yield a generic meaning, though other forms can express such a meaning [e.g., *A mongoose eats snakes.*; @Carlson1977] .

Given that generics express a property that can be applied to individuals, it seems intuitive that what makes the statement true or false would correspond to the number of individuals who hold the property.
At first glance, generics convey that *most* have the property, such as *Most dogs are friendly*.
*Robins lay eggs* is true, though, despite the fact that only female robins lay eggs (not exactly *most robins*). 
If generic statements can be true by restricting themselves to only be describing females, why does *Robins are female* seem like a weird statement to make?
Finally, *Mosquitos carry malaria* is intuitively true despite malaria only being present in a tiny fraction of a percentage of mosquitos.
It seems that any hard condition on the prevalence of the feature in the category (e.g., how many robins lay eggs) would violate intuitions. 

These observations have led to proposals that prevalence or probability is only peripherally related to generic meaning. 
Conceptual accounts of generics emphasize the structure of generic knowledge [@Prasada2000], and view generic utterances as the way of expressing special mental relationships between kinds and properties [@Leslie2008; @Prasada2012]. 
From this perspective, the statement *Bishops move diagonally* is true not because most bishops move diagonally, but rather those are the rules of chess.
The most influential account in psychology is credited to @Leslie2007, who proposes that generics express a cognitively primitive, *default generalization*. 

The *generics as default* view capitalizes on general cognitive principles to explain why certain generics are true or not.
*Mosquitos carry malaria* conveys a dangerous or striking property, which is useful to know about if you are trying to survive in a dangerous world.
This theory thus predicted that generics that convey striking properties would be true even if they were relatively rare (e.g., *Sharks attack swimmers*), which has been empirically verified [@Cimpian2010; @Prasada2013].
Other generics convey properties that are *characteristic* of a kind, such as *Robins lay eggs*, argued to have a *principled connection* between kind and property [@Prasada2006; @Prasada2013].

Yet, generics are not limited to conveying rich relations. 
Arbitrary relations can also be expressed like *Barns are red* or *Ravens are bigger than toasters*, which seem only to be true because of the statistics of the world [@Nickel2008; @Nickel2016; @Sterken2015].
The *generics as default* view must then be supplemented with the principle that, in certain situations, the statistics can influence generic endorsement.
How do we make sense of this panoply of conditions?
Is there some more general, unified principle that explains what makes generic statements true or false?

Bayesian cognitive models are used to represent flexible, structured knowledge of the world and formalize the inferences that people draw using such conceptual representations [e.g., @Kemp2008; @Goodman2015Chapter].
The basic currency of inference in these models is probability.
In the case of generic language, we posit that conceptual factors may influence the meaning of a generic statement via its influence on subjective probability.
If that's true, a simple, semantic theory (e.g., a threshold on subjective probability) may be enough to formalize the core meaning of a generic statement. 

\begin{eqnarray}
L(h \mid u) &\propto& {\delta_{\denote{u}(h, \theta)} \cdot P(h)} \label{eq:L0fixed}
\end{eqnarray}

Equation \ref{eq:L0fixed} is a model of a listener $L$ who updates her beliefs $h$ according the meaning an utterance $u$.
$P(h)$ represents the listener's prior world knowledge concerning the relevant probabilities $h$.
The particular form of the prior plausibly depends upon the kind of property or event in question and could be structured as a result of deeper conceptual knowledge about properties and events [cf., @Griffiths2005; @Tenenbaum2006; @Kemp2008].
We term this prior distribution the *prevalence prior*.
$\delta_{\denote{u}(h, \theta)}$ is the likelihood term in Bayes' Rule, representing the literal semantics of utterances.
For an utterance conveying a generalization $u_{gen}$, we adopt a simple threshold semantics:

\begin{eqnarray}
\delta_{\denote{u_{gen}}(h, \theta)} & = & P(u_{gen} \mid h, \theta) \\
&\propto  &
\begin{cases}
1 & \text{if } h > \theta \\
0 & \text{otherwise}
\end{cases}
\end{eqnarray}

The $\delta_{\denote{u}(h, \theta)}$ likelihood is the Kronecker delta function returning $1$ for states $h$ greater than threshold $\theta$ and $0$ otherwise. 
Logical quantifiers can be described using threshold semantics (i.e., *some* is $h > 0$, all is $h = 1$).
What threshold $\theta$ should be used for the generic generalization?
We posit that meaning of a generalization in language is *underspecified*; that is, there is not a fixed $\theta$ that corresponds to the generalization, but rather the listener must infer $\theta$ in context.
In the probabilistic model, this is formalized as a prior distribution over the value of $\theta$.
We assume this prior is uninformed: $\theta \sim \text{Uniform}(0, 1)$.

\begin{eqnarray}
L(h, \theta \mid u) &\propto& {\delta_{\denote{u}(h, \theta)} \cdot P(h) \cdot P(\theta)} \label{eq:L0}
\end{eqnarray}

This is a Bayesian model of interpreting a statement conveying a generalization whose meaning is simple (a threshold function) but underspecified.
Figure \ref{fig:simulations} shows model $L$'s posterior distribution on $h$ upon hearing utterances corresponding to the uncertain threhsold (Eq. \ref{eq:L0}) as well as a comparison model using a fixed threshold at 0 (intuitively, corresponding to the quantifier "some").
The differences in the semantics are easily seen when considering a uniform distribution over $h$ (top left facet).
"Some" rules out only the lowest possible state and returns a posterior very similar to the prior.
The behavior of the generalization is distinct: The higher the $h$, the more likely the state is.

The intuition behind this behavior can be gleaned by imagining what the $L$ listener would believe with different thresholds and averaging over those possibilities.
If the threshold is very high, only the highest $h$ would pass the threshold.
If the threshold is slightly lower but still high, the highest $h$ probabilities would still pass the threshold, as would some that are slightly lower.
As the threshold takes on lower and lower values, more and more probabilities would surpass it.
When the threshold is very low, almost all probabilities are consistent with it (akin to "Some").
When the listener averages over these thresholds, higher values of $h$ pass more thresholds; thus, higher $h$ are more likely *a posteriori*.

In this paper, we are interested in explaining the variable endorsements of generalizations based on some known or believed probability $h$.
Following the Rational Speech Act (RSA) framework [@Goodman2016], we describe an endorsement model as a Bayesian decision of whether or not to say the generalization to the listener $L$ (Eq. \ref{eq:L0}).
\begin{equation} 
S(u \mid h) \propto \exp{(\lambda \cdot \ln{ \int_{\theta} L_0(h, \theta \mid u)}  \diff \theta  }
\label{eq:S1}
\end{equation}

In RSA, language production and comprehension are defined by recursive Bayesian models describing speaker and listener.
Following RSA, this speaker is assumed to be an approximately rational Bayesian agent with degree with rationality governed by parameter $\lambda$.
The speaker's decision to say an utterance (e.g., the generalization) is determined with respect to how well it would communicate $h$ to the listener $L$, in comparison to alternative utterances.
To model generic endorsement, this decision is evaluated in comparison to the alternative of *not saying the generalization*;
with just two alternatives (say the generalization vs. not), the model can be interpreted as a model of felicity judgments [@Degen2014]. 
Formally, we consider the negative alternative as the option of staying quiet, which carries no information content^[
This alternative can be realized in at least two other ways: the speaker could have said the negation of the utterance (i.e., *The generalization is not true.*) or the negative generalization (i.e., *The opposite is true.*, e.g., *Ks do not have F*).
All results reported are similar for these two alternatives, and we use the alternative of the *silent* utterance for simplicity.
]:

\begin{equation*}
\delta_{\denote{u_{silence}}(h, \theta)} \propto \begin{cases}
1 &\text{for all h}\ 
\end{cases}
\end{equation*}

Since the speaker $S$ doesn't know the threshold $\theta$, he must integrate over the likely values that the listener will infer. ^[
A more general version of this model can relax the assumption that the speaker has access to a degree of propensity $h$ that he is trying to communicate.
Rather, the speaker may have a belief distribution over $h$, corresponding to his beliefs about the rate with which an event happens or the prevalence of the property in the kind. 
In this situation, we would define the utility function to be the expected value of the informativity, which integrates over his belief distribution: 
$U(u; k) = {\mathbb E}_{h\sim P_{k}} \ln{ \int_{\theta} L_0(h, \theta \mid u)}  \diff \theta$
]

<!-- This decision is based on whether or not the generalization would accurately convey the $h$ -->
<!-- For addressing the question of whether or not a generalization is "true" or "felicitous", we consider how a Gricean speaker would act, given the goal of being informative to the literal listener (Eq. \ref{eq:L0}).  -->

<!-- S_{1}(u \mid k) \propto \exp{(\lambda \cdot {\mathbb E}_{h\sim P_{k}} \ln{ \int_{\theta} L_0(x, \theta \mid u)}  \diff \theta ) } -->

<!-- Inspired by Bayesian decision theory, the speaker takes actions (i.e., produces utterances) soft-max optimally in accord with his utility function \cite{Baker2009}. -->
<!-- The utility function of a speaker is based on the informativeness of the utterance, which is computed with respect to what a naive listener $L_0$ would believe after hearing the utterance, taking into account the cost of the utterance $C(u)$.  -->
<!-- \begin{equation} -->
<!-- U(u; h) = \ln{ \int_{\theta} L_0(h \mid u)}  \diff \theta - C(u) -->
<!-- \label{eq:utilS1marginalization} -->
<!-- \end{equation} -->
<!-- Since the speaker doesn't know the threshold $\theta$, he must integrate over the likely values that the listener will infer. ^[ -->
<!-- A more general version of this model could relax the assumption that the speaker has access to a degree of propensity $h$ that he is trying to communicate. -->
<!-- Rather, the speaker may have a belief distribution over $h$, corresponding to his beliefs about the rate with which an event happens or the prevalence of the property in the kind.  -->
<!-- In this situation, we would define the utility function to be the expected value of the informativity, which integrates over his belief distribution:  -->
<!-- $U(u; k) = {\mathbb E}_{h\sim P_{k}} \ln{ \int_{\theta} L_0(h, \theta \mid u)}  \diff \theta$ -->
<!-- ] -->
<!-- $S_1$ thus seeks to minimize the surprisal of $s$ given $u$ for the naive listener, while bearing in the mind the utterance cost $C(u)$. -->


<!-- No fixed value of the threshold, $\theta$, would allow for the extreme flexibility generics exhibit (e.g., *Mosquitos carry malaria*; *Robins lay eggs* v. *Robins are female*). -->


<!-- Abstract mental representations, then, may thus be influencing generic endorsement via its influence on subjective probability. -->


<!-- To understand how generalizations are conveyed in language, we start by considering general purpose language understanding principles. -->
<!-- Foremost, understanding language depends upon assumptions interlocutors make about each other and can exhibit a complex sensitivity to context [@Clark1996; @Grice1975; @Levinson2000]. -->
<!-- Though once viewed as a wastebasket in which to dump unexplained loose ends in service of more rigorous formal analysis, *pragmatics* --- or language understanding in context --- has seen an emergence of formal frameworks that connect closely with behavioral data [@Franke2015]. -->

<!-- One dominant framework --- the Rational Speech Act theory --- has had considerable success in providing a formal account of pragmatic language phenomena [i.e., interactions between language and context; @Goodman2016]. -->
<!-- This framework has been used to explain, in precise mathematical terms, how it is that utterances like "some of the kids failed the test" are interpreted to mean "some (but not all) of the kids failed the test" [@Goodman2013], how "I waited a million years to get a table" is interpreted as "I waited an obnoxiously long time to get a table" [@Kao2014], how "John is tall" can mean John is 5'4" is John if a 12-year-old but means John is 6'2" if he is 24-years-old [@Lassiter2015], and how "Your talk was fine" can be a polite way of saying your talk was less than fine [@Yoon2016].  -->
<!-- Computational modeling has pushed our understanding of these complex linguistic phenomena, but so far, rational models of language use have focused on *specific* statements: utterances that convey information about a particular entity or situation.  -->
<!-- A formal theory of statements that convey generalizations about entities or situations ---  statements that extend beyond the here-and-now --- has remained elusive. -->

<!-- Formalizing the meaning of linguistic expressions requires specifying *truth conditions*, or the states of the world in which the expression is true vs. false. -->
<!-- Using the tools of formal semantics, we specify a *truth function*: A function from states of the world to truth-values.  -->
<!-- A simple truth function for a generalization could be a threshold on an agent's posterior probability: $\denote{u_{generalization}}(h, \theta): \{ h: h > \theta\}$, where $\denote{u_{generalization}}$ represents a function from a state of the world $h$ and a threshold variable $\theta$ to the set of the states of the world where $h > \theta$.  -->
<!-- Applying this function to a set of worlds returns a set of worlds that are consistent with $h > \theta$. -->

<!-- Though intuitively appealing and simple, this threshold-based truth function for a generalization is problematic. -->
<!-- <!-- fixed value of $\theta$ seems unlikely. --> -->
<!-- The generalization *Mary smokes cigarettes* suggests a daily-habit (e.g., $h > \text{once a day}$), while *Bill writes poems* implies something much weaker, perhaps a poem every few weeks (e.g., $h > \text{once a month}$. -->
<!-- *Drinking moonshine makes you go blind* and so does *staring at the sun*, but neither causal statement tells you to precisely the increased relative risk. -->
<!-- *Mosquitos carry malaria* is a true statement despite the prevalence of carrying malaria among mosquitos being a just a fraction of 1\%, while *Ducks are female* might seem like a weird thing to say, even though the rate is much higher than the malaria-carrying mosquitos. -->
<!-- Finally, *Ducks lay eggs* is a good generalization, though the rate is the same as *Ducks are female*. -->
<!-- The meaning of generalizations, it seems, cannot reduce to a single, precise quantitative statement; this is the major stumbling block to providing a formal account of genericity [@Carlson1977; @Leslie2008; @NickelBlackwell]. -->

<!-- We hypothesize the simple threshold-based truth function for lingusitic generalizations can be rescued by positing an *underspecified* meaning.  -->
<!-- That is, we adopt a threshold semantics as described above, but imagine that $\theta$ is not a fixed property of language but rather is drawn from a prior probability distribution. -->
<!-- In this formulation, listeners infer thresholds along with speakers' intended meanings in context. -->
<!-- We formalize this hypothesis with a "literal listener" model from the Rational Speech Act framework [@Frank2012; @Goodman2013; @Goodman2016]. -->

<!-- *Bills writes poems* might true if Bill does it a few times a year, while we might be hesitant to say *Mary smokes cigarettes* if she only does it once every few months. -->
<!-- *Ducks lay eggs* is true despite only the female ducks laying eggs, while *Ducks are female* is strange to say (even though only the females are female). -->

<!-- The language of generalizations is so simple that it appears everywhere in human conversation (*Movie theaters are cold.*), pedagogy (*The blicket makes the machine play music.*), political and scientific discourse (*The President peddles falsehoods.*, *Psychology experiments don’t replicate.*), stereotypes (*Boys are good at math*), motivation (*Big girls eat their broccoli!*), emotion-regulation  (*Accidents happen.*), child-directed (*Mommy works late*) and child-produced speech (*Slides aren't for grown-ups!*), and many other facets of experience [@GelmanEtAl2004; @Gelman2008; @Cimpian2010motivation; @Rhodes2012]. -->

<!-- Though the language of generalizations is found everywhere and in every language [@Behrens2005; @Carlson1995], the meaning of such linguistic expressions is philosophically puzzling and has resisted precise formalization. -->
<!-- Intuitively, generalizations should convey something about the probability of an instance of the category to have a property, but exactly what is conveyed is unclear. -->

<!-- What if we leave the $\theta$ underspecified in the semantics? -->
<!-- That is, what would a listener believe if she drew $\theta$ from an uninformed prior belief distribution: $P(\theta)$?^[ -->
<!-- Previous attempts have been made to salvage this threshold semantics, using a semantic a technique called "domain restriction", wherein the scope of generalization is restricted to a smaller subset of entities or instances [e.g., "only female ducks"; @Cohen1999].  -->
<!-- Though effective at dealing with at least some of these semantic puzzles, this approach leaves unresolved why the domain should be restricted in some cases and not others. -->
<!-- We return to this more fully in the General Discussion. -->
<!-- ] -->

<!-- [MHT: talk about soft semantics here?] -->

<!-- \begin{eqnarray} -->
<!-- L_{0}(h, \theta \mid u) &\propto& {\delta_{\denote{u}(h, \theta)} \cdot P(h) \cdot P(\theta)} \label{eq:L0} -->
<!-- \end{eqnarray} -->


<!-- The threshold $\theta$ is assumed to be drawn by an uninformative prior distribution, defined on the same scale as the probability $h$: $\theta \sim \text{Uniform}(0, 1)$.^[ -->
<!-- Though it's plausible that different thresholds could be learned for different domains, we assume an uninformed prior distribution in our model to show how background knowledge about how the world works drives inferences. -->
<!-- ] -->
<!-- Finally, the prior distribution $P(h)$ is a distribution over the degrees of probability. -->
<!-- The particular form of the prior plausibly depends upon the kind of property or event in question and could be structured as a result of deeper conceptual knowledge about properties and events [cf., @Griffiths2005; @Tenenabum2006; @Kemp2008]. -->
<!-- This is a simple Bayesian model of interpreting a statement conveying a generalization. -->


```{r simluationsModel, eval = T, cache = T}

l0.model <- '
var probability = function(Dist, x) {
    return Math.exp(Dist.score(x));
}
var targetUtterance = "generic";

var utterancePrior = Infer({model: function(){
  return uniformDraw([targetUtterance,"silence"])
}});

var thetaPrior = Infer({model: function(){
 return uniformDraw([
   0.01, 0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,
   0.5, 0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95
 ])}
});

var bins = [
  0.01,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,
  0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99
];

var meaning = function(utt,state, theta) {
  return utt=="generic"? state > theta :
         utt=="generic is false"? state<=theta :
         utt=="silence"? true :
         utt=="some"? state>0.01:
         utt=="most"? state> 0.5:
         utt=="all"? state >= 0.99:
         true
}

var mixture = data.prior.mix[0];
var priorParams = data.prior.params[0];

var statePrior = Infer({model: function(){
  var component = flip(mixture);
  return component ?
    categorical({
      vs: bins,
      ps: map(function(b) {
        return probability(Beta(priorParams), b) + Number.EPSILON
      }, bins )
    }) :
    categorical({
      vs: bins,
      ps: map(function(b) {
        return probability(Beta({a:1,b:50}), b) + Number.EPSILON
      }, bins )
    })
}});

var listener0 = cache(function(utterance) {
  Infer({model: function(){
    var state = sample(statePrior)
    var state_prior = sample(statePrior)
    var theta = utterance == "generic" ? sample(thetaPrior) : -99
    condition(meaning(utterance, state, theta))
    return {
      state_Posterior: state, 
      state_Prior: state_prior
  }
 }})}, 10000)


var continuousListener0 = function(utterance) {
  Infer({model: function(){
    var state = sample(Beta( flip(mixture) ? priorParams : {a:1,b:100}))
    var state_prior = sample(Beta( flip(mixture) ? priorParams : {a:1,b:100}))
//    var theta = uniform(0,1)
    factor(
    (utterance == "generic") ? 
      Math.log(state) : 
    (state > 0) ? 0 : -Infinity
    )
    return {
      state_Posterior: state, 
      state_Prior: state_prior
  }
 }, method: "rejection", samples: 20000, burn:5000, verbose: T})}



//var out = {generic: listener0("generic"), some: listener0("some")}
//out
continuousListener0(data.utt[0])
'

priorNames <- c(
  "uniform", #"uniformRare", 
  "isFemale", 
  "laysEggs", 
  #"eatsFood", 
  "barks",
  "carriesMalaria"#,
 # "areSick"
  )
priorShapes <- list(
  uniform =  list(params = data.frame(a = 1, b = 1), mix = 1), 
  #uniformRare =  list(params = data.frame(a = 1, b = 1), mix = 0.4), 
  isFemale =  list(params = data.frame(a = 10, b = 10), mix = 1), 
  laysEggs =  list(params = data.frame(a = 10, b = 10), mix = 0.4), 
  #eatsFood =  list(params = data.frame(a = 50, b = 1), mix = 1), 
  barks =  list(params = data.frame(a = 5, b = 1), mix = 0.4), 
  #areSick =  list(params = data.frame(a = 1, b = 5), mix = 1), 
  carriesMalaria =  list(params = data.frame(a = 2, b = 10), mix = 0.4)
)

all.simulations <- data.frame()
for (p in priorNames){
  for (u in c("generic", "some")){
    
    inputData = list(prior = priorShapes[[p]], utt = u)
    l0.rs <- webppl(l0.model, data = inputData, data_var = "data")
    
    # all.simulations <- bind_rows(all.simulations,
    #                         bind_rows(
    #                           data.frame(l0.rs$generic) %>%
    #                             gather(key, val, -probs) %>%
    #                              group_by(key, val) %>%
    #                              summarize(prob = sum(probs)) %>%
    #                             ungroup() %>%
    #                               mutate(key = gsub("support.", "", key)) %>%
    #                              separate(key, into = c("Parameter","Distribution")) %>%
    #                               mutate(Distribution = gsub("Posterior", "Posterior_Generalization", Distribution)),
    #                           data.frame(l0.rs$some) %>%
    #                             gather(key, val, -probs) %>%
    #                             group_by(key, val) %>%
    #                             summarize(prob = sum(probs)) %>%
    #                             ungroup() %>%
    #                             mutate(key = gsub("support.", "", key)) %>%
    #                             separate(key, into = c("Parameter","Distribution")) %>%
    #                             mutate(Distribution = gsub("Posterior", "Posterior_0", Distribution)) %>%
    #                             filter(Distribution != "Prior"),
    #                           data.frame(l0.rs$most) %>%
    #                             gather(key, val, -probs) %>%
    #                             group_by(key, val) %>%
    #                             summarize(prob = sum(probs)) %>%
    #                             ungroup() %>%
    #                             mutate(key = gsub("support.", "", key)) %>%
    #                             separate(key, into = c("Parameter","Distribution")) %>%
    #                             mutate(Distribution = gsub("Posterior", "Posterior_05", Distribution)) %>%
    #                             filter(Distribution != "Prior")
    #                         ) %>%
    #                           mutate(PriorShape = p)
    # )
      all.simulations <- bind_rows(all.simulations,
                                   l0.rs %>%
                                  separate(Parameter, into = c("Parameter","Distribution")) %>%
                                  mutate(Distribution = gsub("Posterior", "Posterior_Generalization", Distribution))
                                  %>%
                              mutate(PriorShape = p, utterance = u)
    )
  }
  #print(p)
}
```

```{r simulations, fig.width = 8, fig.height=5}
all.simulations %>%
  mutate(Distribution = paste(Distribution, utterance, sep = "_")) %>%
  filter(Distribution != "Some", Distribution != "Most", Distribution != "Prior_generic") %>%
  mutate(Distribution = factor(Distribution, levels = 
                             c("Prior_some", "Posterior_Generalization_some", "Posterior_Generalization_generic"),
                                labels = c("Prior/Silence", "Some", "Generalization")),
         PriorShape = fct_relevel(PriorShape, "uniform", "barks","laysEggs","carriesMalaria","isFemale"
                                  #"eatsFood","areSick", "uniformRare", 
                                  #"carriesMalaria"
                                  )
         ) %>%
  ggplot(., aes(x = value, #y = prob, 
                #lty = Distribution, 
                color = Distribution, fill = Distribution))+
    geom_density(#stat= 'identity', 
                aes(y = ..scaled..),
                 size = 0.6, alpha = 0.7, adjust = 1.5)+
    #geom_bar(stat = 'identity', position = position_dodge(), color = 'black')+
    theme_few() +
    #scale_color_solarized()+
    #scale_fill_solarized()+
    #scale_fill_manual(values = c("#636363", "#abdda4", "#2b83ba", "#d7191c"))+
    #scale_color_manual(values = c("#636363", "#abdda4", "#2b83ba", "#d7191c"))+
   scale_fill_manual(values = c("#636363", "#2b83ba","#d7191c"))+
    scale_color_manual(values = c("#636363","#2b83ba", "#d7191c"))+
    #scale_linetype_manual(values = c(3, 4, 2, 1))+
    scale_linetype_manual(values = c(3,4, 1))+
    scale_x_continuous(breaks = c(0, 0.5, 1), limits= c(0, 1))+
    xlab("Degree of propensity (probability)") +
    ylab("Probability density") +
  facet_grid(PriorShape~Distribution, scales = 'free')+
  theme(strip.text.y = element_text(angle = 0))
```



<!-- For addressing the question of whether or not a generalization is "true" or "felicitous", we consider how a Gricean speaker would act, given the goal of being informative to the literal listener (Eq. \ref{eq:L0}).  -->

<!-- <!-- S_{1}(u \mid k) \propto \exp{(\lambda \cdot {\mathbb E}_{h\sim P_{k}} \ln{ \int_{\theta} L_0(x, \theta \mid u)}  \diff \theta ) } --> 
<!-- \begin{equation}  -->
<!-- S_{1}(u \mid h) \propto \exp{(\lambda \cdot U(u; h)  } -->
<!-- \label{eq:S1} -->
<!-- \end{equation} -->

<!-- Following RSA, this speaker is an approximately rational (speech-)actor with degree with rationality governed by parameter $\lambda$. -->
<!-- Inspired by Bayesian decision theory, the speaker takes actions (i.e., produces utterances) soft-max optimally in accord with his utility function \cite{Baker2009}. -->
<!-- The utility function of a speaker is based on the informativeness of the utterance, which is computed with respect to what a naive listener $L_0$ would believe after hearing the utterance, taking into account the cost of the utterance $C(u)$.  -->
<!-- \begin{equation} -->
<!-- U(u; h) = \ln{ \int_{\theta} L_0(h \mid u)}  \diff \theta - C(u) -->
<!-- \label{eq:utilS1marginalization} -->
<!-- \end{equation} -->
<!-- Since the speaker doesn't know the threshold $\theta$, he must integrate over the likely values that the listener will infer. ^[ -->
<!-- A more general version of this model could relax the assumption that the speaker has access to a degree of propensity $h$ that he is trying to communicate. -->
<!-- Rather, the speaker may have a belief distribution over $h$, corresponding to his beliefs about the rate with which an event happens or the prevalence of the property in the kind.  -->
<!-- In this situation, we would define the utility function to be the expected value of the informativity, which integrates over his belief distribution:  -->
<!-- $U(u; k) = {\mathbb E}_{h\sim P_{k}} \ln{ \int_{\theta} L_0(h, \theta \mid u)}  \diff \theta$ -->
<!-- ] -->
<!-- $S_1$ thus seeks to minimize the surprisal of $s$ given $u$ for the naive listener, while bearing in the mind the utterance cost $C(u)$. -->


## Alternative formulation

The pair of speaker-listener models presented above correspond to the simplest possible communicative models with an underspecified threshold meaning for a generalization. 
The Rational Speech Act framework defines a class of models with potentially more levels of recursion (e.g., a listener who thinks about a speaker who thinks about a listener).
For the most basic formulation of an RSA model, the level of recursion for a model can be unidentifiable from the 
"speaker optimality" model parameter in Eq. \ref{eq:S1} [@FrankEtAlUnderReview].
For our model, with an uncertain threshold variable, theoretically meaningful different models can be formulated in the pragmatic framework.

For example, @Lassiter2013 modeled vagueness and the context-sensitivity of gradable adjectives using a similar underspecified threshold semantics. 
In that work, the authors argued that understanding adjectives required a "pragmatic listener" [i.e., a listener who thinks about a speaker who thinks about a listener; @Lassiter2015]. 
In their model, the threshold variable was "pragmatically lifted", meaning the uncertainty over the threshold variable was resolved using pragmatic reasoning [a so-called uRSA model; @Goodman2016].
In the case of our model of generalizations, we can compare the simple model we described above to a more sophisticated model that resolves the threshold using pragmatic principles.

### Listener models

Eq. \ref{eq:L0} describes how a naive Bayesian agent should update her beliefs about the probability after hearing an utterance conveying a generalization. 
This listener model is not pragmatic because it doesn't reason about the generative process of the utterance (i.e., it doesn't reason about a speaker). 
Eq. \ref{eq:L1u} extends this model adding a level of recursion, modeling a pragmatic listener who reasons about the Gricean speaker in Eq. \ref{eq:S1} who reasons about the literal listener in Eq. \ref{eq:L0}.

\begin{eqnarray}
L_{1}(h \mid u) &\propto& S_{1}(u \mid h) \cdot P(h) \label{eq:L1u}
\end{eqnarray}

This $L_1$ model reasons about the conditions under which the speaker $S_1$ would produce one or another speech act (here, the generalization or staying silent), described above.
Still, the threshold variable gets resolved by $L_0$ (and marginalized out by $S_1$): The posterior distribution over thresholds is arrived at by $L_0$ trying to make the generalization true.
<!-- \mht{How does this posterior on states differ?} -->

Truthfulness is not the only process that could help set $\theta$.
If the listener were to reason about what threshold was likely to be *used by the speaker*, informativity would also help set $\theta$.
This can be modeled by a pragmatic listener who reasons about the threshold, but assumes the speaker had a particular threshold in mind (Eq. \ref{eq:S1l}). 

\begin{eqnarray}
L_{1}(h, \theta \mid u) &\propto& S_{1}(u \mid h, \theta) \cdot P(h) \cdot P(\theta) \label{eq:L1l} \\
S_{1}(u \mid h) &\propto &\exp{(\lambda \cdot U(u; h; \theta)  } \label{eq:S1l} \\
U(u; h; \theta)& =& \ln{  L_0(h \mid u, \theta) } - C(u) \label{eq:utilS1nomarginalization} \\
L_{0}(h \mid u, \theta) &\propto& {\delta_{\denote{u}(h, \theta)}} \cdot P(h) \label{eq:L0l}
\end{eqnarray}

Eq. \ref{eq:L1} is mathematically equivalent to the gradable adjectives model of @Lassiter2013, with the modification that states of the world are defined with respect to the probability $h$ under discussion.
In this model, the listener's posterior distribution on thresholds is arrived at by trying to make the utterance conveying the generalization to be both truthful and informative. That is, the listener must believe the threshold used by the speaker is both true and informative; very low thresholds could only be informative in contexts when the listener believes most probabilities are all very low *a priori*.

These alternative pragmatic listener $L_1$ models give rise to corresponding alternative pragmatic speaker models.

### Speaker models

We can define two speaker models who reason about the two different pragmatic listeners.

The speaker who reasons about the pragmatic listener in Eq. \ref{eq:L1u} is defined by a utility function similar to Eq. \ref{eq:utilS1nomarginalization}, but with informativity computed with respect to $L_1$'s posterior distribution rather than $L_0$. 

\begin{eqnarray}
S_{1}(u \mid h) \propto \exp{(\lambda \cdot U(u; h; \theta)  } \label{eq:S1l} \\
U(u; h; \theta) = \ln{  L_1(h \mid u) } - C(u) \label{eq:utilS2nomarginalization} \\
\end{eqnarray}

The model who reasons about the pragmatic listener in Eq. \ref{eq:L1l} marginalizes over $L_1$'s posterior distribution on the threshold $\theta$ in order to decide which utterance to produce (similar to \ref{eq:utilS1marginalization}).

\begin{eqnarray}
S_{2}(u \mid k) \propto \exp{(\lambda_2 \cdot U_{S_2}(u; k)  } \\ 
U_{S_2}(u; h) = \ln{ \int_{\theta} L_1(h, \theta \mid u)}  \diff \theta - C(u) \label{eq:S2l}
\end{eqnarray}


All models were implemented in the probabilisitic programming language WebPPL [@dippl], and a complete, runable versions of the models in the following section can be found at \url{http://forestdb.org/models/generics.html}


## Model simulations

All of the RSA models defined in the previous section predict that the interpretation and endorsement of a generalization depends listener's *a priori* beliefs about the probabilty in question $P(h)$.
Qualitatively, the predictions of the different formulations of the RSA models for understanding generalizations are not appreciably different (though their quantitative predictive flexibility is).
For purposes of illustration, we present present predictions of the simplest model with an underspecified threshold and a model where the threshold is fixed to 0 (corresponding intuitively to *some* statements).

Before, we described how an underspecified threshold interacts with a uniformly uncertain belief about the probability.
Here, we consider some canonical cases from the literature on generics to demonstrate the kind of inferences a listener would draw from different generic statements.
Our model of endorsements is a model of speaker who decides whether or not to say the generic or stay silent. 
Thus, qualitatively model predictions for endorsement can be gleaned by comparing the prior distribution over the probability $h$ (which is the same as posterior upon hearing "silence") with the posterior distribution over $h$ upon hearing the generalization.

In Figure \ref{fig:simulations} (row 2), we show a schematic prior distribution over a feature "barks".
Here, we show the prior is bimodal with peaks at 0\% and some high prevalence values, corresponding intuitively to the fact that many kinds creatures do not bark (i.e., have 0\% prevalence) and for those that do have members that bark, many of them bark (i.e., have some high prevalence value).
The fact that "those that do not bark" is not just a Delta function at 0\% reflects the intuitive possibility that some members of a kind who does not usually bark (say, a cat) could somehow have the feature (e.g., due to some transient or accidental state).
We see that the quantifier "Some" (middle row) struggles to differentiate those that accidentally do have the feature from those that usually have the feature, returning a posterior distribution very similar to the prior.
Hearing the generalization ("Dogs bark"), however, strongly signals the property is widespread in the category.

The strength of a listener's inference (i.e., how prevalent is the feature?) depends in systematic ways on the prior belief distribution over the prevalence of the feature.
Consider a prior intuitively corresponding to the feature "lays eggs" (Figure \ref{fig:simulations}, row 3). 
The listener's posterior upon hearing the generalization (e.g., "Robins lay eggs") is much more conservative than with "barks" prior: The listener thinks that about 50% of robins lay eggs.
Indeed, this is the same inference as if a listener heard "Robins are female" (Figure \ref{fig:simulations}, row 4, right panel). 
The intuitive differences in the endorsements of these statements comes from the speaker's comparison to what a listener would believe if she stayed silent (i.e., the listener's prior).
In the case of "are female", the posterior is nearly identical with the prior; thus, the utterance has very litle information content. 

Finally, we look at how a listener would interpret the statement "Mosquitos carry malaria", which intuitively should correspond to "Some mosquitos carry malaria".
Indeed, we see that for the prior over "carries malaria", which *a priori* assumes that most creatures do not carry malaria and among those that do, the feature is not very widespread, the listener's posterior upon hearing the generalization is similar to what she learns about hearing "Some mosquitos carry malaria". 
Thus, a speaker who believes "some but very few" mosquitos carry malaria will still endorse the generalization.

In the rest of this paper, we examine the validity and generality of this theory of communicating generalizations through three case studies: generalizations about categories, events, and causes.


<!-- Consider how an uniformly underspecified threshold would interact with a uniformly uncertain belief about a probability (recall the thresholds defines what probabilities or states of the world should be ruled out).  -->
<!-- If the threshold is very high, only the highest probabilities would be left (i.e., pass the threshold). -->
<!-- If the threshold is slightly lower but still high, the highest probabilities would still pass the threshold, as would some that are slightly lower. -->
<!-- As the threshold takes on lower and lower values, more and more probabilities would surpass it. -->
<!-- When the threshold is very low, almost all probabilities are consistent with it. -->
<!-- But since we don't know *a priori* what the threshold is likely to be, each of theses situations is plausible. -->
<!-- The posterior distribution on probabilities or states of the world will favor higher probabilities (because they pass more thresholds), but will still include probabilities that are quite low [though they are *a posteriori* unlikely; see Figure \ref{fig:simluations} ].  -->
<!-- Speakers, thus, will produce generalizations with some probability in each state of the world, though the speaker will say the generalization more often when the propensities associated with the states of the world are higher [see Figure \ref{fig:simluations}]. -->

<!-- - Figure -->
  <!-- - Subfigure 1 [width = 0.2] (Uniform priors) [two rows, left subfigure] -->
  <!--   -- Basic L0 posteriors on degrees for uncertain, fixed at 0 and fixed at 0.5 -->
  <!--   -- Basic S1 posteriors on utterances, for prevalence 0 - 1 (and for fixed thresholds) -->
  <!-- - Subfigure 2 [width = 0.8] (L0 vs. L1 lifted vs. L1 unlifted x 4 priors x {speaker, listener} ) [model as color, lty; priors as columns x {speaker, listeners} as rows]  -->
  <!--   -- priors = [uniform, n-shaped, u-shaped, mixture model / maybe put more in appendix: rare, accidental, female, eggs] -->

<!--
mht: is it possible to construct priors in causals that would reflect the qualitative prediction shown here?
-->






<!-- $P(x)$ is a distribution on the prevalence of a given property (e.g. \textsc{lays eggs}) across animal categories.  -->
<!-- In Figure \ref{fig:schematic-unif}, are $L_1$ (Eq.~\ref{eq:L1}) posterior prevalence distributions on $x$ (red solid line) for several example prior prevalence distributions $P(x)$ (blue dashed line), as well as the $S_2$ generic endorsement probability for different levels of prevalence. -->
<!-- We name these example prior distributions to suggest properties that might be associated with such priors.  -->
<!-- (Later, we will empirically measure these priors for properties of interest.) -->
<!-- First, we explore generic interpretation and endorsement for priors of three different shapes (left column).  -->
<!-- For each of these, the $L_1$ posterior distribution (red solid) over prevalence is heavily driven by the prior (blue dashed). -->
<!-- $S_2$ endorsement probabilities for the generic (black solid) increase as a function of prevalence, and what counts as "true" (in terms of the prevalence) depends on the prior.  -->

<!-- \begin{figure} -->
<!-- \centering -->
<!--     \includegraphics[width=\columnwidth]{figs/schematics_s2.pdf} -->
<!--     \caption{Schematic prior distributions for prevalence $x$ (blue dashed), the pragmatic listener $L_1$ model's posterior distribution over prevalence upon hearing a generic utterance (red), and speaker $S_2$ model's endorsement of a generic utterance for different levels of prevalence (black). -->
<!--     The names given to these priors are meant to be suggestive of what kinds of properties these distributions might correspond to. -->
<!--     The left column uses prevalence priors modeled as Beta(15,15), Beta(4,1), and Beta(4,16) distributions. -->
<!--       The right column uses a prior distribution that is a mixture of the distribution to the left of it with a second component, modeled as Beta(0.5, 4.5), reflecting categories with 0\% property prevalence. -->
<!--     Horizontal dashed line at 0.5 is for convenience of comparing the point at which an utterance becomes judged as more true than false for $S_2$. -->
<!-- 	Note that the prior distribution over prevalence will be the same as $L_1$'s posterior distribution upon hearing the "null" utterance. -->
<!--     } -->
<!--   \label{fig:schematic-unif} -->
<!-- \end{figure} -->


<!-- To take one example, consider the distribution over what might be the property "are female" (top-left facet). -->
<!-- The \emph{a priori} prevalence is centered around 0.5. -->
<!-- Because of pragmatics, the pressure to be \emph{truthful} will drive likely threshold values below 0.5 (lower values are more likely to be true).  -->
<!-- At the same time, the pressure to be \emph{informative} will drive the threshold values up: Higher values are more likely to be informative.  -->
<!-- The result is a posterior over prevalence that is only marginally greater than the prior, making higher prevalence values more likely after hearing the generic.  -->
<!-- But the relative information gain is very little (the posterior is not very different from the prior), and thus the $S_2$ model is reluctant to endorse the generic unless the property is exceedingly prevalent.  -->
<!-- The same basic phenomenon can be observed for the other two example priors (left column): The posterior over prevalence heavily depends upon the prior, but is also not very different from the prior. -->

<!-- We now imagine what would happen if there were some kinds where the property was completely absent, while being present at some rate in other kinds. -->
<!-- Figure \ref{fig:schematic-unif} (right column) shows this possibility: mixing the distribution to the left of it with a second component at 0\% prevalence. -->
<!-- Consider the schematic prior over "lay eggs". -->
<!-- We see the pragmatic listener $L_1$'s posterior prevalence distribution is not very different from the interpretation that doesn't include the second component in the prior (here, "are female"), but it is dramatically different from the prior with two components (compare red with blue dashed line for the right column). -->
<!-- This suggests that when many categories have 0\% prevalence, lower thresholds are informative.  -->
<!-- Indeed, the $S_2$ model predicts that the generic becomes felicitous at lower prevalence levels (compare black line of left v. right column). -->
<!-- For "lay eggs", when the property is prevalent in 50\% of the kind (e.g., 50\% of birds lay eggs), endorsement of the generic (e.g., \emph{Birds lay eggs}) by the $S_2$ is roughly 0.85; for "are female", with the same prevalence (50\% of birds are female), endorsement for \emph{Birds are female} is only 0.50: It is judged to be neither true nor false.  -->
<!-- The important result is the asymmetry: the first generic can be endorsed more strongly than the second, at the same prevalence level; the exact endorsement rates depend on quantitative aspects of the priors, which must be determined empirically. -->

<!-- The model thus predicts differences in truth judgments depending on the prevalence prior.  -->
<!-- The first test of our theory, then, will be to see if these predictions correspond to human truth judgments of familiar generic sentences.  -->




<!-- Next is a hypothetical speaker, who reasons about the literal listener when deciding which utterance to produce. -->
<!-- \begin{eqnarray} -->
<!-- S_{1}(u \mid x, \theta) &\propto& \exp{(\lambda_1 \cdot \ln {L_{0}(x \mid u, \theta)} ) }\label{eq:S1} -->
<!-- \end{eqnarray} -->
<!-- This speaker $S_1$ also knows the threshold $\theta$ and chooses utterances to convey information to the literal listener $L_0$ . -->
<!-- Following RSA, this speaker is an approximately rational (speech-)actor with degree with rationality governed by parameter $\lambda_1$. -->


<!-- For the case of understanding a generic (e.g., *Dogs are friendly*), the relevant dimension for the adopted semantics is the prevalence of property within the category (e.g., the \% of dogs that are friendly). -->
<!-- In this model, a threshold $\theta$ is established in context by a Bayesian listener reasoning about what threshold would make this utterance true? -->



<!-- The model begins with a simple Bayesian agent---a literal listener---who updates her prior beliefs $P(x)$ according to the truth-functional meaning of the utterance heard $\denote{u}$. -->
<!-- \begin{eqnarray} -->
<!-- L_{0}(x \mid u, \theta) &\propto& {\delta_{\denote{u}(x, \theta)} \cdot P(x)} \label{eq:L0} -->
<!-- \end{eqnarray} -->
<!-- For the generic sentence, we assign the simplest possible meaning, a threshold on the prevalence: $\denote{u_{generic}} = P(F\mid K)>\theta$. -->

<!-- The likelihood $\delta_{\denote{u}(x)}$ is the Kronecker delta function returning $1$ for states $x$ compatible with utterance $u$ (i.e., where the prevalence $x$ is above the threshold $\theta$), and $0$ otherwise. -->
<!-- The literal listener is a hypothetical agent who knows the threshold $\theta$. -->

<!-- Next is a hypothetical speaker, who reasons about the literal listener when deciding which utterance to produce. -->
<!-- \begin{eqnarray} -->
<!-- S_{1}(u \mid x, \theta) &\propto& \exp{(\lambda_1 \cdot \ln {L_{0}(x \mid u, \theta)} ) }\label{eq:S1} -->
<!-- \end{eqnarray} -->
<!-- This speaker $S_1$ also knows the threshold $\theta$ and chooses utterances to convey information to the literal listener $L_0$ . -->
<!-- Following RSA, this speaker is an approximately rational (speech-)actor with degree with rationality governed by parameter $\lambda_1$. -->



<!-- For the generic sentence, we assign the simplest possible meaning, a threshold on the propensity: $\denote{u_{generic}} = P(F\mid K)>\theta$. -->
<!-- The prior distribution $P(h)$ is a distribution over likely degrees of propensity.  -->
<!-- For the case of understanding a generic (e.g., *Dogs are friendly*), the relevant dimension for the adopted semantics is the prevalence of property within the category (e.g., the \% of dogs that are friendly). -->

<!-- Life is only so long, however, and a person can only be in one place at a time. -->
<!-- The amount of data we can gather about any particular category, event, or causal force is extremely limited by these physical constraints. -->
<!-- Thus, it would be useful if language provided a simple way to communicate these generalizations to one another. -->





<!-- # A Formal Theory of Generalizations in Language -->

<!-- We find both the statistical and conceptual accounts compelling, but an important perspective is missing. -->
<!-- Linguistic generalizations are not unique in their flexibility. -->
<!-- Understanding language in general depends upon assumptions interlocutors make about each other and what content is under discussion.  -->
<!-- Viewing language understanding as a social reasoning process reveals that utterances carry a mosaic of interpretations with a complex sensitivity to context [@Clark1996; @Grice1975; @Levinson2000].  -->
<!-- Can the puzzles of generic language be understood as effects of pragmatic reasoning? -->
<!-- If so, we may be able to get away with a relatively simple, statistical,  semantic theory. -->
<!-- Abstract mental representations, then, may be the conceptual backdrop against which generic language is interpreted.  -->

<!-- We pursue such a line of inquiry, assuming the simplest truth-conditional meaning: a threshold on prevalence $P(F\mid K)>\theta$ [c.f., @Cohen1999]. -->
<!-- No fixed value of the threshold, $\theta$, would allow for the extreme flexibility generics exhibit (e.g. \emph{Mosquitos carry malaria}; \emph{Robins lay eggs} v. \emph{Robins are female}),  -->
<!-- so instead we allow this threshold to be established in context through pragmatic reasoning. -->
<!-- Such an inference would depend on background knowledge about properties and categories---potentially structured, conceptual knowledge. -->
<!-- This inference, nonetheless, is a general mechanism of understanding language, not specific to interpreting generic statements. -->
<!-- We formalize this hypothesis in the Rational Speech Act (RSA) theory---a formal, probabilistic theory of language understanding. -->
<!-- RSA is derived from social reasoning, formalized as recursive Bayesian inference between speaker and listener [@Frank2012; @Goodman2013; @Goodman2016; see also, @Franke2009; @Franke2015]. -->
<!-- @Goodman2016 provides a good introduction to the RSA framework and Appendix A presents a brief tutorial on RSA for the reader unfamiliar. -->


<!-- The model begins with a simple Bayesian agent---a literal listener---who updates her prior beliefs $P(x)$ according to the truth-functional meaning of the utterance heard $\denote{u}$. -->
<!-- \begin{eqnarray} -->
<!-- L_{0}(x \mid u, \theta) &\propto& {\delta_{\denote{u}(x, \theta)} \cdot P(x)} \label{eq:L0} -->
<!-- \end{eqnarray} -->
<!-- For the generic sentence, we assign the simplest possible meaning, a threshold on the prevalence: $\denote{u_{generic}} = P(F\mid K)>\theta$. -->
<!-- The prior distribution $P(x)$ is a distribution over likely states of the world.  -->
<!-- For the case of understanding a generic (e.g., *Dogs are friendly*), the relevant dimension for the adopted semantics is the prevalence of property within the category (e.g., the \% of dogs that are friendly). -->
<!-- The likelihood $\delta_{\denote{u}(x)}$ is the Kronecker delta function returning $1$ for states $x$ compatible with utterance $u$ (i.e., where the prevalence $x$ is above the threshold $\theta$), and $0$ otherwise. -->
<!-- The literal listener is a hypothetical agent who knows the threshold $\theta$. -->


<!-- To understand how language is interpreted pragmatically, we model a pragmatic listener $L_1$ who updates her prior beliefs $P(x)$ by reasoning about the generative process of the utterance, the speaker model $S_1$. -->
<!-- \begin{eqnarray} -->
<!-- L_{1}(x , \theta \mid u) &\propto& S_{1}(u \mid x, \theta) \cdot P(x) \cdot P(\theta) \label{eq:L1} -->
<!-- \end{eqnarray} -->
<!-- Following @Lassiter2013, we model the pragmatic listener as having uncertainty about the threshold: $P(\theta)$. -->
<!-- Though the listener doesn't know the threshold *a priori*, she resolves the threshold (i.e., the meaning) in context by integrating her prior beliefs $P(x)$ with the basic principles of communication to be truthful and informative, instantiated in her model of the speaker $S_1$ [@Lassiter2015; @GoodmanLassiter]. -->
<!-- In principle, thresholds could be learned over time for different contexts, but here we assume the listener has no informative knowledge about the semantic variable $P(\theta) = \text{Uniform([0, 1])}$. -->
<!-- The pragmatic listener $L_1$ (Eq. \ref{eq:L1}) is thus a model of *generic interpretation*: Upon hearing a generic, how should a listener update her beliefs? -->



# Case Study 1: Generic Language

Generalizations about categories (i.e., *generic language*) have received substantial interest in psychology for their role in concept formation [@Gelman2004] and stereotype propogation [@Rhodes2012].
Generic language (e.g., *Birds fly.*) exhibits substantial flexibility in meaning and truth conditions as described above.
<!-- At first glance, generics feel like universally-quantified statements as in *All* birds fly.  -->
<!-- Unlike universals, however, generics are resilient to counter-examples (e.g., *Birds fly* seems true even in the face of flightless birds like kiwis or penguins). -->
<!-- *Most* birds fly seems more reasonable, and yet most mosquitos *do not* carry malaria while *Mosquitos carry malaria* seems like a true statement. -->
<!-- Finally, the probability of a bird being female is much higher than the probability of a mosquito carrying malaria, but *Birds are female* seems weird to say. -->
<!-- *Birds lay eggs*, however, is fine, even though the rate is the same as *are female* (only females lay eggs). -->

<!-- Empirical work done on category generalizations has elucidated another puzzling phenomenon. -->
<!-- Generic statements often imply the property is widespread in the category [e.g., *Swans have hollow bones* implies something much stronger than *Some swans have hollow bones*; @Gelman2002; @Cimpian2010; @Brandone2014]. -->
<!-- This characteristically strong interpretation interacts with the indeterminacy in truth conditions, resulting in an *asymmetry* between endorsement and interpretation. -->
<!-- For a variety of features, both children and adults infer that a property is *more* prevalent when told the generalizations than when judging it true or not [@Cimpian2010; @Brandone2014]. -->


As a first test of our theory, we wish to explain the flexibility in endorsements of generics in terms of the relevant prior knowledge about properties and show how it systematically predicts endorsements of familiar generic statements (Expt. 1).
In Experiment 3, we replicate and extend a paradigm used by @Cimpian2010 to demonstrate the asymmetry between endorsements and interpretations and find that a similar pattern is predicted by our model.

We evaluate our family of RSA models, in addition to some ad-hoc non-Bayesian models, on these experimental data.
Because the ad-hoc models do not comprise a formalized alternative theory of endorsement and interpretation, but rather statistical descriptions of the data, we compare the ad-hoc models to the simplest RSA model on endorsement and interpretation, separately.
After presenting the results of Expts. 2 \& 3, we compare RSA models on their ability to jointly predict both endorsement and interpretation data simultaneously. 


<!-- Interpreting the generic as meaning "most" (i.e. \emph{Most swans are white}) captures many cases, but cannot explain why \emph{Robins lay eggs} and \emph{Mosquitos carry malaria} are so intuitively compelling: Only adult female robins lay eggs and a very tiny fraction of mosquitos actually carry malaria. -->
<!-- Indeed, it appears that any \emph{truth condition} stated in terms of how common the property is within the kind violates intuitions. -->
<!-- Consider the birds: for a bird, being female practically implies you will lay eggs (the properties are present in the same proportion), yet we say things like \emph{Birds lay eggs} and we do not say things like \emph{Birds are female}. -->


<!-- One case study in the language of generalizations is about category generalizations. -->
<!-- Category generalizations, called *generic statement*, has been studied extensively in cognitive and developmental psychology: *generic* statements, or generalizations about categories. -->


<!-- These *strong implications* might underly stereotype formation in social categories [@Rhodes2012]. -->
<!-- In addition to the flexibility in truth conditions, two phenomena have been noted.  -->
<!-- The case of *Mosquitos carry malaria* suggests the utterance must in some way be analogous to the quantifier "some" (e.g., *Some mosquitos carry malaria*).  -->
<!-- Generic language, however, is often interpreted as implying the property is widespread: *Swans have hollow bones* means something different than *Some swans have hollow bones* [@Gelman2002]. -->

<!-- These three phenomena---flexible truth, strong interpretations, and evidence exaggeration---have confounded all formal models aimed to capture the meaning of generalizations in language. -->
<!-- Informal theories have argued that the nature of concepts and their relations are inextricably tied to their linguistic expression [@Leslie2007; @Prasada2013]. -->
<!-- Formal theories have limited themselves to a measurable quantitative degree (e.g., how prevalent a property is in a category), which, in isolation, is difficult to reconcile with the extreme flexibility of generic language. -->
<!-- Here, we present a theory formalizing the inuition that the core meaning of a linguistic generalization is simple, but underspecified, and that general principles of communication may be used to resolve the precise meaning in context.  -->
<!-- This theory inherently relies upon measurable quantities (i.e., prevalence) but situates it within a Bayesian agent with potentially structured prior knowledge, providing a bridge to conceptual theories.  -->
<!-- We find that this formalism (and not simpler ones) explains all three empirical puzzles. -->

<!-- When interpretations are compared directly against truth conditions (i.e., how prevalent a property would need to be for the generic to be true),  -->

<!-- Three empirical phenomena make generalizations in language difficult to formalize. -->
<!-- The conditions under which a generalizations becomes "true" are variable: -->


<!-- Existing work in both adults and children suggests that choosing to communicate a generalization can be used to exagerate evidence [@Cimpian2010; @Brandone2014]. -->

<!-- In addition to having manifold interpretations, what makes linguistic generalizations true or false (i.e., their truth conditions) is also a mystery. -->
<!-- The statement *Birds lay eggs* is true even though only about half of them do (namely, the females). -->
<!-- Half of birds are also female, and yet *Birds are female* sounds like a strange thing to say. -->
<!--  while *Canadians are right-handed* is also weird, even though the vast majority of them are.  -->

## Experiment 1: Endorsing generalizations about categories

Any theory of generic language must explain their puzzling flexibility of usage with respect to prevalence.
That is, \emph{Mosquitos carry malaria} and \emph{Birds lay eggs} are reasonable things to say, but \emph{Birds are female} is not.
<!-- The pragmatic speaker model $S_2$, Eq.~\ref{eq:S2}, is a model of truth judgments.  -->
We test our model on thirty generic sentences that cover a range of conceptual distinctions discussed in the literature [@Prasada2013]: characteristic (e.g. \emph{Ducks have wings.}), minority (e.g. \emph{Robins lay eggs.}), striking (e.g. \emph{Mosquitos carry malaria.}), false generalization (e.g. \emph{Robins are female.}), and false (e.g. \emph{Lions lay eggs.}).
In additional to the canonical cases from the linguistics literature, we selected sentences to elicit the full range of acceptability judgments (intuitively: "acceptable", "unacceptable", and "indeterminate") with low-, medium-, and high-prevalence properties. 

To compare the model to empirical truth judgments, we first measure the prior distribution over prevalence of these properties (Expt. 1a).
We hypothesize that this prior distribution encodes probabilities associated with deeper conceptual knowledge [e.g., of the kind discussed by @Prasada2013].
This would be one way in which our theory touches upon other psychological accounts of generic language [cf., @Prasada; @Gelman; @Leslie].
If, indeed, there are such things as different types of kind--property relations (e.g., *principled* v. *accidental relations*), we would expect the prevalence prior data to follow a multi-modal, mixture distribution where different modes or components of the prior are the results of the different types of relations.
As a simple of this hypothesis, we compare a structured (i.e., mixture) model of the prior data to an unstructured one.

After exploring the prevalence prior, we move on to the issue of primary theoretical interest: How well our *simple but underspecified* hypothesis accounts for endorsements of generic sentences (Expt. 1b).

### Experiment 1a: Measuring the Prevalence Prior for Categories

The prior $P(h)$ in Eq. \ref{eq:L0} describes the belief distribution on the prevalence of a given property (e.g. \textsc{lays eggs}) across relevant categories. 
To get an intuition for the kind of knowledge encoded in this belief distribution, imagine your favorite kind of animal.
Then answer, "what percentage of that kind of animal is female?".
The answer is probably 50\%. 
Then ask yourself, "what percentage of that kind of animal lays eggs?".
Depending on what animal you thought of, the answer is probably either 50\% or 0\% (e.g., lions, tigers, and bears each have 0\% egg-laying members).

This decomposition of the prevalence prior $P(h)$ into a kind prior $P(k)$ and then a conditional probability of the prevalence of the feature given the kind $P(h \mid k)$ is one way to measure the prevalence prior $P(h) = \int_{k} P(h \mid k) \diff k$.
We measured this distribution by employing this technique empirically for the set of properties (e.g. \textsc{lays eggs, carries malaria}; 21 in total) used in our target sentences. 
We then ask whether a structured, prior model accounts better for this data than an unstructured model.
 
#### Method

##### Participants

We recruited 60 participants over Amazon's crowd-sourcing platform Mechanical Turk (MTurk).  
Participants were restricted to those with US IP addresses and with at least a 95\% MTurk work approval rating (the same criteria apply to all experiments reported). 
3 participants were accidentally allowed to complete the experiment for a second time; we excluded their second responses (resulting in $n=57$).
2 participants self-reported a native language other than English; removing their data ($n=55$) has no effect on the results reported. 
The experiment took about 10 minutes and participants were compensated \$1.00.

##### Procedure and materials

On each trial of the experiment, participants filled out a table where each row was an animal category and each column was a property. 
Participants first were shown six animal categories (randomly sampled from a set corresponding to the generic sentences used in Expt. 1b (e.g. \textsc{robins, mosquitos}) and asked to generate five of their own.

A column then appeared to the right of the animal names with a property in the header (e.g., "lays eggs").
Participants were asked to fill in each row with the percentage of members of each of the species that had the property by giving a number (e.g., "50\%").
Eight property--columns appeared in the table, and this whole procedure was repeated 2 times.
In total, each participant generated 10 animal names and reported on the prevalence of sixteen properties for 22 animals (their own 10 and the experimentally-supplied 12). 
For a full list of the properties, and generic sentences used in Expt. 1b, see Table 2 (Appendix).
The experiment can be viewed at \url{http://stanford.edu/~mtessler/experiments/generics/experiments/real-kinds/prior-2.html}.

### Bayesian analysis

We begin by exploring the hypothesis that the prior is structured as a result of deeper conceptual knowledge
We formalize this hypothesis using a simple, Bayesian mixture model. 
We test the simplest "structural" hypothesis, where there are two distinct components, for example, if participants believe that some kinds have a causal mechanism that *could* give rise to the property, while kinds others do not [@Griffiths2005].
In this task, participants give responses in the form of numbers between 0 and 100 (or, rescaled to be between 0 - 1).
The canonical prior for generating numbers between 0 - 1 is the Beta distribution.

We then assume the data, for each item independently, was generated from one of two distributions: a distribution corresponds to those kinds with a stable causal mechanism that *could* give rise to the property ($\mathcal{D_{stable}}$) or a distribution corresponding to those kinds without a stable mechanism ($\mathcal{D_{transient}}$).
The "transient" distribution intuitively corresponds to accidental causes of the feature (e.g., a lion, who through some genetic mutation, reproduces by laying eggs).
We model this distribution as a Beta distribuition that heavily favors values near 0: $\text{Beta}(1, 100)$.
The "stable" distribution is modeled as a Beta distribution with unknown parameters $\text{Beta}(\alpha, \beta)$.^[
Because the Beta distribution is not defined at the points 0 and 1, we add $\epsilon$ to the 0 responses and round 1 to 0.99.
Adjusting 1 to $1- \epsilon$ leads to improper inferences for this model, as $1 - \epsilon$ is only likely under a highly right-skewed distribution; this would disproportionately influence the shape of $D_{stable}$. 
This problem does not appear for 0 being adjusted to $\epsilon$ as we explicitly posit a left-skewed "transient" distribution.
Similar results can be obtained by rounding 0 to 0.01. 
Alternatively, the "transient" distribution could be defined as a Delta distribution at 0, and 0 responses could remain in their raw form.
]
Finally, we assume that these two components combine with some weighting $\phi$ such that the data we observe is $$P(d) = \phi\cdot \text{Beta} (d \mid \alpha, \beta) + (1 -  \phi) \cdot \text{Beta}(d \mid \alpha = 1, \beta = 100) $$.

We put priors over the latent parameters of this model and infer their credible values by way of Bayesian infernence.

\begin{eqnarray}
\theta & \sim & \text{Uniform}(0, 1) \\
\alpha & \sim & \text{Uniform}(0, 100) \\
\beta & \sim & \text{Uniform}(0, 100) \\
\end{eqnarray}

To see how well this data-analytic model fits the prevalence prior data, we can use the inferred parameters to generate new data.
This is called the *posterior predictive distribution* and is an important step in model validation. 
If the model is a good representation of the data, the posterior predictive data will align with the experimental data. 
We construct a posterior predictive distribution by "forward sampling" the model.^[
This can be described by the following algorithm: First, flip a coin weighted by $\theta$.
If it comes up heads, we then sample from the "stable" component: $\text{Beta}(\alpha, \beta)$.
If it comes up tails, we sample from the "transient" component: $\text{Beta}(1, 100)$.
We do this many times using the posterior distibution to generate a distribution over predicted prevalence ratings.
]

We implemented this statistical model using the probabilistic programming language WebPPL [@dippl].
To learn about the credible values of the parameters, we ran separate MCMC chains for each item, collecting 75,000 samples, removing the first 25,000 for burn-in.


```{r generic-endorsement-priors, eval = F}
d.gen.endorse.priors <- read.csv(paste(project.path, 
                                       "data/generics/endorsement/",
                                       "naturalGenerics-prior-trials-n57.csv", sep = ""))
gen.endorse.properties <- levels(d.gen.endorse.priors$Property)

genericEndorsementPriorModel <- '
var eps = 0.01;//Number.EPSILON;
var log = function(x){ return Math.log(x) }
var exp = function(x){ return Math.exp(x) }

var avoidEndPoints = function(x){
  x == 0 ? eps : 
  x == 1 ? 1 - eps : 
  x
}

var betaShape = function(params){
  return {
      a: params.g * params.d,
      b : (1-params.g) * params.d
  }
}

var preprocessedResponses = map(function(d){
  return avoidEndPoints(d / 100)
}, data)

var model = function(){
  var phi = uniformDrift({a:0, b: 1, width:0.2});
  //var a = uniformDrift({a:0, b: 100, width:5});
  //var b = uniformDrift({a:0, b: 100, width:5});
  var g = uniformDrift({a:0, b: 1, width:0.2});
  var d = uniformDrift({a:0, b: 100, width:5});
  var stableParams = betaShape({g, d})
  var stableComponent = Beta(stableParams)
  var transientComponent = Beta({a:1, b:100})
  mapData({data: preprocessedResponses}, function(d){
    factor( log(
      phi * exp(stableComponent.score(d)) +
      (1 - phi) * exp(transientComponent.score(d))
    ))
  })

  var marginalPrevalence = sample(flip(phi) ? stableComponent : transientComponent)
  return {g, d,phi, marginalPrevalence}
}
'
marginal.prevalence <- data.frame()
m.gen.endorse.priors.summary <- data.frame()

for (p in gen.endorse.properties){
  priorData <- filter(d.gen.endorse.priors, Property == p)$prevalence
  m.gen.endorse.priors <- webppl(genericEndorsementPriorModel, data = priorData, data_var = "data",
         model_var = "model", inference_opts = list(method = "MCMC", samples = 1000, burn = 500, verbose = T))
  
  marginal.prevalence <- bind_rows(marginal.prevalence, 
                                   m.gen.endorse.priors %>% 
                                     filter(Parameter == "marginalPrevalence") %>%
                                     mutate(Property = p))
  
  m.gen.endorse.priors.summary <- bind_rows(m.gen.endorse.priors.summary,
                                            m.gen.endorse.priors %>% 
                                              mutate(Property = p) %>%
                                              group_by(Property, Parameter) %>%
                                              summarize(MAP = estimate_mode(value),
                                                        cred_upper = hdi_upper(value),
                                                        cred_lower = hdi_lower(value))
                                              )
  #print(p)
}

```
```{r, eval = F}

ggplot(m.gen.endorse.priors.summary %>% filter(Parameter == 'phi') %>%
         mutate(Property = factor(Property, levels = Property[order(MAP)]) ),
       aes( x = Property, y = MAP, ymin = cred_lower, ymax = cred_upper))+
  geom_bar(stat = 'identity', position = position_dodge())+
  geom_errorbar(position = position_dodge())+
  coord_flip()+
  ylab("MAP estimate and 95% HDI of Mixture parameter")
  
```


### Results

The prevalence prior data is indeed structure.

We also see tremendous variability in the shapes of these prevalence distributions.

<!-- To process the priors data, we discretize the prevalence judgments to 12 discrete bins: $\{[0-0.01), (0.01-0.05), (0.05-0.15), (0.15-0.25),  ..., (0.75-0.85), (0.85-0.95), (0.95-1]\}$, and look at the counts within each bin, after doing add-1 Laplace smoothing, as the relative probability of that prevalence.  -->
<!-- Do a BDA to describe the data in a more compact form. -->
<!-- We can explore how the underspecified-threshold listener model $L_{0}(x , \theta \mid u)$ (Eq. \ref{eq:L0}) interprets generic utterances with these priors on prevalence (Figure \ref{fig:commongenerics}a, insets).  -->
<!-- The prior beliefs over the prevalence of the property, $P(h)$, can also be interpreted as the pragmatic listener's posterior upon hearing the null utterance, because the null utterance has no information content. -->
<!-- We see the interpretation of the generic is quite variable across our empirically measured priors. -->
<!-- For instance, in the case of \textsc{carries malaria}, the prior is very left-skewed; with this prior, the threshold $\theta$ can plausibly be very low because high prevalence is unlikely. -->
<!-- Properties like \textsc{doesn't attack swimmers} are very right-skewed; with this prior, not many thresholds lead to a substantial update in beliefs, and so the generic is unlikely to be used by speaker $S_1$ unless the property is practically-universal within the target category.  -->
<!-- Some properties have priors that are unimodal with low variance (e.g. \textsc{is female}); these properties are present in every kind in almost exactly the same proportion. The model  and thus are too obvious and certain to allow for an informative generic utterance: The posterior is not very different from the prior.  -->
<!-- With $P(x)$ now empirically established, we can test if our speaker model predicts human truth judgments of generic statements about these properties. -->


### Experiment 1b: Endorsing generic statements

Having measured the prevalence prior distribution (e.g., the prevalence of laying eggs for different kinds of animals) in addition to target-category prevalence (e.g., how many robins lay eggs; Expt. 1a), our speaker model (Eq. \ref{eq:S1}) can predict endorsements for the corresponding generic statements (e.g., Robins lay eggs).
To test these predictions, we collect human endorsements for thirty generic statements taken from the linguistic and psychological literature on generics [@Prasada2013].

#### Method

```{r generic-endorsement}
d.gen.endorse.catch <- read.csv(paste(project.path, "data/generics/endorsement/",
                    "truth-judgments_catch-trials.csv", sep = ""))

d.gen.endorse <- read.csv(paste(project.path, "data/generics/endorsement/",
                    "truth-judgments.csv", sep = ""))


d.gen.endorse.summary <- left_join(
  d.gen.endorse, 
  d.gen.endorse.catch %>% select(workerid, pass)
  ) %>%
  filter(pass == 1) %>%
  rowwise() %>%
  mutate(response = ifelse(response == "agree-key", 1, 0),
         sentence = gsub('&quotechar', '', sentence),
         sentence = gsub('lyme', 'Lyme', sentence)) %>%
  group_by(sentence) %>%
  multi_boot_standard(column = "response") %>%
  ungroup() %>%
  mutate(sentence = factor(sentence, levels = sentence[order(mean)]))

d.gen.endorse.bayes <- left_join(
  d.gen.endorse, 
  d.gen.endorse.catch %>% select(workerid, pass)
  ) %>%
  filter(pass == 1) %>%
  rowwise() %>%
  mutate(response = ifelse(response == "agree-key", 1, 0),
         sentence = gsub('&quotechar', '', sentence),
         sentence = gsub('lyme', 'Lyme', sentence)) %>%
  group_by(sentence) %>%
  summarize(k = sum(response), n = n()) %>%
  ungroup() %>%
  mutate(a = 1 + k,
         b = 1 + n - k,
         low  = qbeta(.025, a, b),
         high = qbeta(.975, a, b),
         MAP_h = (a-1)/(a+b-2),
         mean = a / (a + b)) %>% 
  ungroup() %>%
  mutate(sentence = factor(sentence, levels = sentence[order(MAP_h)]))


# d.gen.endorse.summary %>%
#   ggplot(., aes(x = sentence, y = mean, ymin = ci_lower, ymax = ci_upper))+
d.gen.endorse.bayes %>%
  #ggplot(., aes(x = sentence, y = MAP_h, ymin = low, ymax = high))+
  ggplot(., aes(x = sentence, y = MAP_h - 0.5, ymin = low - 0.5, ymax = high - 0.5))+
  geom_bar(stat = 'identity', position = position_dodge(),fill = 'grey')+
  geom_linerange(position = position_dodge())+
  #geom_errorbar(position = position_dodge())+
  coord_flip()+
  ylab("Proportion Endorsement")+
  xlab("")+
  #scale_y_continuous(limits = c(0,1), breaks = c(0, 0.5, 1))+
  scale_y_continuous(limits = c(-0.5,0.5), breaks = c(-0.5, 0, 0.5), labels = c(0, 0.5, 1))#+
  #geom_hline(yintercept = -0.25, lty = 3)+
  #geom_hline(yintercept = 0.25, lty = 3)
```

##### Participants

We recruited 100 participants over MTurk. 
4 participants were excluded for failing to pass a catch trial.
5 participants self-reported a native language other than English; removing their data has no effect on the results reported. 
The experiment took about 3 minutes and participants were compensated \$0.35.

##### Procedure and materials

Participants were shown thirty generic sentences in a randomized order.
They were asked to press one of two buttons (randomized between-participants) to signify whether they agreed or disagreed with the sentence (see Table 2 in Appendix for complete list). 
The thirty sentences were presented in a random order between participants and covered a range of conceptual categories described above.
Approximately 10 true, 10 false, and 10 uncertain truth-value generics were selected.

As an attention check, participants were asked at the end of the trials which button corresponded to "Agree".
4 participants were excluded for failing this trial.

#### Data and model analysis

As a manipulation check, the first author assigned an \emph{a priori} truth-judgment (true/false/indeterminate) to each stimulus item.
This was a significant predictor of the empirical truth judgments: true generics were significantly more likely to be agreed with than the indeterminate generics ($\beta = 3.14; SE = 0.15; z = 21.5$), as revealed by a mixed-effect logistic regression with random by-participant effects of intercept.
Indeterminate generics were agreed with \emph{less} likely than chance ($\beta = -0.49; SE = 0.09; z = -5.3$) but significantly more than false generics ($\beta = 2.09; SE = 0.14; z = 14.5$).

In addition to these categorical differences between our thirty generic statements, we find a contiuum of endorsement values (Figure \ref{fig:generic-endorsement}).
This argues against any simple theory that only predicts whether or not a generic statement is true or false. 
Ideally, a complete theory of genericity should be able to explain statements that are endorsed completely, unendorsed completely, and all shades in between.

To try to understand this endorsement data, we articulate alternative models that have been proposed in the literature and a reduced-form of our proposed RSA model. 
As the simplest baseline hypothesis, we first explore whether prevalence itself predicts generic endorsement (e.g., does the fraction of \textsc{robins} that \textsc{lay eggs} predict the felicity of *Robins lay eggs*?).
As a secondary alternative hypothesis, we explore whether prevalence and *cue validity* (the probability of a kind given the feature; described in more detail below) predicts generic endorsement of these items.

Our underspecified threshold model has access to the full prior distribution on prevalence $P(h)$, from which it infers likely thresholds for the generic. 
The endorsement model is a model of a speaker who is deciding whether or not to say the generic.
There are thus three unique components of this model: (i) the prior distribution $P(h)$, (ii) the speaker model deciding whether or not to produce the generic, and (iii) the uncertain threshold.
As a control model, we use the same infrastructure but assign the semantics of "Some" to the utterance (i.e., a fixed-threshold which only rules out the lowest possible degree). 
This control model has both features (i) and (ii) but lacks the uncertainty over the threshold.
This provides a strict test of our *simple but underspecified* hypothesis.

##### Prevalence baseline

From the prevalence prior data (Expt. 1a), we estimate participants' beliefs about the prevalence of a property for the target categories (e.g., the percentage of \textsc{robins} that \textsc{lay eggs}.
We find a little over half of the variance in the endorsement data is explained this way ($r^2 = 0.599$; MSE=0.065; Figure \ref{fig:commongenerics}b, right). 
This is because our stimulus set includes generics that are true with high-prevalence properties (e.g., *Leopards have spots.*) and generics that are false with low prevalence properties (e.g., *Leopards have wings.*). 
However, large deviations from an account based purely on target-category prevalence remain: Generics in which the target-category has intermediate prevalence (prevalence quartiles 2 and 3: $ 20\% < prevalence < 64\%$), are not at all explained by prevalence within those categories ($r_{Q2,3}^2 = 0.029$; MSE = 0.110).

##### Prevalence and cue validity

<!-- As a secondary alternative hypothesis, we explore whether prevalence and *cue validity* predicts generic endorsement of these items. -->
If prevalence is the "forward probability" (e.g., one's predictions about whether or not an entity will lay eggs after learning that the entity is a robin), *cue validity* is the inverse probability: $P(k \mid f)$ (e.g., one's predictions about whether or not the entity is a robin, upon learning that it lays eggs).
*Cue validity* measures the salience of a category given a feature but also captures the distinctiveness of the feature. 
For example, if one learns that an entity carries malaria, that entity is probably a mosquito because only mosquitos carry malaria. 
Previous studies have found cue validity to be correlated with generic endorsement [@Khemlani2012], though a strong version of cue validity has been argued against on *a priori* grounds [@Leslie2007; @Leslie2008].

For a prevalence distribution with a fixed set of categories, the cue validity of a kind given a feature can be calculated from the prevalence prior distribution (i.e., it is a summary statistic of this distribution).
In empirical studies of generic language, however, it is often empirically measured [@Khemlani2012].
To measure cue validity, we employed a free production paradigm, following @Cree2006.
Participants ($n = 50$) were supplied with a feature (e.g., "X lays eggs") and asked to generate a kind (e.g., "what do you think X is ?").
For a detailed discussion of the results of this experiment and comparison to other measurements of cue validity, see Appendix.

A linear model that uses predictors for both prevalence and cue validity does a better job at explaning the endorsement data than just prevalence alone ($r^2(30) = 0.79$).
This model is able to account for the endorsements of examples like "Mosquitos carry malaria" and "Lions have manes", as these features are very diagnostic of the kind.
Deviations, however, still remain.
For example, "Robins lay eggs" still receives only intermediate endorsement by this model, and "Mosquitos don't carry malaria" is judged to be a good statement.

These highlight a shortcoming of cue validity, which is in fact a point-summary statistic based on the prevalence distribution (see Appendix more details).
"Lays eggs" is a somewhat diagnostic features for *birds*, but there are many kinds of birds, and the feature is not itself diagnostic for "Robins".
A single metric like cue validity is too blunt to capture this subtlety.
Additionally, negative properties (like, "not carrying malaria") are completely undiagnostic for almost every category, and the learned regression model doesn't know how to penalize "Mosquitos don't carry malaria" because the prevalence is high.

##### Fixed threshold RSA model

The RSA model we propose for generic endorsement is a speaker model who decides whether or not to say the generic to a naive listener, who has access to the full prior distribution on prevalence $P(h)$.
As a strong alternative model, we retain the specification of the speaker reasoning about a listener with this prior distribution, but remove the uncertainty about the generic threshold. 
For this model, we set $\theta = 0$, and thus the generic statement corresponds to the quantified statement "Some".

<!-- Our pragmatic speaker model, $S_1$ in Eq. \ref{eq:S1}, reasons about whether it would be useful to say to the generic to this kind of listener so that the listener may acquire the same beliefs as the speaker (represented as the prevalence of the property within the target category $h'$). -->
We use the empirically estimated within-kind target prevalence as the $h$ that the speaker $S_1$ is trying to communicate, and use the empirically measured priors from Expt. 1a as the listener's prevalence prior $P(h)$.^[
Rather than trying to communicate a particular $h$, the speaker could plausibly try to communicate her full belief distribution over $h$ to the listener. This corresponds to the more general form of the model described in **Alternative Formulations** section. With these data, the predictions of these two models are nearly identical.
]
The $S_1$ model is then fully specified after setting the speaker optimality parameter $\lambda_1$ (in Eq. \ref{eq:S1}).
We infer this parameter, as well as the values of target prevalence $h$, and parameters of the prevalence priors $P(h)$ (assuming the structured model validated in Expt. 1a) using Bayesian data analysis [@LW2014].
For the prevalence parameters, we use the same priors described in Expt. 1a; for the speaker optimality parameter, we use an informative prior, with a range consistent with previous literature using the same model class: $\lambda_1 \sim \text{Uniform}(0,5)$.
We learn about the \emph{a posteriori} credible values of our model parameters by collecting samples from MCMC chains of 10,000 iterations removing the first 5,000 iterations, using the Metropolis-Hastings algorithm. 

We compare the "Some" model's posterior predictive distribution of generic endorsement to the empirical truth judgments.
(The posterior predictive distribution marginalizes over the inferred parameter values to produce predictions about what the data \emph{should look like} given the pragmatics model and the observed data.)
In accord with intuition, assigning a fixed semantics corresponding to "Some" is too lenient a specification. 
Even for patently false generics (e.g., "Mosquitos don't carry malaria"), the speaker model is unable to prefer staying silent than producing the generic (with a "some" semantics).
It also doesn't strongly prefer producing the generic, possibly because the information content is so small.

##### Uncertain threshold RSA model with universal priors

##### Uncertain threshold RSA model with diverse priors

Our underspecified threshold model is the same as the fixed-threshold RSA model described above, except that rather than having a fixed threshold at $\theta = 0.5$, it has *a priori* uncertainty over the threshold.
We perform the same Bayesian data analysis as the "Some" model.
As we see in Figure \ref{fig:commongenerics}b, the pragmatic speaker model $S_2$, using empirically measured priors, explains nearly all of the variance in human truth judgments ($r^2=0.98$; MSE=0.003; Figure \ref{fig:commongenerics}b). 


```{r generic-fullmodel}
# Look at KL model for what the prev distributions look like

n_chains <- 1
n_samples <- 100000
burn <- n_samples

model_prefix <- "results-fullModel-s1-allowUPriors-refinedPriors-fixedNull-prevPriorFactorBugFixed-smtncsgeneric-"

m.samp <- data.frame()
for (i in seq(1, n_chains)){
  mi <- fread(paste(project.path,  "models/generics/results/", model_prefix, 
                    n_samples, "_burn", burn, "_chain", i, ".csv", sep = ""))
  m.samp.i <- mi %>% mutate(chain = i)
  m.samp <- bind_rows(m.samp, m.samp.i)
  #print(i)
}


example.generics.properties <- c("dont eat people", 
                      "carry malaria", 
                      "lay eggs", 
                      "are female",
                      "have spots")

example.generics <- c("Tigers dont eat people", 
                      "Mosquitos carry malaria", 
                      "Robins lay eggs", 
                      "Robins are female",
                      "Leopards have spots")

m.gen.fullmodel.prior.parameters <- m.samp %>%
  filter(type == "prior", property %in% example.generics.properties) %>%
  group_by(param, property, category) %>%
  summarize(MAP = estimate_mode(val),
            cred_upper = hdi_upper(val),
            cred_lower = hdi_lower(val))

# use MAP estimates to generate L(h | generic) & L(h | silence) predictions

m.gen.fullmodel.prior.parameters.tidy <- m.gen.fullmodel.prior.parameters %>%
  ungroup() %>%
  select(param, property, category, MAP) %>%
  mutate(param = paste(param, category, sep = "_")) %>%
  select(-category) %>%
  spread(param, MAP) %>%
  rename(mix = isPresent_na, 
         stable_mean = prevalenceGivenPresent_mean, 
         stable_concentration = prevalenceGivenPresent_sampleSize) %>%
  mutate( a = stable_mean * stable_concentration, 
          b = (1 - stable_mean) * stable_concentration)

gen.listener.predictions <- data.frame()
  
for (p in example.generics.properties){
 priorParams <- m.gen.fullmodel.prior.parameters.tidy %>% filter(property == p) 
 inputData = list(prior = list(params = data.frame(a = priorParams[["a"]],
                                                   b = priorParams[["b"]]),
                               mix = priorParams[["mix"]]), 
                  utt = "generic")
 l0.rs <- webppl(l0.model, data = inputData, data_var = "data")
 gen.listener.predictions <- bind_rows(
   gen.listener.predictions, 
   l0.rs %>% select(Parameter,value) %>% mutate(property = p)
   )
}

m.gen.fullmodel.target.prevalence <- m.samp %>%
  filter(type == "withinKind") %>%
  group_by(param, property, category) %>%
  summarize(MAP = estimate_mode(val),
            cred_upper = hdi_upper(val),
            cred_lower = hdi_lower(val))



m.gen.speakerBeliefs <- m.samp %>%
  filter(type == "withinKind") %>%
  mutate(Sentence = paste(category, property)) %>%
  filter(Sentence %in% example.generics) 



m.gen.fullmodel.endorsement <- m.samp %>%
  filter(type == 'predictive') %>%
  group_by(type, param, property, category) %>%
  summarize(MAP = estimate_mode(val),
            cred_upper = hdi_upper(val),
            cred_lower = hdi_lower(val))


left_join(
  d.gen.endorse.bayes,
  m.gen.fullmodel.endorsement %>%
    mutate(sentence = paste(category, " ", property, ".", sep = "")) %>%
    ungroup() %>%
    select(-type, -param)
) %>%
  ggplot(., aes ( x = MAP, xmin = cred_lower, xmax = cred_upper,
                  y = MAP_h, ymin = low, ymax = high ))+
  geom_abline(intercept = 0, slope = 1, lty = 3)+
  geom_point()+
  geom_linerange()+
  geom_errorbarh()+
  scale_x_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  coord_fixed()+
  xlab("Model posterior predictive")+
  ylab("Human generic endorsement")

gen.inset.distributions <- bind_rows(
  gen.listener.predictions %>%
    mutate(category = NA),
  m.gen.speakerBeliefs %>%
    select(-type, -param, -chain, -Sentence) %>%
    rename(value = val) %>%
    mutate(Parameter = "speakerBeliefs")
)
```

```{r generic.model.insets, fig.width = 4.75, fig.height = 1.5}
category.text.labels <- data.frame(property = c("dont eat people", 
                      "carry malaria", "lay eggs",  "are female", "have spots"),
             category = c("Tigers", "Mosquitos", "Robins", "Robins", "Leopards"),
             x = c(0.3, 0.3, 0.47, 0.05, 0.6),
            y = c(0.45, 0.5, 0.45, 0.5, 0.26))

gen.inset.distributions %>%
  mutate(Parameter = factor(Parameter, levels = c("state_Prior",
                                                  "state_Posterior",
                                                  "speakerBeliefs"),
                            labels = c("Listener Prior (Posterior given Silence)", 
                                       "Listener Posterior given Generic", 
                                       "Speaker Beliefs")),
         property = fct_relevel(property,
                                "have spots", "lay eggs","carry malaria", 
                                "are female", "dont eat people") ) %>%
  ggplot(., aes( x = value, fill = Parameter, color = Parameter, lty = Parameter, alpha = Parameter ))+
  geom_density(aes(y = ..scaled..), adjust = 4, size = 1)+
  facet_wrap(~property, nrow = 1)+
  geom_text_repel(data = category.text.labels,
                  aes(label = category, x = x , y = y),
                  inherit.aes = F, color = "#2b83ba")+
    #scale_fill_manual(values = c("#636363", "#abdda4", "#2b83ba", "#d7191c"))+
    #scale_color_manual(values = c("#636363", "#abdda4", "#2b83ba", "#d7191c"))+
    scale_fill_manual(values = c("#636363", "#d7191c", "#2b83ba"))+
    scale_color_manual(values = c("#636363", "#d7191c", "#2b83ba"))+
    scale_alpha_manual(values = c(0.6, 0.4, 0))+
    #scale_linetype_manual(values = c(3, 4, 2, 1))+
    scale_linetype_manual(values = c(3, 4, 1))+
    scale_x_continuous(breaks = c(0, 1), limits= c(0, 1))+
    scale_y_continuous(breaks = c(0, 1), limits= c(0, 1))+
    xlab("Prevalence") +
    ylab("Scaled probability density")+
    theme(legend.position = "bottom", legend.title = element_blank())

```


<!-- The above analysis provides a single estimate for model predictions, but it is based on noisy empirical measurements of $P(x)$. In order to estimate the impact of this empirical noise on our model predictions, we resampled the prior data (with replacement) for 57 participants worth of data, discretizing and binning as we did above and then inferring parameters. -->
<!-- This procedure (re-sample prior, discretize and bin, infer parameters) was repeated 500 times to bootstrap the model predictions. -->
<!-- The Maximum A-Posteriori (MAP) estimate and 95\% Highest Probability Density (HPD) interval for $\lambda_1$ is 0.5 [0.004, 12.7] and $\lambda_2$ is 1.7 [1.3, 2.1]. -->
<!-- ^[ -->
<!-- The fact that $\lambda_1$ is credibly less than 1 suggests that the generic utterance may be more costly than "staying silent" (our model assumes equal cost). -->
<!-- We maintain using only the two $\lambda$ parameters in the model for simplicity. -->
<!-- ] -->


<!-- This is akin to fitting the parameters and is the critical step in model validation: It shows what data is actually predicted by the model.)  -->

Generics that received definitive agreement or disagreement are predicted to be judged as such by the model (corners of Figure \ref{fig:commongenerics}b), including items for which target-category prevalence is not a good indicator of the acceptability (e.g. \emph{Mosquitos carry malaria}, for prevalence quartiles 2 and 3, $r_{Q2,3}^2=0.955$; MSE=0.005; Figure \ref{fig:commongenerics}b, intermediate shades).
We also see the generics truth judgment model predicts uncertain truth judgments: for instance, \emph{Robins are female} is judged by both the model and human participants to be neither true nor false.
\emph{Sharks don't attack swimmers}, while true of most sharks, is judged to be not a good thing to say by both participants and the model.
This is strong evidence that the puzzling flexibility of generic truth conditions can be understood with a simple but underspecified semantics for which the precise meaning is resolved with respect to diverse prior beliefs in context.

<!-- basic communicative principles (\emph{be truthful}, \emph{be informative}) operating over diverse prior beliefs about the properties, all of which are at play in understanding language.  -->

\begin{figure}
\centering
    \includegraphics[width=\columnwidth]{figs/generics-prior-prevalence-tj.pdf}
    \caption{Endorsing familiar generics. (a) 
    Prevalence prior distributions empirically elicited for twenty-one animal properties.
    Prior distributions summarized by two parameters of a structured Bayesian model: $\phi$----a property's potential to be present in a category----and $\gamma$----the mean prevalence when it is possible for the property to be present in a category.
    Inset plots display example empirical prior distributions over prevalence and corresponding $L_1$ model predictions: the posterior after hearing a generic utterance. 
    Intervals on the top of insets show human judgments about the prevalence of the property within a target category.
    (b)
    Human acceptability judgments compared with model predictions (left) and the target-category prevalence (right) for thirty generic utterances about familiar animals and properties. 
    Color denotes target-category prevalence of the property, with lighter colors indicating higher prevalence. 
     Error bars denote 95\% Bayesian credible intervals.
    }
  \label{fig:commongenerics}

\end{figure}


## Discussion

Generic language is the premier case study for generalizations in language. 
Generics have been studied extensively in the cognitive and developmental psychological literatures and have been shown to have implications for wide ranging phenomena from stereotype propogataion [@Rhodes2012] to motivation [@Cimpian2007].
However, no formal model has been able to make precise quantitative predictions about the basic phonemena of generics, and classic counterexamples to theories based on probability (*Birds lay eggs* v. *are female*; *Mosquitos carry malaria*) have stifled the development of formal models.

By measuring listeners' prior beliefs about the prevalence of the property across kinds and the prevalence of the target kind (e.g., the percentage of birds that lay eggs), we were able to show how a semantics based on probability is tenable inspite of these seeming counterexamples.
The key theoretical claim is that the threshold must be *underspecified* in the semantics and inferred in context by the listener.
The decision of whether or not to endorse the generic comes down to whether or not the generic would make the listener's belief distribution more in line with the speaker's.

In explaining the variable endorsements of generics, we measured the prior distribution over the prevalence of the features across categories in addition to the prevalence of the feature in the target category (e.g., the percentage of robins that lay eggs) to model the endorsement data.
Thus, we show how these measurements are related via our model. 
Yet, the evidence is still correlational in nature.
We do not yet know if these variables that we are measuring are causally related to endorsement and interpretation.
In our second case study, we manipulate the target propensity that the speaker aims to communicate, while
continuing to measure the prior distributions.

<!-- In addition, why generics often imply the property is widespread has also been puzzling [@Gelman2004]. -->
<!-- We show that this is the result of the shape of listener's prior knowledge and that when that shape differs, the implied prevalence is much weaker (e.g., with accidental properties). -->
<!-- Even more puzzling has been the basic asymmetry between endorsements and interpretations [@Cimpian2010]. -->
<!-- We show that this asymmetry arises from the underspecified-threshold interacting with diverse prior beliefs.  -->
<!-- While implied prevalences vary wildly for different kinds of properties under discussion, the endorsements are relatively less sensitive to these distinctions. -->
<!-- Thus, the basic asymmetry is largely being driven by the listener's interpretation of a generic. -->


# Case Study 2: Habitual Language

*Habitual* language (e.g,. "Mary smokes."; "My car won't start.") convey generalizations about events. 
In this case study, we focus on a particular class of events: people doing actions.
We focus on present-tense habitual sentences of the form \textsc{singular noun phrase} $+$ \textsc{present tense simple verb phrase} (e.g., \emph{Mary smokes cigarettes.}). 

Habituals are a particularly nice domain for manipulating the target probability that a speaker aims to communicate, as this is expressed in an easily-interpretable frequency with which a person does an action (e.g., "Last month, Mary smoked cigarettes 3 times.").^[
While target probability can be manipulated for generalizations about categories (generic language) (e.g., by stating the prevalence of feature in a kind), this may interact with domain knowledge in complex ways (e.g., it's *a priori* very unlikely that 90% of a hypothetical novel kind---lorches---have broken wings).
]
In our first experiment concerning habitual language, we manipulate the target frequency as well as the kind of event (Expt. 2b), creating a data set of endorsements that is three times as large as the data from Expt. 1b (generic endorsement). 
Again, we measure participants' latent prior belief distribution over the frequencies of people doing various actions (e.g., how often people *run*; Expt. 2a) in a way analagous to the prevalence prior elicitation for generics.
In addition to directly manipulating the target propensity, these experiments provide the first test of the generality of our theory.

If habituals (and generics) are truly language for conveying generalizations, it would be useful for them to reflect expectations, not merely observations. 
Is the underlying scale for habituals the actual, past frequency of the event (e.g., how often Mary has actually smoked in the past week) or the predictive probability that this event will occur in the near future (e.g., how likely it is thatMary will smoke next week)? 
In Expts. 3a \& 3b, we show that the object of communication is a speaker’s prediction about the future frequency of action, and not past frequency.


<!-- This set of experiments is organized as follows. -->
<!-- In the **Event Prior Elicitation** study (Expt. 1), -->
<!-- In the **Endorsing Habitual Language** experiment (Expt. 2), we introduce a separate participants to different characters, each of whom have done some action with some frequeny (e.g., *In the last month, John ran 3 times*), and ask them to judge the corresponding generalization (e.g., *John runs*). -->
<!-- In the **Interpreting Habitual Language** experiment (Expt. 3), we invert this paradigm, supplying participants with the generalization (e.g., *John runs*) and ask them to juge how often the person does some action (e.g., answer the question: *How often do you think John runs?*). -->

<!-- We evaluate our family of RSA models, in addition to some ad-hoc non-Bayesian models, on these experimental data. -->
<!-- Because the ad-hoc models do not comprise a formalized alternative theory of endorsement and interpretation, but rather statistical descriptions of the data, we compare the ad-hoc models to the simplest RSA model on endorsement and interpretation, separately. -->
<!-- After presenting the results of Expts. 2 \& 3, we compare RSA models on their ability to jointly predict both endorsement and interpretation data simultaneously.  -->
<!-- Finally, having validated a communicative theory of genericity, we probe the theory in more detail in Experiment 4 by asking whether past frequency or predictive probability is what is being communicated. -->


<!-- The internal structure of particular events can differ in substantial ways. -->
<!-- For example, events differ in their expected duration. -->
<!-- For example, the event of *smoking a cigarette* plausibly takes between 5 - 10 minutes, while the event of *wearing socks* probably lasts for several hours. -->
<!-- We take as a starting point the fact that events can be segmented and aggregated; the relevant dimension becomes the frequency with which the event occurs. -->

<!-- In our main test of the hypothesis, we collect felicity or truth judgments for habitual statements about people's actions. -->
<!-- The computational model described in Eq. \ref{eq:S1} is fully specified except for the prior distribution over the frequency of an event $P(h)$, which plausibly varies across different kinds of events. -->
<!-- First, we measure the prior distribution, and use it and the computational model to predict human endorsement of habitual statements. -->

## Experiment 2: Endorsing generalizations about events

### Experiment 2a: Measuring the propensity prior for event knowledge

In this experiment we elicit the prior $P(h)$ for different events in order to generate model predictions for corresponding habitual statements.
For the case of statements about the behaviors of people, $P(h)$ can be conceived as a distribution over *different people*, each of whom do the behavior with a different frequency.
To better understand what frequencies should be expected for different actions, we had participants judge the frequency of action for people they were familiar with.


#### Method

##### Participants

We recruited 50 participants from Amazon's Mechanical Turk.
Participants were restricted to those with U.S. IP addresses and who had at least a 95\% work approval rating.
The experiment took on average 12 minutes and participants were compensated \$1.25 for their work.

##### Materials

<!-- We created thirty-one events organized into pairs or triplets from 5 different conceptual categories:  -->
We created twenty-seven events organized into pairs or triplets from 5 different conceptual categories: 
food and drug (e.g. \emph{eats caviar}, \emph{eats peanut butter}), 
work (e.g. \emph{sells things on eBay}, \emph{sells companies}), 
clothing (e.g. \emph{wears a suit}, \emph{wears a bra}), 
entertainment (e.g. \emph{watches professional football}, \emph{watches space launches}), and 
hobbies (e.g. \emph{runs}, \emph{hikes}). 
Items were chosen to intuitively cover a range of likely frequencies of action, as well as to provide a minimal comparison to another item by having a common superordinate action (e.g. \emph{eating} caviar vs. peanut butter).

##### Procedure

The experiment began by having participants input the names of eight friends, family members, or people they knew well that they could answer some questions about.
Participants were told that these names would only be used to assist them in reasoning through the second part of the experiment. 

In the second phase of the experiment, participants were asked: "For each of the following people, how often does he or she \textsc{do action}?"
Participants had to fill in the blanks in sentences of the form: "\text{friend does action} ___ times per ___".
The first blank was a text box where participants could enter a number.
The second blank was a drop-down menu where participants could select a time interval from the following options: \{week, 2 weeks, month, 2 months, 6 months, year, 2 years, 5 years\}
They completed this task for each of their eight listed friends or family members.
To make the task slightly less tedious, there was an option where participants could set the time window for all eight of their responses.

In order to get sufficient data for actions that are relatively uncommon (e.g., *climbs mountains*, *writes novels*), if participants responded that all of their friends do the action with a frequency of "0 times" (in some interval), a follow-up question appeared that read: "Do you know anybody who has \textsc{done action} before?". 
If they responded "Yes", another follow-up question appeared that read: "How often do you think that person \textsc{does action}?", with the same dependent measure format as before.

Participants completed these elicitation trials for a random subset of 15 items, presented in a randomized order.
The experiment can be viewed at \url{http://stanford.edu/~mtessler/generics-paper/experiments/habituals/priors/friends-and-family-1.html}

\begin{figure*}[t]
\centering
  \includegraphics[width=0.84\textwidth]{figs/tj-scatters-3}
  \caption{
  Human acceptability judgments as a function of the log frequency of action (left) and speaker $S_2$ model predictions (right) for ninety-three unique items (event \textsc{x} frequency). 
  Color denotes target-individual frequency of action (log scale), with lighter colors indicating more frequent actions. 
  Actual frequency noted on x-axis for examples (left).
  Error bars correspond to 95\% bootstrapped confidence intervals for the participant data and 95\% Bayesian credible intervals for the model predictions. 
  Error bars suppressed and points jittered on left facet for visual clarity.
  }
  \label{fig:tjScatters}
\end{figure*}

#### Data preprocessing

```{r habituals-prior}
annualRates = list("5 years" = 1/5, "2 years" = 1/2,
                   "year" = 1, "6 months" = 2, "2 months" = 6,
                   "month" = 12, "2 weeks" = 26 ,"week" = 52)

d.hab.priors <- read.csv(paste(project.path,
                           "data/habituals/priors/friends-and-family-2-trials.csv",
                           sep= ""))
```

Every response for a frequency of a person doing an action is a sample from $P_{event}(h)$.
We first transformed all responses onto the same scale of "times per year" (assuming 52 weeks per year; 12 months per year).
An empirical distribution can be found by making a histogram of these responses. 
The empirical distributions follows a kind-of log-normal distribution, with the additional feature of having a substantial probability mass at the frequency of 0 (for those individuals who never do the action). 
We thus log-transformed the empirical data. 
To avoid values of -Infinity, we set the responses of 0 to mean roughly "once every twenty years".

We took the log-transformed (and "-Infinity"-adjusted) raw data and binned each response to the closest bins on a grid with binwidth of 0.5 in the log-"times per year" scale.
This yields a grid of 23 points with frequencies ranging from "once every twenty years" (log-frequency = -3) to "twenty times per day" (log-frequency = 9).

#### Data analysis and results



We analyze the data using a Bayesian approach to allow for a consistent integration into the computational model.
The data we would like to explain are: the bins $n_i \in \{-3, -2.5, ..., 8.5, 9\}$ that participants gave in response to items $i \in \{1, ..., 27\}$.
The data is explained as a function of subjective beliefs $P_i$, with $P_{ij}$ being participants' (as a collective) belief about the relative likelihood for bin $j$ for item $i$. 
Each $P_i$ defines a likelihood for our data, assuming an appropriate linking function.

Following @Franke2016, the linking function for this data treats each bin $n_{i}$ as a draw from a categorical distribution where the probability of bin $j$ is proportional to $\exp{(a\cdot P_i)}$, i.e., a soft-max choice from $P_{i}$. 
The higher parameter $a$, the more likely $n_{i}$ is the mode of $P_{i}$. 
For $a \rightarrow 0$, all bins become equiprobable.

\begin{eqnarray}
P_{i} &\sim& \text{Dirichlet}(1, ..., 1) \\ 
a & \sim & \text{Gamma}(2,1) \\
n_{i} &\sim & \text{Categorical}(\exp(a \cdot P_i))
\end{eqnarray}

VIZ (as before)?

<!-- We assume each "binned" response is a sample from a multinomial distribution with unknown probability vector. -->
<!-- We put a Dirichlet-prior over this probability vector. -->

<!-- We built a Bayesian data analysis model for this prior elicitation task. -->
<!-- Question 1 elicits the proportion of people who have done an action before.  -->
<!-- We model this data as coming from a Beta distribution: $d_{1} \sim \text{Beta}(\gamma_{1}, \xi_{1})$.  -->
<!-- Question 2 elicits the rate, or relative frequency, with which a person does the action. -->
<!-- This was modeled by a log-normal distribution: $\ln d_{2} \sim \text{Gaussian}(\mu_{2}, \sigma_{2})$.  -->
<!-- Each item was modeled independently for each gender. -->
<!-- We implemented this model using the probabilistic programming language WebPPL \cite{dippl}, and found the credible values of the parameters by running MCMC for 100,000 iterations, discarding the first 50,000 for burnin. -->

<!-- The priors elicited cover a range of possible parameter values as intended (Figure \ref{fig:priorScatter}, scatter), resulting in parametrized distributions of dramatically different shapes (insets).   -->
<!-- We observe a correlation in our items between the mean \% of Americans who have \textsc{done action} before (Question 1) and the mean log-frequency  of action (Question 2) ($r_{1,2} = 0.74$). -->
<!-- Items that tend to be more popular actions also tend to be more frequent actions (e.g. \emph{wears socks}) and visa-versa (e.g. \emph{steals cars}), though there are notable exceptions (e.g. \emph{plays the banjo} is not popular but done frequently when done at all, as is \emph{smokes cigarettes}; \emph{goes to the movies} is a popular activity though not done very often).  -->
<!-- This diversity is relevant because the speaker model (Eq.~\ref{eq:S2}) will produce habitual sentences (e.g. \emph{Sam goes to the movies vs. the ballet.}) contingent on the shape of the prior distribution.  -->

<!-- From the inferred parameters and assumed functional forms, we get an inferred $P(p)$ modeled as a mixture of individuals with the possibility of carrying out the action and those without the possibility of doing it.  -->
<!-- That is, $P(p)$ was constructed by sampling $p$ as follows: -->

<!-- \begin{align} -->
<!-- \theta & \sim \text{Beta}(\gamma_{1}, \xi_{1}) \nonumber \\  -->
<!-- \ln \lambda & \sim \begin{cases} -->
<!-- 		\text{Gaussian}(\mu_{2}, \sigma_{2}) &\mbox{if } \text{Bernoulli}(\theta) = \textsc{t} \label{eq:priorModel}  \\ -->
<!-- 				\delta_{\lambda=-\infty} &\mbox{if } \text{Bernoulli}(\theta) = \textsc{f} \\ -->
<!-- 		\end{cases} -->
<!-- \end{align} -->

<!-- In addition to specifying the correct way to combine our two prior-elicitation questions, using this inferred prior in our language model resolves two technical difficulties: (1) It smooths effects that are clearly results of the response format^[ -->
<!-- For example, a very common rating is *1 time per year*. Presumably participants would be just as happy reporting *approximately* 1 time per year; the raw data does not reflect this due to demands of the dependent measure. -->
<!-- ] -->
<!-- and (2) it better captures the tails of the prior distribution which have relatively little data and need to be regularized by the analysis. -->
<!-- Figure \ref{fig:priorScatter} (right) shows example inferred priors. -->

<!-- Some items show substantial differences between the genders (e.g., *wears a bra*) and some show subtle differences (e.g., *watches professional football*).  -->
<!-- We will explore the possibility of different truth conditions for habituals of different gendered characters in Experiment 2, for select items with priors that differ substantially by gender. -->



## Experiment 2b: Endorsing generalizations about events

We next explore the endorsements of habituals from the items whose priors were measured the prior elicitation task. 

### Method

#### Participants

We recruited 150 participants from MTurk.
To arrive at this number, we performed a Bayesian precision analysis to determine the minimum sample size necessary to reliably ensure 95\% posterior credible intervals no larger than 0.3 for a parameter whose true value is 0.5 and for which the data is a 2-alternative forced choice.
This analysis revealed a minimum sample size of 50 per item; since participants only completed about one third of the items, we recruited 150 participants.
The experiment took 4 minutes on average and participants were compensated \$0.55 for their work.

#### Procedure and materials

On each trial, participants were presented with a \emph{past frequency statement} for a given event of the form: "In the past M \{weeks, months, years\}, \textsc{person} \textsc{did x} 3 times".
For example, \emph{In the past month, Bill smoked cigarettes 3 times}.
The particular intervals used (\{weeks, months, years\}) were selected after examining the predictions of the speaker model (Eq. \ref{eq:S1}), for each item independently, to yield a range of predicted endorsement rates.
The items were the same as in the prior elicitation task.

Participants were asked whether they agreed or disagreed with the corresponding habitual sentence: "\textsc{person does x}" (e.g., \emph{Bill smokes cigarettes}).
Participants completed 37 trials, which were composed of the 27 items from the prior elicitation task and 4 additional filler items not in the prior elicitation task randomly paired with either a male or female character name.
6 of these items were then also paired with a name of the opposite gender (e.g., participants saw both a female character and a male character who watched professional football).
These were used for an exploratory analysis on gender differences.
The 4 filler items were not used in the prior elicitation because they described illegal activities (e.g., "doing cocaine", "stealing cars").
The experiment can be viewed at \url{http://stanford.edu/~mtessler/habituals/experiments/truth-judgments/tj-2.html}.

### Results



```{r habituals-endorsement}
d.hab.endorsement.catch <- read.csv(paste(project.path, "data/habituals/endorsement/", 
                    "habituals-endorsement-catch_trials.csv", sep = ""))

d.hab.endorsement <- read.csv(paste(project.path, "data/habituals/endorsement/", 
                    "habituals-endorsement.csv", sep = ""))

d.hab.endorsement <- left_join(d.hab.endorsement, 
                               d.hab.endorsement.catch %>% 
                                 select(workerid, pass)) %>%
  filter(pass == 1)

d.hab.endorsement.summary <- d.hab.endorsement %>% 
  mutate(response = ifelse(response == "agree-key", 1, 0),
         roundedFreq = round(log_times * 2) / 2) %>%
  group_by(habitual, time_period, roundedFreq) %>%
  summarize(k = sum(response), n = n()) %>%
  ungroup() %>%
  mutate(a = 1 + k,
         b = 1 + n - k,
         low  = qbeta(.025, a, b),
         high = qbeta(.975, a, b),
         MAP_h = (a-1)/(a+b-2),
         mean = a / (a + b))


ggplot(d.hab.endorsement.summary, aes( x = roundedFreq, y = MAP_h, ymin = low, ymax = high, fill = roundedFreq))+
  geom_jitter(width = 0.1, shape = 21)
```



#### Behavioral results

On each trial of the experiment, the participant was told a person did a particular action 3 times during some time window. 
A simple null hypothesis is that habitual statements convey that the a person *has done this action before*, analagous to how the quantifier *Some* conveys that there exists at least one. 
Under this hypothesis, all of the items used in our experiment would qualify as good habitual statements.
A more sophisticated alternative hypothesis is that the degree to which the habitual statement is good is the frequency itself. 
<!-- Our computational model predicts that the the degree to which the habitual statement is good is the frequency of event, normalized by the alternative possible frequencies under the prior. -->
<!-- [MHT: SENTENCE ABOVE IS THE SOFT-SEMANTICS INTERPRETATION] -->

Both of the simple alternative hypotheses can immediately be ruled by out by visual inspection of Figure \ref{fig:tjScatters} (left), which shows the correspondence between the frequency of the event (transformed to a log times-per-year scale) and the human-judged felicity of the corresponding habitual sentence. 
First, it is clear that not all habitual statements are strongly assented to, even though it is true that all the stimuli involved an agent doing the action with some non-zero frequency.
It is also clear that a habitual sentence can receive strong agreement even when the actions are very infrequent (log frequency $\sim$ -1; 3 times in a 5-year interval; e.g. \emph{writes novels}, \emph{climbs mountains}), arguing against the second alternative.
We see in addition that even when actions are done relatively frequently (e.g. 3 times in a one month interval; log frequency $\sim$ 5), some habitual sentences receive less than full endorsement (e.g. \emph{wears socks}, \emph{drinks coffee}). 
In our data, actions completed with a high frequency (3 times in a one week interval; log frequency $\sim$ 6.5) receive at a minimum 75\% endorsement, though there is still variability among them (e.g. between 10-25\% of people disagree with \emph{wears a watch} and \emph{wears a bra}).
Overall, the raw (log) frequency of action predicts only a fraction of the variability in responses ($r^2(93) = 0.33$).
For actions that are done on the time scale of years or longer (lower median of frequency), frequency itself no longer explains the endorsements ($r^2(50) = 0.07$)

We observe that none of our items receive less than 25\% endorsement (i.e., a maximum of about 75\% of participants disagree with the felicity of the utterance).
This reflects the fact that these statements are not altogether *false* even though the action is done very rarely.

We find no differences between endorsements of the habitual of characters with male and female names, and overall, the mean endorsements by gender are strongly correlated $r(93) = 0.91$. 
This may be because the felicity of habitual sentences depends on a comparison to individuals of both genders (i.e, the \emph{contrast class} is other people; not just other men or women). 
Less interestingly, the lack of a difference may be the result of gender being not very salient in our paradigm, perhaps because the names used were not sufficiently gendered.

\begin{figure*}[t]
\centering
  \includegraphics[width=\textwidth]{figs/expt3-4-scatters-camera.pdf}
  \caption{Left: Predicted log frequency as a function of past log frequency given to the participant (Expt. 3a; CIs suppressed and jitter added for visual clarity).
  Middle: Human endorsements of habitual sentences (Expt. 3b) vs. Predicted log frequency (Expt. 3a), with data for corresponding items from Expt. 2 (assumed to have the same predictive log frequency as baseline). 
  Right: Endorsements (Expt. 3b) vs. Speaker $S_2$ model predictions using empirically elicited predictive frequencies (Expt. 3a).}
  \label{fig:tj3}
  \vspace{-7pt}
\end{figure*}

#### Model criticism and comparison

We used the pragmatic speaker model $S_2$ (Eq.~\ref{eq:S2}) with the priors elicited above (Expt.~1) to predict felicity judgments in Expt.~2, assuming the target propensity (to be conveyed by $S_2$) is the provided frequency.
Because we observe no difference between the felicity judgments for habituals of male and female characters, we use a 50\% mixture of the inferred priors for each gender to construct a single frequency distribution $P(\lambda)$ across individuals.
The model has two free parameters---the speaker optimality parameters, $\alpha_i$, in Eqs.~\ref{eq:S2} \& \ref{eq:S1}. 
We use Bayesian data analytic techniques to integrate over these parameters \cite{LW2014}, comparing the posterior predictive distribution to the empirical data in Expt.~2.
To construct the posterior predictive distribution over responses, we collected 2 MCMC chains of 100,000 iterations, discarding the first 50,000 iterations for burn in.
The Maximum A-Posteriori value and 95\% highest probability density interval for $\alpha_1$ is 19.3 [14.9,19.9] and $\alpha_2$ is 1.5 [1.4,1.6].
%The MAP and HPD interval for the data-analytic guessing parameter is 0.004 [0.0003, 0.03], suggesting that there is not a substantial amount of the data that is better explained by a model of random guessing than by our pragmatic speaker model.

As shown in Figure \ref{fig:tjScatters}, right, the pragmatic speaker model does a good job of accounting for the variability in responses ($r^2(93) = 0.94$), including actions done on the time scale of years or more  ($r^2(50) = 0.92$).
The speaker model endorses the statement when the observed frequency is relatively high, compared to the prior distribution over people doing the action. 

As another potential alternative hypothesis, we formulate a model of a speaker who judges the felicity of the habitual utterance based on simple summary statistics of the prior, such as the mean and variance.

Only our pragmatic speaker model who reasons about a listener is able to capture the quantitative variability in our data.


## Experiment 3: Communicating predictive propensities

In Experiment 2b, we supplied participants with a statement about how often a person has done the action in the past and asked them to judge the correspoding habitual statement.
This raises an interesting question: Does the propensity communicated by a generalization indicate an objective, past frequency or a subjective, future expectation?

While past frequency is often a good indicator of future tendency, people change abruptly due to a variety of decisions and outside events.
Does habitual language communicate propensity in terms of past frequency or future expectations?
On one hand, speakers can only *know* about what has happened in the past.
On the other hand, language has a communicative function, and it would seem useful for speakers to convey what they *believe* will be the case in the future.

In this pair of experiments, we address this by introducing causal events that enable or prevent future actions (e.g., buying a pack of cigarettes; developing an allergy).
In Expt. 3a, we measure *predictive frequency* both when past frequency alone is observed and when these causal factors are introduced.
In Expt. 3b, we examine felicity judgments of the habitual sentence (e.g., \emph{John smokes cigarettes.}; \emph{Susan eats peanut butter.}) in the presence of these causal modifiers.
This allows us to test whether habituals are best explained by a speaker $S_1$ who communicates the objective past frequency or the subjective future frequency.

### Experiment 3a: Prediction elicitation

#### Methods

We recruited 120 participants from MTurk, using the same criterion as Expt. 2b.
The experiment took 4 minutes on average and participants were compensated \$0.40.

The procedure was identical to Expt. 2b except for the inclusion of a second sentence on a subset of trials and the use of a different dependent measure. 
On all trials, participants were presented with a \emph{past frequency sentence} (same as Expt. 2b).
Additionally, on one third of the trials, participants were presented with a \textbf{preventative sentence} (e.g. \emph{Yesterday, Bill quit smoking.}).
On one third of the trials, participants were presented with an \textbf{enabling sentence} (\emph{Yesterday, Bill bought a pack of cigarettes.}) 
The final third of trials had no additional evidence and were identical to Expt. 2b. 

Only twenty-one of the original thirty-one items were used in order to shorten the experiment.
To increase expected variability, participants saw only the frequencies that led to most intermediate endorsement of the habitual in Expt. 2b. 
In addition, we did not include separate trials for both male and female names for the select items we did in Expt. 2b, since we saw no differences in their endorsements of the habitual.

Participants were asked ``In the next \textsc{time window}, how many times do you think \textsc{person} does \textsc{event}?'', where the \textsc{time window} was the same as given in the \emph{past frequency statement}.
The experiment in full can be viewed at \url{http://stanford.edu/~mtessler/habituals/experiments/priors/predictive-1.html}.


#### Results

Figure \ref{fig:tj3} (left) shows the predicted future frequency as a function of the past frequency given to the participant and the type of causal information given. 
We observe in the baseline condition that future frequency perfectly tracks past frequency (e.g. participants believe if a person smoked cigarettes 3 times last month, they will smoke cigarettes 3 times next month). 
This means that our model makes identical predictions for Expt. 2 whether the target is past frequency or expected future frequency (indicating, as expected, that we must look to the new data to distinguish these models).
Critically, we observe the preventative information appreciably decreasing and the enabling information slightly increasing predicted frequency (Figure \ref{fig:tj3} left; blue and green dots).

+ MHT: Add some regression analysis here


### Experiment 3b: Felicity judgments

#### Methods

We recruited 150 participants from MTurk, using the same criterion as Expt. 2b.
The experiment took 4 minutes on average on participants were compensated \$0.40 for their work.
None of the participants had completed Expt. 3a.
%\subsubsection{Procedure and materials}
The only difference from Expt. 3a is the dependent measure. 
On each trial, participants were asked if they agreed or disagreed with the corresponding habitual sentence (as in Expt. 2).
The experiment can be viewed at \url{http://stanford.edu/~mtessler/habituals/experiments/truth-judgments/tj-3-preventative.html}.
#### Results

There is a clear and consistent negative effect of preventative information on endorsements for the habitual sentence (Figure \ref{fig:tj3}, middle; blue points).
When collapsing across items and subjecting the data to a generalized mixed-effects model with random by-participant effects of intercept and random by-item effects of intercept and conditions, we find evidence for a small effect of \emph{enabling} conditions on endorsements (M =  0.89; 95\% Bootstrapped CI [0.88, 0.91]) as compared to baseline (M = 0.85 [0.83, 0.87]) [$\beta = 0.42; SE = 0.15; z = 2.8$]
, and a large effect of \emph{preventative} conditions on endorsements (M = 0.29 [0.26, 0.31]) [$\beta = -3.22; SE = 0.21; z = -15.2$]. 
<!-- %\mht{should I add points from Expt. 2 to left-most scatter, or maybe there is a better plot?} -->

We use the mean predicted log frequency from Expt. 3a as the input to the speaker $S_1$ model to predict the felicity judgments measured in Expt. 3b.
We infer the two model parameters using the same analysis approach in Expt. 2. 
The model matches the data well ($r^2(63) = 0.91$; Figure \ref{fig:tj3}, right).
The same model using the past frequency as the object of communication does not match the data at all ($r^2(63) = 0.02$).
These results suggest that the felicity of habituals is based on an underlying scale of predicted future propensity, not merely the observed frequency in the past.

Interestingly, we observe endorsements in this experiment that are appreciably higher than in Expt. 2 for the same items (Figure \ref{fig:tj3}, middle; red vs. purple points). 
This may be due, in part, to an effect of the experimental context on participants: 
in this experiment the overall population of frequencies is much lower (both because we selected moderate frequencies from Expt. 2 and because of the preventative information) and participants may infer that the experimenter believes this to be a representative range and adjust judgments accordingly.
Future investigation into this issue is warranted.

## Discussion

Habitual language conveys generalizations about events and our model decides if a habitual sentence is a pragmatically useful way to describe the rate at which a person does an action, taking into account the listener’s prior beliefs about the action (measured in Expt. 2a). 
We have seen that our computational model endorses statements that communicate generalizations about events with the same sensitivity to context that people exhibit (Expt. 2b).
In Experiment 2b, we varied the type of event and the past frequency with which the person did the action, and found substantial graded variability in the endorsement judgments of people.
<!-- Naive baseline models could not explain these endorsements judgments and our communicative model provided the most parsimonious account of the data in comparison to non-Bayesian models.  -->
<!-- In Experiment 3, we looked at interpretations of habitual statements about different events and again found substantial gradedness that our theory provided the most parsimonious account of. -->
<!-- The theory defines a pair of interpretation and endorsement models and these models can simultaneously account for both data sets. -->
In Experiment 3, we further investigated the nature of the underlying “propensity” scale by introducing enabling and disabling causal evidence, measuring the predicted future frequency (Expt. 3a) and using that, with the model, to predict the felicity of habitual sentences (Expt. 3b). 
To our knowledge, the experiments presented here are first empirical investigations into the truth conditions of habitual sentences and the first test of a formal psychological model of generalizations in language.
In these experiments, we directly manipulated the frequency that the speaker was trying to communicate while measuring the propensity priors.
Thus, it is still possible that the propensity priors that are central to our communicative theory of generalizations are somehow epiphenomenal, correlational associated with generic endorsement but not directly causally related.
In our final case study, we extend our theory to communicating generlizations about causes, and test experimentally whether the propensity prior is indeed causally related to generic endorsement. 

# Case Study 3: Causal Language

Learning that an event consistently tends to result in another event serves as a foundation for an intuitive theory of causality (CITE noah's and kemp's causality and causal models papers?).
Communicating generalizations about causally related events is potentially highly useful because no one individual can run all the experiments that she wants to run in a life time. 
The history of civilizations has shown that it is incredibly useful to divide labor: Some members can investigate modifications to the food preparation procedures while others can examine different ways of cutting stone. 

Our framework for communicating generalizations makes predictions about statements conveying genericty about a category of causal events. 
In this domain, an instance of the category is a single causal event (e.g., adding a particular amount of a particular kind of yeast to an actual piece of dough at a particular time of the day). 
@Gerstenberg
The study of *elemental causal induction* is itself very subtle, depending on an observer's background theory of causality. [@Griffiths2005; @Schulz].

We design this last experiment with the goal of testing whether background knowledge that gives rise to the prevalence priors is causally related to the endorsement of causal statements.
Also, by designing the experiments in the domain of causal language, we further demonstrate the generality of our theory of communicating generalizations.

In Experiment 4a, we manipulate participants' beliefs about a causal system and measure their updated beliefs about system, serving a manipulation check.
In Experiment 4b, we test whether these manipulated priors give rise to different endorsements of causal statements.

## Experiment 4a: Manipulating the Prevalence Prior for Causes

People have theories about how different casusal systems work. 
Physical causation tends to have a deterministic bend to it: If one billiard ball hits a second with a certain force, the second will respond by moving with a certain force. 
If the experiment is repeated exactly, we would expect the same results.
In other domains, probabilistic causes are plausible: Giving a sick animal a certain medication may sometimes make it better and other times it won't. 
Finally, some events could have multiple possible causes: Testing whether or not a drug makes an animal *blink* might be difficult because animals will tend to *blink* even without intervention. 

In this experiment, we examine causal domains that vary as to whether or not probabilistic causes are plausible and whether or not a background cause of the event is intuitively present.
We introduce participants to the results of several experiments about each domain and see how different experimental results update participants' beliefs about causal power in these domains.


### Method


#### Participants 

We recruited N participants from Amazon's Mechanical Turk.
Participants were restricted to those with U.S. IP addresses and who had at least a 95\% work approval rating.
The experiment took on average N minutes and participants were compensated \$N.NN for their work.


<!-- The different kinds of system are described in more detail below. -->
<!-- Participants are then told that the team of scientists is conducting experiments with different possible causes (e.g., different kinds of foods). -->


The experiment is a single-trial experiment with 2 phases to the trial.
In the first phase, participants are given a story about a causal domain in question.
In the second phase, participants are asked to make a judgment corresponding to the between-subjects condition they are assigned (prior, endorsement, interpretation). 

#### Procedure

Participants are told that they are an astronaut-scientist on a distant planet trying to figure out how some system works (e.g., how to make a certain kind of animal more alert). They are told:

\begin{quotation}
You are an astronaut-scientist exploring a distant planet. 
On this planet, there are animals called  (e.g., daiths) and your team of scientists wants to figure out what makes daiths's hair turn brown. 
Your team runs experiments trying to make daiths's hair turn brown with different chemical compounds. 
The results are shown below:
\end{quotation}

Participants then must click a button to show the results of the experiments.
Experiment results appear one at a time (upon a click), and are described verbally (e.g., The team tested Food A on 100 daiths. 30 of them were made more alert.) as well as put into a table showing the number of successes per number of attempts (always 100 per experiment). 
Eleven "experiments" are shown, though one of the experiments had their results misplaced so they cannot report on the results at that point (the significance of this "missing experiment" will be described in Experiment 6).
After participants view the results of the 10 "experiments" (and 1 missing experiment), they are told to review the results of the experiments before continuing. 

Upon proceeding to phase 2, the results of the "experiments" are removed and participants are told more experiments were conducted.
Participants were asked to predict the results of the next 4 experiments.
Participants were given 4 slider bars ranging from 0 - 100, and asked to predict the next four treatments (e.g., foods M, N, P, and Q). 

#### Materials 

The kind of causal events in question were selected to correspond roughly to different positions in a theoretically meaningful space defined by the model.
Research in elemental causal induction suggests people use causal models that correspond to a mixture probability distributions, where one component of the distribution is a consequence to the intrinsic causal force while the other component is a result of some extrinsic background cause.
So we designed materials that corresponded to domains where various parameters of that mixture model could be manipulated. 

A second dimension of manipulation corresponds to the extent to which *determinism* is expected in the domain. 
For example, people's theories of physical causation tends to be more deterministic (i.e., favoring probabilities 1 and 0) then causation in the social or psychological domain. 


### Results


...

## Experiment 4b: Endorsing Causal Language

In this experiment, we tested whether the manipulated priors of Expt. 4a are causally related to the endorsement of causal statements.

### Method

Most of the experiment was identical to that of Experiment 4a.

#### Participants

We recruited N participants from Amazon's Mechanical Turk.
Participants were restricted to those with U.S. IP addresses and who had at least a 95\% work approval rating.
None of the participants had participated in Experiment 4a. 
The experiment took on average N minutes and participants were compensated \$N.NN for their work.

#### Procedure and materials

The materials were the same as in Experiment 4a.
Phase 1 of the experiment was identical to that of Experiment 4a.
In phase 2 of the endorsement task, the table of results and background story were removed from the screen and the participant is told that the results of the "lost experiment" were found. 
The results are reported to the participant in terms of how many out of 100 of the attempts were successful. 
Participants were then asked to judge the causal sentence: "Treatment X makes the effect happen". 
Partipants responded by either clicking "Yes" or "No". 

Participants saw 1 of 3 frequencies: 20\%, 50\%, or 80\%.

### Results


```{r causals-endorsement}
d.caus.endorse.catch.20 <- read.csv(paste(project.path, 
                                       "data/causals/endorsement/",
                                       "causals-8-20-catch_trials.csv", sep = ""))

d.caus.endorse.catch.70 <- read.csv(paste(project.path, 
                                       "data/causals/endorsement/",
                                       "causals-8-70-catch_trials.csv", sep = "")) %>%
  mutate(workerid = workerid + 1 +  max(d.caus.endorse.catch.20$workerid) )

d.caus.endorse.catch <- bind_rows(d.caus.endorse.catch.20, d.caus.endorse.catch.70)

d.caus.endorse.catch <- d.caus.endorse.catch %>% 
  mutate(passBoth = ifelse(pass_numeric + pass_story == 2, 1, 0))

d.caus.endorse.20 <- read.csv(paste(project.path, 
                                "data/causals/endorsement/",
                                "causals-8-20-trials.csv", sep = ""))

d.caus.endorse.70 <- read.csv(paste(project.path, 
                                "data/causals/endorsement/",
                                "causals-8-70-trials.csv", sep = "")) %>%
  mutate(workerid = workerid + 1 + max(d.caus.endorse.20$workerid))

d.caus.endorse <- bind_rows(d.caus.endorse.20, d.caus.endorse.70)

d.caus.endorse.summary <- left_join(
  d.caus.endorse, 
  d.caus.endorse.catch %>% select(workerid, passBoth)
  ) %>%
  filter(passBoth == 1) %>%
  group_by(distribution, frequency) %>%
  summarize(k = sum(response), n = n()) %>%
  ungroup() %>%
  mutate(a = 1 + k,
         b = 1 + n - k,
         low  = qbeta(.025, a, b),
         high = qbeta(.975, a, b),
         MAP_h = (a-1)/(a+b-2),
         mean = a / (a + b))

ggplot(d.caus.endorse.summary, aes( x = factor(frequency), y = MAP_h, ymin = low, ymax = high, fill = distribution,
                        group = distribution))+
  geom_bar(stat='identity', position = position_dodge(), width = 0.3, color = 'black')+
  geom_errorbar(width = 0.2, position = position_dodge(0.3), color = 'black')+
  theme(axis.text.x = element_text(angle = 0))+
  geom_hline(yintercept = 0.5, lty = 3, color = 'black')+
  scale_y_continuous(limits = c(0, 1), breaks = c(0,0.5, 1))+
  scale_fill_solarized()+
  xlab("Frequency")+
  ylab("Proportion Causal Endorsement")
```

## Discussion

# General Discussion

It is a remarkable fact that so much is learned from ideas expressed vaguely in words.
Generalizations in language (e.g., *John runs.*, *Dogs are friendly.*, *The block makes the machine play music*) are a premier example of how simple statements --- statements understood by even the youngest language users --- can display complex sensitivity to context.
We have argued that the core meaning of such linguistic expressions is, in fact, simple, but underspecified. 
To our knowledge, this is the first formal theory of genericity in language that makes accurate and precise quantitative predictions about human behavioral data. 
It is also the first attempt in psychology to try to unify significant swaths of language that are seemingly quite different from one another: generalizations about events, causes, and categories.
What these expressions have in common is not surface-level features but *genericity*, the fact that these statements convey generalizations. 
Indeed we have been able to capture the context-sensivity of these statements by positing a single underlying scale defined by the *propensity*, or probability (Expts. 1, 3, \& 4).
This scale is crucially defined by a subjective, predictive probability, not mere frequency (Expt. 2).
We have shown that listeners' prior knowledge about this scale is causally related to their endorsement of statements of genericity (Expt. 3).
Finally, our framework naturally accounts for a number of well-documented phenomena from cognitive and developmental psychology concerning *generic language*, or generalizations about categories (Expt. 5).
In addition to unifying seemingly disparate parts of language, this paper provides a theoretical framework for asking further questions about genericity, which we outline below.

The theory we present here has a number of desirable features that go beyond alternative theories.
The first is that our theory is presented with a formal model, which makes precise quantitative predictions about production and comprehension of statements that convey generalizations.
We used the most basic tests to validate our model: Production was examined in terms of *endorsement*, which can be seen as a special case of production when the only available alterantive utterances are the assertion or its negation.
Comprehension was examined in terms of *implied prevalence*, which in our theory is most basic inference a hearer can make upon hearing a generalization.
Though these are highly abstracted tests of the model, the modeling framework in principle allows for elaboration to a more complete production and comprehension model. 

Our formal model provides a clean separation of the semantics of a generalization from background, world knowledge.
This is critical to understand the contribution of a generalization in language above and beyond world knowledge.
We believe this has been a stumbling block for formal semantic models that try to argue in one or another way for a probabilty based approach [@Pelletier; @Cohen1999; @Nickel].
As @Nickel2014 notes, genericity has been particularly difficult to study because it intersects with many other phenomena in language.
We argue that it also intersects with world knowledge in subtle ways, and it is critical to accurately measure and describe world knowledge before making claims about the implications of a generalization *per se*.
Our separation of world knowledge from the semantics of generics allows a way for conceptual structure to influence generic production and comprehension (described in more detail below).
This paves the way for articulating formal theories about conceptual structure and it's implications on generic language without having to posit adhoc rules governing the core meaning of a generic with different relations [c.f., @Leslie2008].
It also allows for models to derive inferences about particular exemplars from generic statements, which is a key step towards advancing Natural Language Processing algorithms that feed off large corpora.

In the rest of this discussion, we discuss some key features of the theory that warrant future investigation and the relationship of our theories to extant theories of genericity.
We conclude by sketching out arguments for other philosophical puzzles in genericity.

## The Comparison Class and the Question Under Discussion

In this paper, we proposed a model for understanding generalizations in language that relies upon interlocutors' shared beliefs over the statistics of the event or propertyn under discussion.
We constructed the prior belief distribution for the propensity of an action, cause, or property by considering other possible people doing the action, other possible causes producing the effect, or other possible categories having the property.
These other people, causes, and kinds form *comparison classes* against which the target is evaluated. 
$P(x)$ is always relative to a class of other entities or events, a comparison class $K$: $P_K(x)$.

The existence of comparison classes is uncontroversial in the study of *vague language* [e.g., gradable adjectives like *tall* and vague quantifiers like *many*; @Bale2011; @Solt2009].
Adult judgments of the felicity of gradable adjectives like *tall* or *dark* depend upon fine-grained details of the statistics of the comparison class [@Qing2014; @Schmidt2009; @Solt2012].
We have shown similar sensitivity to the statistics of comparison class in the language of generalizations, thus connecting generic, habitual, and causal language to the study of *vague language*. 

In this work, we made the design decision to construct the comparison class with respect to other people, causes, or kinds.
In this way, the statement of genericity is addressing the implicit Question Under Discussions (QUDs): *who \textsc{does action}?*, *what causes \textsc{effect}?*, or *what \textsc{has feature}?*, respectively.
In the minimal contexts employed in our experiments, this is a reasonable assumption.
There is a different assumption we could have made, however: Another clear way to construct the comparison class, with respect to other features. 
This *feature-wise* comparison class would correspond to addressing the implicit QUDs: *what does \textsc{person} do?*, *what effects does \textsc{cause} bring about?*, and *what features does \textsc{kind} have?*

Statements of genericity can be used to address either QUD, and this difference can even be observed the same sentence.
"Lawyers care about the law." can be interpreted with a category-wise comparison class (i.e., *Lawyers (as opposed to doctors, firefighters, ...) care about the law.*; say, in a pedagogical context) or a feature-wise comparison class (i.e., *Lawyers care about the law (as opposed to justice, ethics, ...)* e.g., said sardonically).
We chose to focus in this work on the category-wise comparison class for methodological convenience. 
In our three case studies, the *category-wise* comparison classes are fixed to *other people*, *other causes*, or *other kinds*, even as we vary the features.
*Feature-wise* comparison classes are likely to be modulated by the feature itself.
Future work should address the property-wise reading of generalizations, and explore what cues lead listeners to one or the other interpretation.


<!-- Throughout our experiments in this work, we have focused on sentences about animals.  -->
<!-- In addition to being the main focus of past theoretical and empirical work, focusing on animals is methodologically convenient as the comparison class for generics about animals is quite naturally \emph{animals}. -->
<!-- When we look beyond generics about animals, deciding what goes into a comparison class becomes less clear. -->
<!-- There are some hints that the comparison class can be derived with respect to the property [@Keil1979], but may involve pragmatic reasoning as well.  -->
<!-- For example, the statement "iPhones are useful" could be in comparison to other forms of technology (like a desktop computer), while "iPhones are heavy" could really only be informative relative to other handheld devices. -->

<!-- The incorporation of a comparison class into the study of generic language might help elucidate other puzzles concerning generics. -->
<!-- Recent work in philosophy and linguistics, for instance, suggest generic language is context-sensitive [@Nickel2008; Sterken2015]. -->
<!-- @Nickel2008 points out that \emph{Dobermans have floppy ears} may be true in the context of a discussion of evolutionary biology but that \emph{Dobermans have pointy ears} is true in a discussion of dog breeding. -->
<!-- Our theory provides a hint from where to begin to understand this context sensitivity: the comparison class. -->
<!-- Different conversational contexts could bring to mind different comparison classes, in a way analogous to the context-sensitivity of  gradable adjectives (e.g., \emph{tall}).  -->
<!-- Hearing that "Abigail is tall" means different things is Abigail is 20 years old or if she is 4.  -->
<!-- Future work will be needed to explore whether a pragmatic inference approach is also relevant to establishing the comparison class, and what background knowledge about properties, categories, and context is relevant. -->

## Structured prior knowledge and Implications for Conceptual Structure

-- add tomasello about learning about how to take turns, as a generalization about an event type which is the event of how the game is supposed to be played

Previous psychological and philosophical work on generics has looked beyond prevalence and focused on conceptual distinctions and relations [@Gelman2003; @Prasada2013; @Leslie2007; @Leslie2008]. 
Prasada has argued for a distinction between \emph{characteristic} properties (e.g.~\emph{Diapers are absorbent.}) and \emph{statistical} properties (e.g.~\emph{Diapers are white.}).
Leslie suggests information that is striking (e.g.~\emph{Tigers eat people.}) is useful and thus permitted to be a generic.
Gelman outlines how generics tend to express \emph{essential} qualities that are relatively timeless and enduring. 
Where in the prevalence-based semantics could such conceptual distinctions come into play?

Our approach makes the strong claim that beliefs about predicted prevalence are the connective tissue between conceptual knowledge and generic language.
That is, the effect of conceptually meaningful differences on generic language is predicted to be mediated by differences in corresponding prevalence distributions.
It is important to note that our approach is based on \emph{subjective} probability, and not mere frequency.
Indeed, we elucidated in Expt.~3 that using participants' \emph{predictions} of probability in our formal model perfectly track generic endorsement, when the present frequency would make the wrong prediction.

The focus on subjective, predictive probability casts new light on puzzles surrounding accidentally-true situations.
An example is the statement "Supreme Court Justices have even social security numbers", which is predicted by linguists to be rejected even if every single Supreme Court Justice has an even social security number [@Cohen1999].
Our explanation is that abstract intuitive theories lead us to reject observed frequencies in forming our subjective probabilities.
That is, because we may believe selection for the Supreme Court is not influenced by one's social security number, we would assign roughly 50\% subjective probability to the \emph{next} justice having an even number.
Thus, we would still reject the generic \emph{Supreme Court Justices have even social security numbers}, because the predictive prevalence would not be any different for Supreme Court Justices than any other profession.^[Our perspective makes the intriguing prediction that if we learned much more surprising information, we might be compelled to revise our theory and then accept the generic. For instance, if every justice in history had \emph{prime numbered} social security numbers (a more suspicious coincidence), one might appeal to a conspiracy, which \emph{would} have predictive consequences.]

Turning back to conceptual relations and structure, it is natural to ask when subjective probabilities might reflect conceptual knowledge?
We found that empirical prevalence distributions are structured in a way that reflects intuitions about causal mechanisms underlying different properties; the differences in shape of these distributions in turn led to variable endorsements and interpretations of generic sentences. 
It is plausible that richer conceptual knowledge also influences these distributions, such as higher-order conceptual knowledge about the nature of properties and categories [@Gelman2003; @Keil1992].
Indeed, it has been argued that conceptual structure in general, including higher-order abstractions, can be captured by probabilisitic causal models and their generalizations [@pearl1988probabilistic; @Gopnik2003theory; @Goodmanconcepts].
Future work will be needed to explore whether probabilistic representations of conceptual knowledge can capture the relations identified in other accounts of generics (such as characteristic, essential, and striking properties), and whether the effect of these relations can then be adequately captured via their impact on subjective prevalence.

### The Problems with Communicating Generalizations

Thus, in order to define a generalization about a category, there must be some corresponding concrete particular instance of that category from which the generalization is formed. 
For example, if an agent observes $n$ instances of \textsc{dog} ($d_1, d_2, ..., d_n$)
For example, if an observer forms a generalization about \textsc{dogs}, she must some way of determining when she is in an instance of the category \textsc{dogs}: She must be able to *individuate*.
In Hume's words, generalizations are predictions about "instances of which we have had no experience resemble those of which we have had experience" [@HumeTHN].


Generalizations can be made about almost anything.
Here, we restrict our focus to generalizations about categories (whose linguistic expression is known as *generic language*), which have been the primary focus of psychologists, linguists, and philosophers.
We posit that our analysis should expect to generalizations about events (habitual language) as well as generalizations about causal forces (causal language).



Generics express a relation between a kind K (e.g., \textsc{robins}) and a property F (e.g., \textsc{lays eggs}), such that the property can also be said to be applicable of an individual (i.e., the bird in my backyard lays eggs).
Bare plural statements (e.g., \emph{Robins lay eggs}) tend strongly to yield a generic meaning [@Carlson1977], though other forms can express such a meaning sometimes (e.g., \emph{A mongoose eats snakes.}).

Given that generics express a property that can be applied to individuals, it would seem intuitive that the number of individuals with the property would be what makes the statement true or false.
Counter-examples like \emph{Mosquitos carry malaria} and \emph{Birds lay eggs} v. \emph{Birds are female} stifle such intuition. 

### Statistical Accounts of Generics

Statistical accounts take the \textbf{property prevalence} to be fundamental: \emph{Birds lay eggs} means \emph{Birds, in general, lay eggs}. 
Of course, birds do not in general lay eggs (it's only the adult, female ones that do).
The primary way of dealing with such issues is to posit domain restrictions ("implicitly, we are only talking about the females") when there are "salient partitions" [@Carlson1995].
The most fully-developed theory on this front is due to @Cohen1999. 
Let's first introduce some notation:



### Conceptual Accounts of Generics

Conceptual accounts of generics emphasize the structure of generic knowledge [@Prasada2000], and view generic utterances as the way of expressing special mental relationships between kinds and properties [@Leslie2008; @Prasada2012].
From this perspective, \emph{Bishops move diagonally} because those are the rules of the game, not because they \emph{tend to} move diagonally.
How do we come to know the rules of the game, though?

@Leslie2007's influential theory posits that generics are tied to a "default mode of generalization". 
This "default mode" comes equipped with the ability to single-out \emph{striking properties} (e.g. properties which are dangerous or appalling) as particularly useful aspects of the world to know about. 
Hence, \emph{Mosquitos carry malaria} is true because carrying malaria is striking, and thus, a useful bit of information to convey.
The default mode can also distinguish "negative" counter-instances of a property   (e.g. a bird that doesn't lay eggs) from "positive" counter-instances (e.g. a hypothetical bird that bears live young).
Generics are much less reasonable when positive counter-instances exist. Hence, \emph{Birds are female} seems weird because "being male" is a positive counter-instance of "being female", but since there are no birds that bear live young,  \emph{Birds lay eggs} is fine.

Parallel work in the psychology of concepts supports this perspective.
@Prasada2006 and later @Prasada2013 distinguish between \emph{principled}, \emph{statistical}, and \emph{causal} relations within concepts. 
Generics like \emph{Birds lay eggs} (in which only a minority of K have F) exhibit characteristics of principled connections (operationalized by endorsement of the phrase \emph{In general, Ks have F}), supporting @Leslie2007's typology.
Striking generics (e.g. \emph{Mosquitos carry malaria}) show characteristics of \emph{causal connections} (operationalized using the phrase \emph{There is something about Ks that cause them to F}). 
The fact that generics about different properties license different kinds of inferences is taken as evidence that the generics themselves represent different kinds of relations. Statistical information takes a backseat to the conceptual structure.







## Communicating Predictive Probabilities

This paper puts forth the theory that the simplest language of abstractions (i.e., the language of generalizations) communicates predictive probabilities from speaker to hearer. 
This might seem contrary to a basic tenet in cognitive psychology, that human cognition falters when reasoning about probabilities [@Tversky1974].
In a multitude of demonstrations, Kahneman and Tversky observed that human reasoners perform poorly when reasoning about explicit probabilities.
This has been taken to imply that people are bad with probabilties.

We suggest that problems with communicating probabilities are a problem of the language used to convey *explicit* probabilties [cf., @Levinson1995]. 
A host of development evidence suggests that even the youngest learners are actually quite good about reasoning about probabilities [@Gweon2010; @Dewar2010].
In this work, we have shown that probabilities are central to even the most basic linguistic expressions.
Indeed they are causally related to communicating generalizations, as evidenced by Expt. 3.
We convey probabilities to each other using language, but the most basic ways we have of conveying them are *vague*. 


## Acquiring the Language of Generalizations

The linguistic outlet for generalizations about categories---so called, *generic language*---has received tremendous attention from psychologists, linguists, and philosophers.
Generic language is one of the earliest emerging forms of complex, compositional language (CITE).
Somewhere between 2 and 3 years of age, children recognize that generics convey a generalization about a category, not directly tied to concrete instances in a scene [@Cimpian2008].
More on development.

What is perhaps surprising from a formal perspective is that generic language is far from trivial to characterize. 
If generics convey something about the prevalence of feature, we would expect them to be in some way comparable to quantifier statments (e.g., "some", "most", "all", ...).
Rehash linguistic puzzles.
The extreme flexibility of generic meaning stands in stark contrast to its early emergence in development.
In fact, quantified statements, whose formal meaning is much more straight-forward, emerge much *later* in development.
This has led some to conclude that the normal tools for describing the semantics of quantified utterances (namely, a truth-functional threshold) will not work for generic language [@Leslie2008].

This may be throwing out the baby with the bathwater.
When we consider the acquisition problem, there are two aspects of meaning that a language learner must acquire for the semantics of a quantified utterance: (1) that the meaning is a threshold-function (i.e., $\denote{u}(p, \theta) = \{p :p > \theta\}$ and (2) the fixed value of the threshold (e.g., $\theta = 0$ for "some", $\theta = 0.5$ for "most").
If there is no fixed value of the threshold, then a uniform prior over the threshold in the truth-functional threshold semantics is mathematically equivalent to a *soft semantics* wherein the degree to which the utterance is true is *the degree itself*, normalized by the prior distribution over the degree (i.e., the comparison class). 

$$
\int_{0}^{1} \delta_{p > \theta} \diff \theta =  p
$$

Given this mathematical equivalence, we can imagine the *more is better* soft semantics is what is acquired early.
The difficulty in acquiring the meaning of quantifiers is then a difficulty in recognizing a fixed-threshold semantics as a special case of this *more is better* sematnics.
This special case involves learning the value of the threshold (aspect 2) and not in recognizing that the utterance conveys something about the quantity (e.g., aspect 1).

## Relationship to Other Theories

To our knowledge, this is the first formal theory of genericity in language that makes accurate and precise quantitative predictions about human behavioral data. 
A number of other theories of genericity have been proposed in the linguistics and psychological literature. By and large, these theories are concerned with explaining *generics* or generalizations about categories, so in keeping with the spirit of these authors, we will refer to the object of explanation, without loss of generality, as *generics*.

Semantic theories fall into one of two broad camps: Those that appeal to the statistics of the world (e.g., how many Ks have F) and those that appeal to structured, conceptual representations (e.g., there is something about being K which causes it to F).
Statistical and conceptual theories express the major contrasting views of the truth conditions of generic statements [@Carlson1995essay].^[We use the terms statistical and conceptual to refer to what @Carlson1995essay referred to as "inductive" and "rules and regulations" views, respectively.]


### Statistical Accounts

Statistical accounts take the \textbf{property prevalence} to be fundamental: \emph{Birds lay eggs} means \emph{Birds, in general, lay eggs}. 
Our probabilistic account has antecedents in @Cohen1999 's theory of generics as a frequency adverb (e.g., "generally").
As with our formulation, Cohen looks to *prevalence* as a metric against which generics get evaluated.
For Cohen, there are two kinds of generic statements: "Absolute" and "Relative".
"Absolute generics" have a meaning with a fixed threshold on prevalence and that threshold is 0.5: $P(F\mid K)>0.5$. 
Roughly speaking, "Dogs have four legs" is true because a given dog is more likely than not to have four legs. 
"Relative generics" on the other hand depend upon an alternative set of kinds (his notation: $Alt(K)$), similar to our comparison class.
These statements (e.g., *Mosquitos carry malaria*) are true if an arbitrary member of the target kind is more likely than an arbitrary member of an alternative kind to have the feature.

There are two main points of deviation of our theory from Cohen's.
First, though his theory is framed in terms of probabilities, it still relies upon fixed threshold and deterministic truth conditions. 
On the contrary, our theory posits that the meaning (i.e., threhsold) is underspecified in the semantics.
Second, Cohen must draw the adhoc distinction between "Absolute" and "Relative" generics; our theory is able to handle both kinds of examples with the same basic machinery.

It should be noted that another mechanism used in Cohen's theory is to contextually restrict the entities that go into the computation of prevalence (i.e., which robins do we look to compute the prevalence of *laying eggs* among *robins*?).
These entities are restricted to those that could have *some* feature in a (contextually-specified) alternative set of features (so called, $Alt(F)$). 
For example, the property \emph{lays eggs} could induce a set of alternatives that all have to do with procreation (e.g. \emph{gives birth to live young}, \emph{undergoes mitosis}, ...).
That is, *Robins lay eggs* can be evaluated as an "absolute generic" as the only individuals under consideration are the female members of kinds because only the female members can plausibly satisfy one or another of the alternatives.
<!-- Of course, the inferential machinery behind this sort of domain restriction (i.e., what is $Alt(F)$?) requires further theorizing to explain.  -->
The inferential machinery behind this sort of domain restriction (i.e., what is $Alt(F)$?) relies upon conceptual information, but how exactly remains obscure [@Carlson1995essay].
^[However, see @Cohen2004 for a discussion of how his semantic constraints relate to different kinds of generics and different kinds of conceptual representational frameworks found in cognitive science.]
Our theory doesn't explicitly rely upon domain restriction for this reason.
However, we think it's plausible that there exists a reformulation of the uncertain threshold model to a fixed threshold that where the listener has uncertainty about the relevant domain restriction. 

Our theory bears some conceptual similarity to a recent proposal by @Sterken2015. 
Sterken treats the generic as a kind of *indexical* (e.g., "this" or "I").
She argues that kind of truth-conditional variability exhibited by generics is best accounted for by an account generics as an indexical where both domain restriction and "quantificational force" vary with context.
We think our uncertain threshold model is a way of formalizing Sterken's "quantificational force".
As noted above, we have not yet formalized uncertainty about domain restriction but think this is a promising avenue for future research.

Other theorists under the quantificational or statistical banner draw on the intuition that generics seem to express something what is *normal* in the world [@Asher1995; @Pelletier1997; @Nickel2008].
For example, it is a regrettable but true fact that due to unfortunate circumstances, not all dogs have four legs.
However, we might want to hold onto the idea that were the world to work *normally*, then all dogs would have four legs. 
This idea has intuitive appeal for rejecting accidentally true generalizations (e.g., the hypothetical situation where all Supreme Court justices had social security numbers that were even numbers and the intuitive ambivalence about the statement *Supreme Court justices have even social security numbers*).
It also may underly what is problematic about stereotyped language (e.g., *Boys are good at math*).
The idea that speaker's beliefs (e.g., about what is *normal*) plays a role in endorsing and interpreting generalizations is central to the formulation of our theory of generics in a Bayesian cognitive model.
Indeed, we have elaborated this view showing in Expt. 3 that is in fact speaker's beliefs about what is likely to be the case in the near future that matters for endorsing generalizations.
Prevalence or propensity in our theory is a posterior predictive probability, which incorporates background knowledge in order to make predictions about the future. 
It is likely that what is "normal" is captured in much of our intuitive theories of other domains.

### Conceptual Accounts

It is also the first attempt in psychology to try to unify significant swaths of language that are seemingly quite different from one another: generalizations about events, causes, and categories.

-- Leslie (2008): Default inferences, could be similar to the cognitive model described, but we don't make strong metaphysical commitments (e.g., to "negative" properties)

-- "default generalization" -- very close, the listener is doing a generalization, but not generalization based on evidence, but by reasoning about the threshold



Generic language is the simple and ubiquitous way by which generalizations are conveyed between people.
Yet the dramatic flexibility of generic language has confounded psychologists, linguists and philosophers who have tried to articulate what exactly generic statements mean. 
We evaluated a theory of generic language derived from general principles of language understanding using a simple, but uncertain, basic meaning---a threshold on property prevalence.
Our formal model is a minimal extension of the RSA theory of language understanding, together with an underspecified threshold semantics.
The model was able to explain two major puzzles of generics: their extreme flexibility in truth conditions and the contrastingly strong interpretation of many novel generics.
Both of these phenomena were revealed to depend in systematic ways on prior knowledge about properties.
This prior knowledge was revealed through Bayesian model analysis to be structured, providing a promising bridge to conceptual accounts of generic language.
To understand the nature of the underlying prevalence scale, we showed that generic language is about speakers' expectations of future prevalence, and not necessarily what the current state of the world is like. 
Across all experiments, the formal model predicted the quantitative details of participants' judgments with high accuracy.

There have been numerous demonstrations arguing that statistics (e.g., property prevalence) are insufficient to explain generic meaning [@Gelman2002; @Gelman2007; @Cimpian2010; @Cimpian2010c; @Khemlani2012; @Prasada2013].
In these experiments, the prevalence considered is only the prevalence of the property for the target category [e.g., the percentage of birds that lay eggs; @Khemlani2012; @Prasada2013], what we have referred to as \emph{within-kind prevalence}. 
Indeed, this simple statistic also fails to explain our data (Figure \ref{fig:commongenerics}b, right).
Our formal model of pragmatics, by contrast, considers not only within-kind prevalence, but a listener's prior beliefs about prevalence across kinds in order to arrive at a meaning for a generic utterance.
By establishing the validity of a semantics based on prevalence alone, we provide a formalism to learn about categories from generic statements. 
Further, since prevalence is a probability, our model can take information conveyed with a generic and be naturally extended to make predictions about entities in the world or support explanations of events or behavior.



<!-- ## Generic Identification -->

<!-- Throughout this paper we treated the bare plural construction as a generic utterance with a threshold semantics: $\denote{\text{K F}}(x, \theta)=x>\theta$. -->
<!-- The bare plural construction can also indicate a specific plural predication. -->
<!-- For example, "Dogs are on my lawn" picks out a specific group of dogs, while "Dogs have fur"  does not [@Carlson1977]. -->
<!-- The problem of \emph{identifying} a generic meaning from a bare plural construction is itself a challenging problem because generic meaning can be signaled using a diverse array of morphosyntactic cues. -->

<!-- @Declerck1991 suggests that generic and non-generic bare plurals can be treated in the same way, and that pragmatic considerations alone may resolve interpretative differences.  -->
<!-- Indeed it does appear that knowledge of the properties under discussion (e.g., the state of being on a front lawn; the state of having fur) could facilitate the generic identification process. -->
<!-- Other pragmatic factors, like knowledge of the identity of the speaker (e.g., a teacher vs. a veterinarian), can also disambiguate generic and non-generic meaning [@Cimpian2008]. -->
<!-- Recent work suggests that utterances that fail to refer to specific entities or events could pragmatically imply generic meaning [@Crone2016cogsci]. -->
<!-- Incorporating these insights about generic identification into an information-theoretic, communicative perspective is a natural extension of this work. -->

## Other philosophical puzzles

-- Books are paperbacks. (failure of the constrast class)
-- Birds lay eggs and are female vs. Elephants live in Asia and Africa
--> can use pragmatics to resolve if the property is conjunctive or not. 
-- Women are submissive. (Haslanger, 2011; generics + politeness mechanism, some states have lower value than others)
-- Muslims are terrorists (vs. Mosquitos carry malaria)
-- Mary handles the mail from antarctica (predictive propensity; also highlights domain restriction on events)
- Glass breaks when struck. (so-called "disposition", but here: a generalization about the event of a glass being struck [already we are domain restricted])


# Conclusion

It might seem paradoxical that a part of language that is so common in communication and central to learning should be vague. 
Shouldn't speakers and teachers want to express their ideas as crisply as possible?
To the contrary, underspecification can be efficient, given that context can be used to resolve the uncertainty [@Piantadosi2012].
In our work, context takes the form of a listener and speaker's shared beliefs about the property in question. 
By leveraging this common ground, generics provide a powerful way to communicate and learn generalizations about categories, 
which would otherwise be difficult or costly information to learn through direct experience.

The dark side of this flexibility is the potential for miscommunication or deceit: A speaker might assert a generic utterance that he himself would not accept, conveying a too-strong generalization to a na\"{i}ve listener.  
Our model predicts this potential particularly for properties which, when present, are widespread in a category---we showed that biological properties are believed to have this distribution, but many properties of social categories may as well [@Cimpian2011a; @Cimpian2012b; @Rhodes2012].
Disagreements are also predicted when interlocutors fail to share background assumptions:
differences in the within-kind prevalence, the prior distributions on prevalence, or the comparison class.
For example, there is considerable disagreement as to whether or not "Humans cause global warming".
Our theory predicts this disagreement may be the result of differences in the estimated \emph{causal power} of humans influencing global warming as well as the causal power of \emph{other forces} (e.g., plate tectonics) on climate change.
This is a promising area for future research.


Categories are inherently unobservable. 
You cannot see the category \textsc{dog}, only some number of instances of it.
Yet we easily talk about these abstractions, conveying hard-won generalizations to each other and down through generations.
The theory presented here gives one explanation of how we do so, providing a computational perspective on how category generalizations are conveyed and how beliefs play a central role in understanding language.



# References 

<!-- \setlength{\parindent}{-0.1in}  -->
<!-- \setlength{\leftskip}{0.125in} -->
<!-- \noindent -->

<div id = 'refs'></div>

```{r child = 'appendix-prevalencePrior.Rmd'}
```

```{r child = 'appendix-cueValidity.Rmd'}
```

